{
  "lecture": "Lecture 10",
  "models": {
    "OpenGVLab__InternVL3-14B": {
      "concepts": null,
      "triples": null
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "category": "algorithm",
        "term": "training"
      },
      "triples": {
        "triples": []
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "category": "ai_ml",
        "term": "sparse ae"
      },
      "triples": {
        "triples": []
      }
    },
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "category": "ai_ml",
        "term": "activation functions"
      },
      "triples": {
        "triples": [
          {
            "confidence": 0.0,
            "evidence": "Once you have the basic idea of how a neural network works, you can imagine that there\u2019s no single way to connect the neurons. In fact, researchers have developed many different network topologies, each suited for specific tasks.",
            "modalities": [
              "text"
            ],
            "o": "feed-forward networks",
            "p": "uses",
            "s": "perceptron"
          }
        ]
      }
    }
  },
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 10\\Images\\Slide41.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 10\\Texts\\Slide41.txt"
  },
  "slide_id": "Slide41"
}
