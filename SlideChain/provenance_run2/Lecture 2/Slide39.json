{
  "lecture": "Lecture 2",
  "models": {
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "concepts": [
          {
            "category": "mathematics",
            "term": "matrix multiplication"
          },
          {
            "category": "algorithm",
            "term": "nested loops"
          },
          {
            "category": "mathematics",
            "term": "dot product"
          },
          {
            "category": "software",
            "term": "function"
          }
        ],
        "evidence": [
          "write our own matrix multiplication function",
          "Using three nested loops",
          "dot product between a row of A and a column of B",
          "create a function called matrix_multiply",
          "Hint: Use vectorization"
        ]
      },
      "triples": {
        "triples": [
          {
            "confidence": 1.0,
            "evidence": "Using three nested loops, we compute the product row by row and column by column.",
            "modalities": [
              "text"
            ],
            "o": "three nested loops",
            "p": "uses",
            "s": "matrix_multiply"
          }
        ]
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "concepts": [
          {
            "category": "algorithm",
            "term": "matrix_multiply"
          },
          {
            "category": "mathematics",
            "term": "matrix multiplication"
          },
          {
            "category": "software",
            "term": "nested loops"
          },
          {
            "category": "mathematics",
            "term": "dot product"
          },
          {
            "category": "software",
            "term": "under the hood"
          },
          {
            "category": "software",
            "term": "optimization"
          }
        ],
        "evidence": [
          "We create a function called matrix_multiply that takes two square matrices and a size n.",
          "Using three nested loops, we compute the product row by row and column by column.",
          "For each entry in the result, we take a dot product between a row of A and a column of B.",
          "This hands-on approach shows exactly how matrix multiplication works under the hood - which is important to understand before we talk about optimization."
        ]
      },
      "triples": {
        "triples": []
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "category": "algorithm",
        "term": "this hands-on approach shows exactly how matrix multiplication works under the hood - which is important to understand before we talk about optimization."
      },
      "triples": {
        "confidence": 0.9,
        "evidence": [
          "For each entry in the result, we take a dot product between a row of A and a column of B."
        ],
        "modalities": [
          "text"
        ],
        "o": "dot product between a row of A and a column of B",
        "p": "represents",
        "s": "matrix_multiply"
      }
    },
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "concepts": [
          {
            "category": "mathematics",
            "term": "matrix multiplication"
          },
          {
            "category": "software",
            "term": "nested loops"
          },
          {
            "category": "mathematics",
            "term": "dot product"
          },
          {
            "category": "software",
            "term": "optimization"
          }
        ],
        "evidence": [
          "We create a function called matrix_multiply that takes two square matrices and a size n.",
          "Using three nested loops, we compute the product row by row and column by column. For each entry in the result, we take a dot product between a row of A and a column of B."
        ]
      },
      "triples": {
        "triples": []
      }
    }
  },
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 2\\Images\\Slide39.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 2\\Texts\\Slide39.txt"
  },
  "slide_id": "Slide39"
}
