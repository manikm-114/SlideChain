{
  "lecture": "Lecture 11",
  "models": {
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "concepts": [
          {
            "category": "ai_ml",
            "term": "supervised learning"
          },
          {
            "category": "algorithm",
            "term": "linear classifiers"
          },
          {
            "category": "ai_ml",
            "term": "hidden layers"
          },
          {
            "category": "ai_ml",
            "term": "nonlinear activation functions"
          },
          {
            "category": "ai_ml",
            "term": "neural network"
          },
          {
            "category": "ai_ml",
            "term": "deep learning"
          },
          {
            "category": "ai_ml",
            "term": "hierarchical features"
          },
          {
            "category": "ai_ml",
            "term": "state-of-the-art performance"
          }
        ],
        "evidence": [
          "Supervised learning builds on this idea by training models directly on labeled data.",
          "linear classifiers cannot draw a single straight line to separate the classes.",
          "by introducing hidden layers and nonlinear activation functions, a neural network can learn to separate the classes correctly.",
          "This principle extends far beyond toy problems-it is the basis of modern deep learning",
          "very large networks can learn hierarchical features from medical images and achieve state-of-the-art performance."
        ]
      },
      "triples": {
        "confidence": 1.0,
        "evidence": [
          "But by introducing hidden layers and nonlinear activation functions, a neural network can learn to separate the classes correctly."
        ],
        "modalities": [
          "text"
        ],
        "o": "hidden layers and nonlinear activation functions",
        "p": "introduces",
        "s": "neural network"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "category": "algorithm",
        "term": "state-of-the-art performance"
      },
      "triples": {
        "triples": [
          {
            "confidence": 1.0,
            "evidence": "Supervised learning builds on this idea by training models directly on labeled data. For example, in the XOR problem, linear classifiers cannot draw a single straight line to separate the classes. But by introducing hidden layers and nonlinear activation functions, a neural network can learn to separate the classes correctly.",
            "modalities": [
              "text"
            ],
            "o": "XOR problem",
            "p": "uses",
            "s": "Supervised Learning"
          }
        ]
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "category": "ai_ml",
        "term": "where very large networks can learn hierarchical features from medical images and achieve state-of-the-art performance"
      },
      "triples": {
        "triples": []
      }
    },
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "category": "ai_ml",
        "term": "state-of-the-art performance"
      },
      "triples": {
        "confidence": 0.0,
        "evidence": [
          "can learn to separate the classes correctly"
        ],
        "modalities": [
          "text"
        ],
        "o": "hidden layers and nonlinear activation functions",
        "p": "uses|via|represents|depends_on|measures|produces|reconstructs_with",
        "s": "neural network"
      }
    }
  },
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide61.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide61.txt"
  },
  "slide_id": "Slide61"
}
