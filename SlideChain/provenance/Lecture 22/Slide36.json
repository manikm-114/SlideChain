{
  "lecture": "Lecture 22",
  "models": {
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "category": "quality_metric",
        "term": "artifacts"
      },
      "triples": {
        "confidence": 0.9,
        "evidence": [
          "When you multiply the received signal by this depth-dependent gain, the resulting image becomes more uniform in brightness."
        ],
        "modalities": [
          "text"
        ],
        "o": "more uniform image brightness",
        "p": "produces",
        "s": "time-gain compensation"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "category": "signal_processing",
        "term": "depth"
      },
      "triples": {
        "triples": []
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "category": "quality_metric",
        "term": "deeper regions would appear dark and faint"
      },
      "triples": {
        "confidence": 0.85,
        "evidence": [
          "This correction is based on assumptions about tissue homogeneity-it works well when the tissue properties are roughly uniform."
        ],
        "modalities": [
          "text"
        ],
        "o": "assumptions about tissue homogeneity",
        "p": "depends_on",
        "s": "time-gain compensation"
      }
    },
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "category": "quality_metric",
        "term": "artifacts"
      },
      "triples": {
        "triples": []
      }
    }
  },
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Images\\Slide36.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Texts\\Slide36.txt"
  },
  "slide_id": "Slide36"
}
