nohup: ignoring input
/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:119: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✅ Device: cuda
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 16039.40it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.11s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.53it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]
✅ Successfully loaded: llava-hf/llava-onevision-qwen2-7b-ov-hf

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=concepts on 50 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/50 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   2%|▏         | 1/50 [00:07<06:01,  7.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   4%|▍         | 2/50 [00:15<06:14,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   6%|▌         | 3/50 [00:23<06:19,  8.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   8%|▊         | 4/50 [00:32<06:20,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  10%|█         | 5/50 [00:40<06:15,  8.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  12%|█▏        | 6/50 [00:49<06:10,  8.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  14%|█▍        | 7/50 [00:58<06:03,  8.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  16%|█▌        | 8/50 [01:06<05:56,  8.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  18%|█▊        | 9/50 [01:15<05:48,  8.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  20%|██        | 10/50 [01:23<05:40,  8.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  22%|██▏       | 11/50 [01:32<05:32,  8.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  24%|██▍       | 12/50 [01:40<05:23,  8.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  26%|██▌       | 13/50 [01:49<05:15,  8.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  28%|██▊       | 14/50 [01:57<05:06,  8.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  30%|███       | 15/50 [02:06<04:58,  8.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  32%|███▏      | 16/50 [02:14<04:49,  8.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  34%|███▍      | 17/50 [02:23<04:41,  8.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  36%|███▌      | 18/50 [02:31<04:32,  8.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  38%|███▊      | 19/50 [02:40<04:23,  8.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  40%|████      | 20/50 [02:48<04:14,  8.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  42%|████▏     | 21/50 [02:57<04:05,  8.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  44%|████▍     | 22/50 [03:05<03:57,  8.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  46%|████▌     | 23/50 [03:14<03:49,  8.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  48%|████▊     | 24/50 [03:22<03:41,  8.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  50%|█████     | 25/50 [03:31<03:32,  8.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  52%|█████▏    | 26/50 [03:39<03:25,  8.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  54%|█████▍    | 27/50 [03:48<03:16,  8.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  56%|█████▌    | 28/50 [03:56<03:08,  8.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  58%|█████▊    | 29/50 [04:05<02:59,  8.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  60%|██████    | 30/50 [04:10<02:31,  7.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  62%|██████▏   | 31/50 [04:19<02:29,  7.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  64%|██████▍   | 32/50 [04:27<02:25,  8.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  66%|██████▌   | 33/50 [04:36<02:19,  8.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  68%|██████▊   | 34/50 [04:45<02:13,  8.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  70%|███████   | 35/50 [04:53<02:06,  8.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  72%|███████▏  | 36/50 [05:02<01:58,  8.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  74%|███████▍  | 37/50 [05:10<01:50,  8.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  76%|███████▌  | 38/50 [05:19<01:42,  8.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  78%|███████▊  | 39/50 [05:27<01:33,  8.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  80%|████████  | 40/50 [05:36<01:25,  8.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  82%|████████▏ | 41/50 [05:45<01:16,  8.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  84%|████████▍ | 42/50 [05:53<01:08,  8.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  86%|████████▌ | 43/50 [06:02<00:59,  8.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  88%|████████▊ | 44/50 [06:10<00:51,  8.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  90%|█████████ | 45/50 [06:19<00:42,  8.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  92%|█████████▏| 46/50 [06:27<00:34,  8.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  94%|█████████▍| 47/50 [06:36<00:25,  8.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  96%|█████████▌| 48/50 [06:45<00:17,  8.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  98%|█████████▊| 49/50 [06:53<00:08,  8.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 50/50 [06:59<00:00,  7.74s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 50/50 [06:59<00:00,  8.39s/it]
✅ Completed 50/50 slides

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=triples on 50 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   0%|          | 0/50 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   2%|▏         | 1/50 [00:03<02:58,  3.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   4%|▍         | 2/50 [00:06<02:45,  3.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   6%|▌         | 3/50 [00:12<03:17,  4.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   8%|▊         | 4/50 [00:16<03:12,  4.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  10%|█         | 5/50 [00:21<03:20,  4.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  12%|█▏        | 6/50 [00:24<03:00,  4.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  14%|█▍        | 7/50 [00:28<02:55,  4.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  16%|█▌        | 8/50 [00:32<02:55,  4.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  18%|█▊        | 9/50 [00:36<02:41,  3.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  20%|██        | 10/50 [00:40<02:38,  3.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  22%|██▏       | 11/50 [00:44<02:34,  3.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  24%|██▍       | 12/50 [00:47<02:17,  3.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  26%|██▌       | 13/50 [00:50<02:15,  3.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  28%|██▊       | 14/50 [00:54<02:11,  3.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  30%|███       | 15/50 [00:59<02:22,  4.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  32%|███▏      | 16/50 [01:03<02:16,  4.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  34%|███▍      | 17/50 [01:06<02:04,  3.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  36%|███▌      | 18/50 [01:10<02:00,  3.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  38%|███▊      | 19/50 [01:13<01:54,  3.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  40%|████      | 20/50 [01:17<01:49,  3.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  42%|████▏     | 21/50 [01:20<01:43,  3.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  44%|████▍     | 22/50 [01:25<01:45,  3.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  46%|████▌     | 23/50 [01:30<01:51,  4.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  48%|████▊     | 24/50 [01:34<01:51,  4.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  50%|█████     | 25/50 [01:40<01:57,  4.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  52%|█████▏    | 26/50 [01:44<01:47,  4.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  54%|█████▍    | 27/50 [01:48<01:42,  4.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  56%|█████▌    | 28/50 [01:52<01:35,  4.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  58%|█████▊    | 29/50 [01:57<01:29,  4.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  60%|██████    | 30/50 [02:01<01:23,  4.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  62%|██████▏   | 31/50 [02:05<01:23,  4.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  64%|██████▍   | 32/50 [02:09<01:12,  4.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  66%|██████▌   | 33/50 [02:13<01:09,  4.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  68%|██████▊   | 34/50 [02:17<01:06,  4.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  70%|███████   | 35/50 [02:21<01:01,  4.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  72%|███████▏  | 36/50 [02:25<00:57,  4.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  74%|███████▍  | 37/50 [02:29<00:53,  4.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  76%|███████▌  | 38/50 [02:38<01:05,  5.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  78%|███████▊  | 39/50 [02:42<00:54,  4.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  80%|████████  | 40/50 [02:46<00:47,  4.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  82%|████████▏ | 41/50 [02:51<00:42,  4.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  84%|████████▍ | 42/50 [02:55<00:36,  4.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  86%|████████▌ | 43/50 [02:59<00:30,  4.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  88%|████████▊ | 44/50 [03:03<00:26,  4.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  90%|█████████ | 45/50 [03:07<00:20,  4.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  92%|█████████▏| 46/50 [03:10<00:16,  4.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  94%|█████████▍| 47/50 [03:14<00:11,  3.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  96%|█████████▌| 48/50 [03:18<00:07,  3.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  98%|█████████▊| 49/50 [03:27<00:05,  5.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 50/50 [03:30<00:00,  4.83s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 50/50 [03:30<00:00,  4.22s/it]
✅ Completed 50/50 slides
