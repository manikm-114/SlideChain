{
  "lecture": "Lecture 20",
  "slide_id": "Slide2",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Images\\Slide2.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Texts\\Slide2.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide2.json",
        "parsed": {
          "concepts": [
            {
              "term": "Ultrasound",
              "category": "modality"
            },
            {
              "term": "Optical imaging",
              "category": "modality"
            },
            {
              "term": "Deep imaging",
              "category": "modality"
            },
            {
              "term": "Deep reconstruction",
              "category": "modality"
            },
            {
              "term": "Reconstruction",
              "category": "reconstruction"
            }
          ],
          "evidence": [
            "Let’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities. Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction.”"
          ]
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.  Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Ultrasound\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Deep imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Deep reconstruction\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Signal processing\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Frequency domain\\\", \\\"category\\\": \\\"frequency_domain\\\"},\\n    {\\\"term\\\": \\\"Reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Quality metric\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Let’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities. Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction.”\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"Ultrasound\", \"category\": \"modality\"}, {\"term\": \"Optical imaging\", \"category\": \"modality\"}, {\"term\": \"Deep imaging\", \"category\": \"modality\"}, {\"term\": \"Deep reconstruction\", \"category\": \"modality\"}, {\"term\": \"Reconstruction\", \"category\": \"reconstruction\"}], \"evidence\": [\"Let’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities. Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction.”\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide2.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.  Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"ultrasound\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"medical imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"MRI part\\\"}\\n  ],\\n    {\\\"s\\\":\\\"optical imaging\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"medical imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"MRI part\\\"}\\n  ],\\n    {\\\"s\\\":\\\"deep imaging\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"medical imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"deep imaging\\\"}\\n  ]\\n}\", \"parsed\": null}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide2.json",
        "parsed": {
          "concepts": [
            {
              "term": "ultrasound",
              "category": "modality"
            },
            {
              "term": "optical imaging",
              "category": "modality"
            },
            {
              "term": "deep imaging",
              "category": "ai_ml"
            }
          ],
          "evidence": [
            "ultrasound and optical imaging",
            "deep imaging"
          ]
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"ultrasound\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"deep imaging\\\", \\\"category\\\": \\\"ai_ml\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"ultrasound and optical imaging\\\", \\\"deep imaging\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"ultrasound\", \"category\": \"modality\"}, {\"term\": \"optical imaging\", \"category\": \"modality\"}, {\"term\": \"deep imaging\", \"category\": \"ai_ml\"}], \"evidence\": [\"ultrasound and optical imaging\", \"deep imaging\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"MRI part\\\", \\\"p\\\":\\\"followed_by\\\", \\\"o\\\":\\\"ultrasound\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging\\\"},\\n    {\\\"s\\\":\\\"MRI part\\\", \\\"p\\\":\\\"followed_by\\\", \\\"o\\\":\\\"optical imaging\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging\\\"},\\n    {\\\"s\\\":\\\"course\\\", \\\"p\\\":\\\"covers\\\", \\\"o\\\":\\\"deep imaging\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide2.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T14:36:35.603179+00:00\", \"text_length\": 339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.  Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"MRI\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Ultrasound\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Optical Imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Deep Imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Deep Reconstruction\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.\\\",\\n    \\\"Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\\"\\n  ]\\n}\", \"parsed\": null}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T16:19:50.388180+00:00\", \"text_length\": 339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.  Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide2.json",
        "parsed": {
          "concepts": [
            {
              "term": "ultrasound",
              "category": "modality"
            },
            {
              "term": "optical imaging",
              "category": "modality"
            },
            {
              "term": "deep imaging",
              "category": "ai_ml"
            },
            {
              "term": "deep reconstruction",
              "category": "ai_ml"
            }
          ],
          "evidence": [
            "After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging",
            "Finally, I will give you a very brief overall of the emerging area called \"deep imaging\" or \"deep reconstruction\""
          ]
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T14:16:51.828498+00:00\", \"text_length\": 339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.  Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"ultrasound\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"optical imaging\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"deep imaging\\\",\\n      \\\"category\\\": \\\"ai_ml\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"deep reconstruction\\\",\\n      \\\"category\\\": \\\"ai_ml\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging\\\",\\n    \\\"Finally, I will give you a very brief overall of the emerging area called \\\\\\\"deep imaging\\\\\\\" or \\\\\\\"deep reconstruction\\\\\\\"\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"ultrasound\", \"category\": \"modality\"}, {\"term\": \"optical imaging\", \"category\": \"modality\"}, {\"term\": \"deep imaging\", \"category\": \"ai_ml\"}, {\"term\": \"deep reconstruction\", \"category\": \"ai_ml\"}], \"evidence\": [\"After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging\", \"Finally, I will give you a very brief overall of the emerging area called \\\"deep imaging\\\" or \\\"deep reconstruction\\\"\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T14:25:53.932537+00:00\", \"text_length\": 339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a quick look at our course schedule to see where we stand. After the MRI part, we have two more major imaging modalities: ultrasound and optical imaging, which are quite different but have their unique utilities.  Finally, I will give you a very brief overall of the emerging area called “deep imaging” or “deep reconstruction”.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}