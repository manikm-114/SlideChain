{
  "lecture": "Lecture 20",
  "slide_id": "Slide47",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Images\\Slide47.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Texts\\Slide47.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide47.json",
        "parsed": {
          "concepts": [
            {
              "term": "emission",
              "category": "physics"
            },
            {
              "term": "transmission",
              "category": "physics"
            },
            {
              "term": "tomography",
              "category": "modality"
            },
            {
              "term": "simultaneous",
              "category": "workflow"
            },
            {
              "term": "reconstruction",
              "category": "reconstruction"
            },
            {
              "term": "multimodal imaging",
              "category": "modality"
            },
            {
              "term": "quantitative accuracy",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "... By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.",
            "... This represents another step toward our broader goal-true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body."
          ]
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nPreviously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\n\\nThis idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging. Normally, in PET or SPECT, emission data and transmission data are collected separately—first one scan for anatomy and then another for function. But with SET, both types of data are acquired at the same time.\\n\\nBy combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution. The images on the left show the structural information from the transmission data, while the ones on the right display emission activity from the radio tracer. When we fuse these two datasets, we obtain both anatomical and functional information in a single scan, reducing motion artifacts and improving quantitative accuracy.\\n\\nThis represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"emission\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"transmission\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"tomography\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"simultaneous\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"anatomy\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"functional imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"multimodal imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"fusion\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"quantitative accuracy\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"... By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.\\\", \\\"... This represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"emission\", \"category\": \"physics\"}, {\"term\": \"transmission\", \"category\": \"physics\"}, {\"term\": \"tomography\", \"category\": \"modality\"}, {\"term\": \"simultaneous\", \"category\": \"workflow\"}, {\"term\": \"reconstruction\", \"category\": \"reconstruction\"}, {\"term\": \"multimodal imaging\", \"category\": \"modality\"}, {\"term\": \"quantitative accuracy\", \"category\": \"quality_metric\"}], \"evidence\": [\"... By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.\", \"... This represents another step toward our broader goal-true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide47.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nPreviously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\n\\nThis idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging. Normally, in PET or SPECT, emission data and transmission data are collected separately—first one scan for anatomy and then another for function. But with SET, both types of data are acquired at the same time.\\n\\nBy combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution. The images on the left show the structural information from the transmission data, while the ones on the right display emission activity from the radio tracer. When we fuse these two datasets, we obtain both anatomical and functional information in a single scan, reducing motion artifacts and improving quantitative accuracy.\\n\\nThis represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Simultaneous Emission–Transmission Tomography (SET)\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Multimodal imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"This represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide47.json",
        "parsed": {
          "term": "reconstructions",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Simultaneous Emission–Transmission Tomography\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"gamma-ray imaging\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"radio tracers\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"PET\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"SPECT\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"emission data\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"transmission data\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"structural information\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"emission activity\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"motion artifacts\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"quantitative accuracy\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"multimodal imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"reconstructions\\\", \\\"category\\\": \\\"reconstruction\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"combining emission and transmission information simultaneously\\\",\\n    \\\"gamma-ray imaging and radio tracers\\\",\\n    \\\"PET or SPECT\\\",\\n    \\\"\", \"parsed\": {\"term\": \"reconstructions\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide47.json",
        "parsed": {
          "s": "SET",
          "p": "produces",
          "o": "more accurate reconstructions with improved spatial and contrast resolution",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution."
          ]
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Simultaneous Emission–Transmission Tomography (SET)\\\", \\\"p\\\":\\\"represents\\\", \\\"o\\\":\\\"an important advance in multimodal imaging\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"This idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging.\\\"},\\n    {\\\"s\\\":\\\"SET\\\", \\\"p\\\":\\\"combines\\\", \\\"o\\\":\\\"emission and transmission tomography\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\\"},\\n    {\\\"s\\\":\\\"SET\\\", \\\"p\\\":\\\"produces\\\", \\\"o\\\":\\\"more accurate reconstructions with improved spatial and contrast resolution\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.\\\"},\\n    {\\\"s\\\":\\\"images on the left\\\", \\\"p\\\":\\\"show\\\", \\\"o\\\":\\\"structural information from the transmission data\\\", \\\"\", \"parsed\": {\"s\": \"SET\", \"p\": \"produces\", \"o\": \"more accurate reconstructions with improved spatial and contrast resolution\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide47.json",
        "parsed": {
          "term": "human body",
          "category": "anatomy"
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T16:06:34.697734+00:00\", \"text_length\": 1445, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nPreviously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\n\\nThis idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging. Normally, in PET or SPECT, emission data and transmission data are collected separately—first one scan for anatomy and then another for function. But with SET, both types of data are acquired at the same time.\\n\\nBy combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution. The images on the left show the structural information from the transmission data, while the ones on the right display emission activity from the radio tracer. When we fuse these two datasets, we obtain both anatomical and functional information in a single scan, reducing motion artifacts and improving quantitative accuracy.\\n\\nThis represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Simultaneous Emission–Transmission Tomography (SET)\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"gamma-ray imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"radio tracers\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"anatomy\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"functional information\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"motion artifacts\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"quantitative accuracy\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"multimodal imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"true multimodal imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"complementary information\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"concurrently\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"human body\\\", \\\"category\\\": \\\"anatomy\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"In this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\\",\", \"parsed\": {\"term\": \"human body\", \"category\": \"anatomy\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide47.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T16:52:45.502702+00:00\", \"text_length\": 1445, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nPreviously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\n\\nThis idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging. Normally, in PET or SPECT, emission data and transmission data are collected separately—first one scan for anatomy and then another for function. But with SET, both types of data are acquired at the same time.\\n\\nBy combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution. The images on the left show the structural information from the transmission data, while the ones on the right display emission activity from the radio tracer. When we fuse these two datasets, we obtain both anatomical and functional information in a single scan, reducing motion artifacts and improving quantitative accuracy.\\n\\nThis represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Simultaneous Emission-transmission Tomography (SET)\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"gamma-ray imaging and radio tracers\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Previously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide47.json",
        "parsed": {
          "term": "true multimodal imaging",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T14:24:35.828922+00:00\", \"text_length\": 1445, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nPreviously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\n\\nThis idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging. Normally, in PET or SPECT, emission data and transmission data are collected separately—first one scan for anatomy and then another for function. But with SET, both types of data are acquired at the same time.\\n\\nBy combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution. The images on the left show the structural information from the transmission data, while the ones on the right display emission activity from the radio tracer. When we fuse these two datasets, we obtain both anatomical and functional information in a single scan, reducing motion artifacts and improving quantitative accuracy.\\n\\nThis represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Simultaneous Emission–Transmission Tomography, or SET\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"gamma-ray imaging and radio tracers\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"emission data and transmission data\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"reconstruction\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"spatial and contrast resolution\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"anatomical and functional information\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"motion artifacts\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"quantitative accuracy\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"true multimodal imaging\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission\", \"parsed\": {\"term\": \"true multimodal imaging\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 20\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide47.json",
        "parsed": {
          "s": "Simultaneous Emission-Transmission Tomography (SET)",
          "p": "reconstructs_with",
          "o": "both emission and transmission data",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.9,
          "evidence": [
            "By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution."
          ]
        },
        "raw": "{\"slide_id\": \"Slide47\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T14:32:36.522796+00:00\", \"text_length\": 1445, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nPreviously, we learned about gamma-ray imaging and radio tracers, which allow us to visualize physiological functions inside the body by detecting radiation emitted from injected tracers. Now, in this work, we take the concept one step further by combining emission and transmission tomography into a single, simultaneous process—what we call Simultaneous Emission–Transmission Tomography, or SET.\\n\\nThis idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging. Normally, in PET or SPECT, emission data and transmission data are collected separately—first one scan for anatomy and then another for function. But with SET, both types of data are acquired at the same time.\\n\\nBy combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution. The images on the left show the structural information from the transmission data, while the ones on the right display emission activity from the radio tracer. When we fuse these two datasets, we obtain both anatomical and functional information in a single scan, reducing motion artifacts and improving quantitative accuracy.\\n\\nThis represents another step toward our broader goal—true multimodal imaging, where complementary information from different imaging mechanisms is acquired concurrently for the most comprehensive view of the human body.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Simultaneous Emission–Transmission Tomography (SET)\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"an important advance in multimodal imaging\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"This idea was presented at the Fully3D Conference in Xi’an, China, and it represents an important advance in multimodal imaging.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Simultaneous Emission–Transmission Tomography (SET)\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"both emission and transmission data\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Simultaneous Emission–Transmission Tomography (SET)\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"both anatomical and functional information\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\", \"parsed\": {\"s\": \"Simultaneous Emission-Transmission Tomography (SET)\", \"p\": \"reconstructs_with\", \"o\": \"both emission and transmission data\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.9, \"evidence\": [\"By combining emission and transmission information simultaneously, we can achieve more accurate reconstructions with improved spatial and contrast resolution.\"]}}"
      }
    }
  }
}