{
  "lecture": "Lecture 21",
  "slide_id": "Slide30",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Images\\Slide30.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Texts\\Slide30.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide30.json",
        "parsed": {
          "term": "preventive healthcare",
          "category": "anatomy"
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\nYou simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.\\n\\nOn this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\n\\nNow, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\n\\nJust imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\nYou could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.\\n\\nBy combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.\\n\\nThis might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"probe\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"ultrasound\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"piezoelectric\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"AI software\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"machine learning\\\", \\\"category\\\": \\\"ai_ml\\\"},\\n    {\\\"term\\\": \\\"digital signal processing\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"personal imaging\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"preventive healthcare\\\", \\\"category\\\": \\\"anatomy\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Now, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\\",\\n    \\\"These probes are used for a variety of diagnostic and therapeutic purposes.\\\",\\n    \\\"Just imagine that the phone’s surface could act as a two-dimensional acoustic transducer array.\\\",\\n    \\\"Each tiny pixel on the screen could both generate and receive ultrasound signals.\\\",\\n    \\\"That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\\",\\n    \\\"It could even show you which parts\", \"parsed\": {\"term\": \"preventive healthcare\", \"category\": \"anatomy\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide30.json",
        "parsed": {
          "triples": [
            {
              "s": "ultrasound probe",
              "p": "uses",
              "o": "commercial ultrasound probes",
              "modalities": [
                "text"
              ],
              "confidence": 0.0,
              "evidence": "Each one is designed for a different purpose - some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\nYou simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.\\n\\nOn this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\n\\nNow, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\n\\nJust imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\nYou could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.\\n\\nBy combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.\\n\\nThis might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"ultrasound probe\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"commercial ultrasound probes\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"ultrasound probe\", \"p\": \"uses\", \"o\": \"commercial ultrasound probes\", \"modalities\": [\"text\"], \"confidence\": 0.0, \"evidence\": \"Each one is designed for a different purpose - some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide30.json",
        "parsed": {
          "concepts": [
            {
              "term": "probe",
              "category": "instrumentation"
            },
            {
              "term": "transducer",
              "category": "instrumentation"
            },
            {
              "term": "ultrasound",
              "category": "modality"
            },
            {
              "term": "piezoelectric technology",
              "category": "instrumentation"
            },
            {
              "term": "two-dimensional acoustic transducer array",
              "category": "instrumentation"
            },
            {
              "term": "ultrasound waves",
              "category": "physics"
            },
            {
              "term": "AI software",
              "category": "ai_ml"
            },
            {
              "term": "machine learning",
              "category": "ai_ml"
            },
            {
              "term": "digital signal processing",
              "category": "signal_processing"
            }
          ],
          "evidence": [
            "You simply place this probe on top of the area you want to examine",
            "single-crystal transducer inside a handheld housing",
            "commercial ultrasound probes",
            "piezoelectric technology directly into the screen",
            "two-dimensional acoustic transducer array",
            "perform a quick body scan",
            "AI software inside would analyze the data",
            "machine learning",
            "digital signal processing"
          ]
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"probe\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"transducer\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"ultrasound\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"piezoelectric technology\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"two-dimensional acoustic transducer array\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"ultrasound waves\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"AI software\\\", \\\"category\\\": \\\"ai_ml\\\"},\\n    {\\\"term\\\": \\\"machine learning\\\", \\\"category\\\": \\\"ai_ml\\\"},\\n    {\\\"term\\\": \\\"digital signal processing\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"You simply place this probe on top of the area you want to examine\\\",\\n    \\\"single-crystal transducer inside a handheld housing\\\",\\n    \\\"commercial ultrasound probes\\\",\\n    \\\"piezoelectric technology directly into the screen\\\",\\n    \\\"two-dimensional acoustic transducer array\\\",\\n    \\\"perform a quick body scan\\\",\\n    \\\"AI software inside would analyze the data\\\",\\n    \\\"machine learning\\\",\\n    \\\"digital signal processing\\\"\\n  ]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"probe\", \"category\": \"instrumentation\"}, {\"term\": \"transducer\", \"category\": \"instrumentation\"}, {\"term\": \"ultrasound\", \"category\": \"modality\"}, {\"term\": \"piezoelectric technology\", \"category\": \"instrumentation\"}, {\"term\": \"two-dimensional acoustic transducer array\", \"category\": \"instrumentation\"}, {\"term\": \"ultrasound waves\", \"category\": \"physics\"}, {\"term\": \"AI software\", \"category\": \"ai_ml\"}, {\"term\": \"machine learning\", \"category\": \"ai_ml\"}, {\"term\": \"digital signal processing\", \"category\": \"signal_processing\"}], \"evidence\": [\"You simply place this probe on top of the area you want to examine\", \"single-crystal transducer inside a handheld housing\", \"commercial ultrasound probes\", \"piezoelectric technology directly into the screen\", \"two-dimensional acoustic transducer array\", \"perform a quick body scan\", \"AI software inside would analyze the data\", \"machine learning\", \"digital signal processing\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide30.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"commercial ultrasound probes\\\", \\\"p\\\":\\\"represents\\\", \\\"o\\\":\\\"different purposes\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"On this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose\\\"},\\n    {\\\"s\\\":\\\"iPhone\\\", \\\"p\\\":\\\"could incorporate\\\", \\\"o\\\":\\\"piezoelectric technology\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen\\\"},\\n    {\\\"s\\\":\\\"phone’s surface\\\", \\\"p\\\":\\\"could act as\\\", \\\"o\\\":\\\"two-dimensional acoustic transducer array\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Just imagine that the phone’s surface could act as a two-dimensional acoustic transducer array\\\"},\\n    {\\\"s\\\":\\\"AI software\\\", \\\"p\\\":\\\"analyzes\\\", \\\"o\\\":\\\"data\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"the AI software inside would analyze the data for you\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide30.json",
        "parsed": {
          "term": "futuristic",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T16:09:55.809049+00:00\", \"text_length\": 2016, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\nYou simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.\\n\\nOn this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\n\\nNow, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\n\\nJust imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\nYou could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.\\n\\nBy combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.\\n\\nThis might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"ultrasound probes\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"piezoelectric technology\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"machine learning\\\", \\\"category\\\": \\\"ai_ml\\\"},\\n    {\\\"term\\\": \\\"digital signal processing\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"personal, professional-level imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"preventive healthcare\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"ultrasound diagnostics\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"ordinary people\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"futuristic\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\\",\\n    \\\"I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\\",\\n    \\\"Just imagine that the phone’s surface could act as a two-dimensional acoustic transducer array.\", \"parsed\": {\"term\": \"futuristic\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide30.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T16:46:19.615584+00:00\", \"text_length\": 2016, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\nYou simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.\\n\\nOn this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\n\\nNow, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\n\\nJust imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\nYou could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.\\n\\nBy combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.\\n\\nThis might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"US Probes\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"ultrasound imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Each probe is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide30.json",
        "parsed": {
          "term": "reconstruction",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T14:14:10.622178+00:00\", \"text_length\": 2016, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\nYou simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.\\n\\nOn this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\n\\nNow, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\n\\nJust imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\nYou could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.\\n\\nBy combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.\\n\\nThis might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"single-crystal transducer\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"probe\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"transducer head\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"piezoelectric technology\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"two-dimensional acoustic transducer array\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"ultrasound waves\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"echoes\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"AI software\\\",\\n      \\\"category\\\": \\\"ai_ml\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"machine learning\\\",\\n      \\\"category\\\": \\\"ai_ml\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"digital signal processing\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"reconstruction\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"modality\\\",\\n      \\\"category\\\": \\\"modality\\\"\", \"parsed\": {\"term\": \"reconstruction\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 21\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide30.json",
        "parsed": {
          "s": "iPhone",
          "p": "represents",
          "o": "a device that could incorporate piezoelectric technology",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.9,
          "evidence": [
            "I believe that in the future, our everyday devices - maybe even the iPhone - could incorporate this kind of piezoelectric technology directly into the screen."
          ]
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T14:20:08.819016+00:00\", \"text_length\": 2016, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.\\nYou simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.\\n\\nOn this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.\\n\\nNow, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\n\\nJust imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.\\nYou could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.\\n\\nBy combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.\\n\\nThis might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"US Probes\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"commercial ultrasound probes\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"On this slide, you can see several examples of commercial ultrasound probes.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"iPhone\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"a device that could incorporate piezoelectric technology\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"phone’s surface\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"a two-dimensional acoustic transducer array\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.85,\\n      \\\"evidence\\\": \\\"Just imagine that the phone’s surface could act as a two\", \"parsed\": {\"s\": \"iPhone\", \"p\": \"represents\", \"o\": \"a device that could incorporate piezoelectric technology\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.9, \"evidence\": [\"I believe that in the future, our everyday devices - maybe even the iPhone - could incorporate this kind of piezoelectric technology directly into the screen.\"]}}"
      }
    }
  }
}