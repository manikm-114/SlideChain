{
  "lecture": "Lecture 14",
  "slide_id": "Slide44",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Images\\Slide44.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Texts\\Slide44.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide44.json",
        "parsed": {
          "term": "filtered backprojection",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe last topic I’m going to explain is motion artifacts. Imagine you have a phantom object, like this one, viewed at angle zero. The phantom has a taiji pattern, a yin-yang shape.\\nAs you slowly increase the projection angle, the X-ray source rotates around the phantom.\\nOver time, the data you collect changes. When the angle reaches 90 degrees, the phantom appears compressed, shrunk to a minimum in the projection.\\n\\nAs the source continues rotating, at 180 degrees, the phantom appears expanded again.\\nThis back-and-forth pattern creates a sinusoidal oscillation in the data.\\nThis example illustrates what happens when the object isn’t stationary, but moves periodically.\\nYou gather projection data while the object moves according to this periodic motion.\\nIf you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\n\\nHowever, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms.\\nWith this additional information, it is possible to recover accurate images despite motion.\\nTomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\nDue to time constraints in this lecture, we won’t delve deeply into motion artifact correction algorithms.\\nFor cardiac imaging, one way to reduce motion artifacts is through hardware: performing ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\n\\nThis instantaneous imaging “freezes” the cardiac structure, minimizing motion blur.\\nAnother way is through smart computational algorithms that predict motion and correct for it during reconstruction.\\nOften, cardiac CT patients are given beta blockers to slow the heart rate, reducing motion during scanning.\\nAdditionally, CT acquisition can be synchronized with the ECG signal, coupling image data with specific cardiac phases.\\nThe ECG indicates when the heart is largest or smallest. You can select data segments corresponding to the heart’s maximum volume and reconstruct images at that phase.\\n\\nSimilarly, you regroup data segments for the minimum volume phase and reconstruct images accordingly.\\nThis approach allows reconstruction of a beating heart in different cardiac phases.\\nThis gives a rough idea of how motion artifacts are managed in dynamic organ imaging.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"motion artifacts\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"phantom\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"X-ray source\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"projection angle\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"sinusoidal oscillation\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\", \"parsed\": {\"term\": \"filtered backprojection\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide44.json",
        "parsed": {
          "triples": [
            {
              "s": "phantom",
              "p": "represents",
              "o": "taiji pattern",
              "modalities": [
                "text"
              ],
              "confidence": 0.0,
              "evidence": "The phantom has a taiji pattern, a yin-yang shape."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe last topic I’m going to explain is motion artifacts. Imagine you have a phantom object, like this one, viewed at angle zero. The phantom has a taiji pattern, a yin-yang shape.\\nAs you slowly increase the projection angle, the X-ray source rotates around the phantom.\\nOver time, the data you collect changes. When the angle reaches 90 degrees, the phantom appears compressed, shrunk to a minimum in the projection.\\n\\nAs the source continues rotating, at 180 degrees, the phantom appears expanded again.\\nThis back-and-forth pattern creates a sinusoidal oscillation in the data.\\nThis example illustrates what happens when the object isn’t stationary, but moves periodically.\\nYou gather projection data while the object moves according to this periodic motion.\\nIf you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\n\\nHowever, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms.\\nWith this additional information, it is possible to recover accurate images despite motion.\\nTomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\nDue to time constraints in this lecture, we won’t delve deeply into motion artifact correction algorithms.\\nFor cardiac imaging, one way to reduce motion artifacts is through hardware: performing ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\n\\nThis instantaneous imaging “freezes” the cardiac structure, minimizing motion blur.\\nAnother way is through smart computational algorithms that predict motion and correct for it during reconstruction.\\nOften, cardiac CT patients are given beta blockers to slow the heart rate, reducing motion during scanning.\\nAdditionally, CT acquisition can be synchronized with the ECG signal, coupling image data with specific cardiac phases.\\nThe ECG indicates when the heart is largest or smallest. You can select data segments corresponding to the heart’s maximum volume and reconstruct images at that phase.\\n\\nSimilarly, you regroup data segments for the minimum volume phase and reconstruct images accordingly.\\nThis approach allows reconstruction of a beating heart in different cardiac phases.\\nThis gives a rough idea of how motion artifacts are managed in dynamic organ imaging.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"phantom\\\", \\\"p\\\":\\\"represents\\\", \\\"o\\\":\\\"taiji pattern\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The phantom has a taiji pattern, a yin-yang shape.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"phantom\", \"p\": \"represents\", \"o\": \"taiji pattern\", \"modalities\": [\"text\"], \"confidence\": 0.0, \"evidence\": \"The phantom has a taiji pattern, a yin-yang shape.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide44.json",
        "parsed": {
          "term": "algorithm",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"motion artifacts\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"filtered backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"iterative reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"sinusoidal oscillation\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"projection data\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"cardiac imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"beta blockers\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"ECG signal\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"tomographic reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"ultra-fast scanning\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"hardware\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"algorithm\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"blurring or distortion caused by the object’s movement during acquisition\\\",\\n    \\\"apply filtered backprojection to reconstruct images from this data\\\",\\n    \\\"iterative reconstruction algorithms\\\",\\n    \\\"sinusoidal oscillation in the data\\\",\\n    \\\"projection data\\\",\", \"parsed\": {\"term\": \"algorithm\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide44.json",
        "parsed": {
          "triples": [
            {
              "s": "Filtered Backprojection",
              "p": "produces",
              "o": "motion artifacts",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "If you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts"
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Filtered Backprojection\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"motion artifacts\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"If you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Iterative Reconstruction with Known Motion Pattern\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"accurate images\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms. With this additional information, it is possible to recover accurate images despite motion\\\"\\n    }\\n  ]\\n}\\n```\", \"parsed\": {\"triples\": [{\"s\": \"Filtered Backprojection\", \"p\": \"produces\", \"o\": \"motion artifacts\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"If you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide44.json",
        "parsed": {
          "concepts": [
            {
              "term": "Motion Artifacts",
              "category": "reconstruction"
            },
            {
              "term": "Filtered Backprojection",
              "category": "reconstruction"
            }
          ],
          "evidence": [
            "Filtered Backprojection",
            "Iterative Reconstruction with Known Motion Pattern",
            "Time-varying Phantom",
            "Motion Artifacts Come from Model Mismatch",
            "An Underlying Structure Keeps Changing While Data Are Collected",
            "The Motion Pattern Can be Taken into Account for Accurate Reconstruction"
          ]
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:59:07.631779+00:00\", \"text_length\": 2466, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe last topic I’m going to explain is motion artifacts. Imagine you have a phantom object, like this one, viewed at angle zero. The phantom has a taiji pattern, a yin-yang shape.\\nAs you slowly increase the projection angle, the X-ray source rotates around the phantom.\\nOver time, the data you collect changes. When the angle reaches 90 degrees, the phantom appears compressed, shrunk to a minimum in the projection.\\n\\nAs the source continues rotating, at 180 degrees, the phantom appears expanded again.\\nThis back-and-forth pattern creates a sinusoidal oscillation in the data.\\nThis example illustrates what happens when the object isn’t stationary, but moves periodically.\\nYou gather projection data while the object moves according to this periodic motion.\\nIf you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\n\\nHowever, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms.\\nWith this additional information, it is possible to recover accurate images despite motion.\\nTomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\nDue to time constraints in this lecture, we won’t delve deeply into motion artifact correction algorithms.\\nFor cardiac imaging, one way to reduce motion artifacts is through hardware: performing ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\n\\nThis instantaneous imaging “freezes” the cardiac structure, minimizing motion blur.\\nAnother way is through smart computational algorithms that predict motion and correct for it during reconstruction.\\nOften, cardiac CT patients are given beta blockers to slow the heart rate, reducing motion during scanning.\\nAdditionally, CT acquisition can be synchronized with the ECG signal, coupling image data with specific cardiac phases.\\nThe ECG indicates when the heart is largest or smallest. You can select data segments corresponding to the heart’s maximum volume and reconstruct images at that phase.\\n\\nSimilarly, you regroup data segments for the minimum volume phase and reconstruct images accordingly.\\nThis approach allows reconstruction of a beating heart in different cardiac phases.\\nThis gives a rough idea of how motion artifacts are managed in dynamic organ imaging.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Motion Artifacts\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Filtered Backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Iterative Reconstruction with Known Motion Pattern\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Time-varying Phantom\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Motion Artifacts Come from Model Mismatch\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"An Underlying Structure Keeps Changing While Data Are Collected\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"The Motion Pattern Can be Taken into Account for Accurate Reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Filtered Backprojection\\\",\\n    \\\"Iterative Reconstruction with Known Motion Pattern\\\",\\n    \\\"Time-varying Phantom\\\",\\n    \\\"Motion Artifacts Come from Model Mismatch\\\",\\n    \\\"An Underlying Structure Keeps Changing While Data Are Collected\\\",\\n    \\\"The Motion Pattern Can be Taken into Account for Accurate Reconstruction\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"Motion Artifacts\", \"category\": \"reconstruction\"}, {\"term\": \"Filtered Backprojection\", \"category\": \"reconstruction\"}], \"evidence\": [\"Filtered Backprojection\", \"Iterative Reconstruction with Known Motion Pattern\", \"Time-varying Phantom\", \"Motion Artifacts Come from Model Mismatch\", \"An Underlying Structure Keeps Changing While Data Are Collected\", \"The Motion Pattern Can be Taken into Account for Accurate Reconstruction\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide44.json",
        "parsed": {
          "triples": [
            {
              "s": "Filtered Backprojection",
              "p": "produces",
              "o": "Motion Artifacts",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 0.0,
              "evidence": "Filtered Backprojection creates motion artifacts when applied to data with motion artifacts."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T09:54:44.663072+00:00\", \"text_length\": 2466, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe last topic I’m going to explain is motion artifacts. Imagine you have a phantom object, like this one, viewed at angle zero. The phantom has a taiji pattern, a yin-yang shape.\\nAs you slowly increase the projection angle, the X-ray source rotates around the phantom.\\nOver time, the data you collect changes. When the angle reaches 90 degrees, the phantom appears compressed, shrunk to a minimum in the projection.\\n\\nAs the source continues rotating, at 180 degrees, the phantom appears expanded again.\\nThis back-and-forth pattern creates a sinusoidal oscillation in the data.\\nThis example illustrates what happens when the object isn’t stationary, but moves periodically.\\nYou gather projection data while the object moves according to this periodic motion.\\nIf you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\n\\nHowever, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms.\\nWith this additional information, it is possible to recover accurate images despite motion.\\nTomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\nDue to time constraints in this lecture, we won’t delve deeply into motion artifact correction algorithms.\\nFor cardiac imaging, one way to reduce motion artifacts is through hardware: performing ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\n\\nThis instantaneous imaging “freezes” the cardiac structure, minimizing motion blur.\\nAnother way is through smart computational algorithms that predict motion and correct for it during reconstruction.\\nOften, cardiac CT patients are given beta blockers to slow the heart rate, reducing motion during scanning.\\nAdditionally, CT acquisition can be synchronized with the ECG signal, coupling image data with specific cardiac phases.\\nThe ECG indicates when the heart is largest or smallest. You can select data segments corresponding to the heart’s maximum volume and reconstruct images at that phase.\\n\\nSimilarly, you regroup data segments for the minimum volume phase and reconstruct images accordingly.\\nThis approach allows reconstruction of a beating heart in different cardiac phases.\\nThis gives a rough idea of how motion artifacts are managed in dynamic organ imaging.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Filtered Backprojection\\\", \\\"p\\\":\\\"produces\\\",\\n     \\\"o\\\":\\\"Motion Artifacts\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Filtered Backprojection creates motion artifacts when applied to data with motion artifacts.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"Filtered Backprojection\", \"p\": \"produces\", \"o\": \"Motion Artifacts\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.0, \"evidence\": \"Filtered Backprojection creates motion artifacts when applied to data with motion artifacts.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide44.json",
        "parsed": {
          "term": "smart computational algorithms that predict motion and correct for it during reconstruction.",
          "category": "data_processing"
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T07:35:17.823818+00:00\", \"text_length\": 2466, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe last topic I’m going to explain is motion artifacts. Imagine you have a phantom object, like this one, viewed at angle zero. The phantom has a taiji pattern, a yin-yang shape.\\nAs you slowly increase the projection angle, the X-ray source rotates around the phantom.\\nOver time, the data you collect changes. When the angle reaches 90 degrees, the phantom appears compressed, shrunk to a minimum in the projection.\\n\\nAs the source continues rotating, at 180 degrees, the phantom appears expanded again.\\nThis back-and-forth pattern creates a sinusoidal oscillation in the data.\\nThis example illustrates what happens when the object isn’t stationary, but moves periodically.\\nYou gather projection data while the object moves according to this periodic motion.\\nIf you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\n\\nHowever, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms.\\nWith this additional information, it is possible to recover accurate images despite motion.\\nTomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\nDue to time constraints in this lecture, we won’t delve deeply into motion artifact correction algorithms.\\nFor cardiac imaging, one way to reduce motion artifacts is through hardware: performing ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\n\\nThis instantaneous imaging “freezes” the cardiac structure, minimizing motion blur.\\nAnother way is through smart computational algorithms that predict motion and correct for it during reconstruction.\\nOften, cardiac CT patients are given beta blockers to slow the heart rate, reducing motion during scanning.\\nAdditionally, CT acquisition can be synchronized with the ECG signal, coupling image data with specific cardiac phases.\\nThe ECG indicates when the heart is largest or smallest. You can select data segments corresponding to the heart’s maximum volume and reconstruct images at that phase.\\n\\nSimilarly, you regroup data segments for the minimum volume phase and reconstruct images accordingly.\\nThis approach allows reconstruction of a beating heart in different cardiac phases.\\nThis gives a rough idea of how motion artifacts are managed in dynamic organ imaging.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Motion Artifacts Come from Model Mismatch.\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"An Underlying Structure Keeps Changing While Data Are Collected.\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"The Motion Pattern Can be Taken into Account for Accurate Reconstruction!\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Filtered Backprojection\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Iterative Reconstruction with Known Motion Pattern\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Tomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"smart computational algorithms that predict motion and correct for it during reconstruction.\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"beta blockers to slow the heart rate, reducing\", \"parsed\": {\"term\": \"smart computational algorithms that predict motion and correct for it during reconstruction.\", \"category\": \"data_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide44.json",
        "parsed": {
          "s": "Iterative Reconstruction with Known Motion Pattern",
          "p": "reconstructs_with",
          "o": "accurate images",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.95,
          "evidence": [
            "However, if you know the object's motion trajectory, you can incorporate that information into iterative reconstruction algorithms. With this additional information, it is possible to recover accurate images despite motion."
          ]
        },
        "raw": "{\"slide_id\": \"Slide44\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T07:41:23.498462+00:00\", \"text_length\": 2466, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe last topic I’m going to explain is motion artifacts. Imagine you have a phantom object, like this one, viewed at angle zero. The phantom has a taiji pattern, a yin-yang shape.\\nAs you slowly increase the projection angle, the X-ray source rotates around the phantom.\\nOver time, the data you collect changes. When the angle reaches 90 degrees, the phantom appears compressed, shrunk to a minimum in the projection.\\n\\nAs the source continues rotating, at 180 degrees, the phantom appears expanded again.\\nThis back-and-forth pattern creates a sinusoidal oscillation in the data.\\nThis example illustrates what happens when the object isn’t stationary, but moves periodically.\\nYou gather projection data while the object moves according to this periodic motion.\\nIf you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\n\\nHowever, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms.\\nWith this additional information, it is possible to recover accurate images despite motion.\\nTomographic reconstruction remains feasible, provided you have either explicit knowledge of motion or use algorithms that infer motion implicitly.\\nDue to time constraints in this lecture, we won’t delve deeply into motion artifact correction algorithms.\\nFor cardiac imaging, one way to reduce motion artifacts is through hardware: performing ultra-fast scanning so the heart doesn’t have significant motion during image acquisition.\\n\\nThis instantaneous imaging “freezes” the cardiac structure, minimizing motion blur.\\nAnother way is through smart computational algorithms that predict motion and correct for it during reconstruction.\\nOften, cardiac CT patients are given beta blockers to slow the heart rate, reducing motion during scanning.\\nAdditionally, CT acquisition can be synchronized with the ECG signal, coupling image data with specific cardiac phases.\\nThe ECG indicates when the heart is largest or smallest. You can select data segments corresponding to the heart’s maximum volume and reconstruct images at that phase.\\n\\nSimilarly, you regroup data segments for the minimum volume phase and reconstruct images accordingly.\\nThis approach allows reconstruction of a beating heart in different cardiac phases.\\nThis gives a rough idea of how motion artifacts are managed in dynamic organ imaging.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Filtered Backprojection\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"motion artifacts\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"If you then apply filtered backprojection to reconstruct images from this data, you get motion artifacts—blurring or distortion caused by the object’s movement during acquisition.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Iterative Reconstruction with Known Motion Pattern\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"accurate images\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"However, if you know the object’s motion trajectory, you can incorporate that information into iterative reconstruction algorithms. With this additional information, it is possible to recover accurate images despite motion.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"ultra-fast scanning\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"hardware\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"For cardiac imaging, one way to reduce motion artifacts is through hardware\", \"parsed\": {\"s\": \"Iterative Reconstruction with Known Motion Pattern\", \"p\": \"reconstructs_with\", \"o\": \"accurate images\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.95, \"evidence\": [\"However, if you know the object's motion trajectory, you can incorporate that information into iterative reconstruction algorithms. With this additional information, it is possible to recover accurate images despite motion.\"]}}"
      }
    }
  }
}