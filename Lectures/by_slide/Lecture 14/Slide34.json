{
  "lecture": "Lecture 14",
  "slide_id": "Slide34",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Images\\Slide34.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Texts\\Slide34.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide34.json",
        "parsed": {
          "term": "clip",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nDifferent body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\n\\nFor instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\nThe human eye can typically distinguish about 50 shades within a window.\\nIf too many shades are presented, subtle differences become difficult to see.\\n\\nFor lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\nWithin this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\nThis windowing is critical to tailoring visualization to different clinical needs.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"CT number windows\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"gray levels\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Hounsfield units\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"window maximum\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"window minimum\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"clipped\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visualization\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"clinical needs\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"50 shades\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"256 grayscale levels\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"white to black\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"subtle differences\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"clip\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Different body regions use different CT number windows for display.\\\", \\n               \\\"The human eye can typically distinguish about 50 shades within a window.\\\", \\n               \\\"If too many shades are\", \"parsed\": {\"term\": \"clip\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide34.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nDifferent body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\n\\nFor instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\nThe human eye can typically distinguish about 50 shades within a window.\\nIf too many shades are presented, subtle differences become difficult to see.\\n\\nFor lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\nWithin this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\nThis windowing is critical to tailoring visualization to different clinical needs.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"CT number windows\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"display\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide34.json",
        "parsed": {
          "concepts": [
            {
              "term": "CT number windows",
              "category": "modality"
            },
            {
              "term": "Hounsfield units",
              "category": "physics"
            },
            {
              "term": "gray levels",
              "category": "signal_processing"
            },
            {
              "term": "windowing",
              "category": "data_processing"
            },
            {
              "term": "lung imaging",
              "category": "anatomy"
            },
            {
              "term": "clinical needs",
              "category": "workflow"
            }
          ],
          "evidence": [
            "Different body regions use different CT number windows for display.",
            "The full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.",
            "For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.",
            "This windowing is critical to tailoring visualization to different clinical needs."
          ]
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"CT number windows\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Hounsfield units\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"gray levels\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"windowing\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"lung imaging\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"clinical needs\\\", \\\"category\\\": \\\"workflow\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Different body regions use different CT number windows for display.\\\",\\n    \\\"The full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\\",\\n    \\\"For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\\",\\n    \\\"This windowing is critical to tailoring visualization to different clinical needs.\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"CT number windows\", \"category\": \"modality\"}, {\"term\": \"Hounsfield units\", \"category\": \"physics\"}, {\"term\": \"gray levels\", \"category\": \"signal_processing\"}, {\"term\": \"windowing\", \"category\": \"data_processing\"}, {\"term\": \"lung imaging\", \"category\": \"anatomy\"}, {\"term\": \"clinical needs\", \"category\": \"workflow\"}], \"evidence\": [\"Different body regions use different CT number windows for display.\", \"The full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\", \"For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\", \"This windowing is critical to tailoring visualization to different clinical needs.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide34.json",
        "parsed": {
          "triples": [
            {
              "s": "CT number windows",
              "p": "depends_on",
              "o": "manufacturer or clinical application",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "Different body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"lung imaging\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"window maximum of about 250 Hounsfield units\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\\"},\\n    {\\\"s\\\":\\\"CT number windows\\\", \\\"p\\\":\\\"depends_on\\\", \\\"o\\\":\\\"manufacturer or clinical application\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Different body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"CT number windows\", \"p\": \"depends_on\", \"o\": \"manufacturer or clinical application\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"Different body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide34.json",
        "parsed": {
          "term": "visualization",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:40:17.645882+00:00\", \"text_length\": 794, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nDifferent body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\n\\nFor instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\nThe human eye can typically distinguish about 50 shades within a window.\\nIf too many shades are presented, subtle differences become difficult to see.\\n\\nFor lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\nWithin this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\nThis windowing is critical to tailoring visualization to different clinical needs.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"CT number window\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"CT number\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"grayscale levels\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"human eye\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"windowing\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Hounsfield units\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"clinical needs\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visualization\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"tailoring\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"lung imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"air value\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"clip\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"critical\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"clinical needs\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"tailoring\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visualization\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"render\\\", \\\"category\", \"parsed\": {\"term\": \"visualization\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide34.json",
        "parsed": {
          "triples": [
            {
              "s": "CT number window",
              "p": "uses",
              "o": "human eye",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 0.0,
              "evidence": "The human eye can typically distinguish about 50 shades within a window."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T09:48:21.812093+00:00\", \"text_length\": 794, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nDifferent body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\n\\nFor instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\nThe human eye can typically distinguish about 50 shades within a window.\\nIf too many shades are presented, subtle differences become difficult to see.\\n\\nFor lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\nWithin this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\nThis windowing is critical to tailoring visualization to different clinical needs.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"CT number window\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"human eye\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The human eye can typically distinguish about 50 shades within a window.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"CT number window\", \"p\": \"uses\", \"o\": \"human eye\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.0, \"evidence\": \"The human eye can typically distinguish about 50 shades within a window.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide34.json",
        "parsed": {
          "term": "For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T07:33:36.816868+00:00\", \"text_length\": 794, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nDifferent body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\n\\nFor instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\nThe human eye can typically distinguish about 50 shades within a window.\\nIf too many shades are presented, subtle differences become difficult to see.\\n\\nFor lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\nWithin this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\nThis windowing is critical to tailoring visualization to different clinical needs.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Different body regions use different CT number windows for display.\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"For instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"The human eye can typically distinguish about 50 shades within a window.\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"If too many shades are presented, subtle differences become difficult to see.\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Within this window, 256 gray levels help render tissues clearly.\\\",\\n      \\\"category\\\": \\\"data_processing\", \"parsed\": {\"term\": \"For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 14\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide34.json",
        "parsed": {
          "s": "bone window",
          "p": "uses",
          "o": "C/W 1000, 2500",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.9,
          "evidence": [
            "bone window C/W 1000, 2500"
          ]
        },
        "raw": "{\"slide_id\": \"Slide34\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T07:40:12.466578+00:00\", \"text_length\": 794, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nDifferent body regions use different CT number windows for display. These windows are defined by minimum and maximum CT numbers, depending on the manufacturer or clinical application.\\n\\nFor instance, the full range of CT numbers might be mapped to 256 grayscale levels on a display, from white to black.\\nThe human eye can typically distinguish about 50 shades within a window.\\nIf too many shades are presented, subtle differences become difficult to see.\\n\\nFor lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value.\\nWithin this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\nThis windowing is critical to tailoring visualization to different clinical needs.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"lung window\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"C/W -600, 1700\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"For lung imaging, for example, you might set the window maximum to about 250 Hounsfield units and the minimum to the air value. Within this window, 256 gray levels help render tissues clearly. Anything outside the window appears clipped and is not visible.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"bone window\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"C/W 1000, 2500\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"bone window C/W 1000, 2500\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"mediastinal window\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"C/W -50, 400\\\",\\n      \\\"modalities\", \"parsed\": {\"s\": \"bone window\", \"p\": \"uses\", \"o\": \"C/W 1000, 2500\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.9, \"evidence\": [\"bone window C/W 1000, 2500\"]}}"
      }
    }
  }
}