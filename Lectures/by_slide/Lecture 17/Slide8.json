{
  "lecture": "Lecture 17",
  "slide_id": "Slide8",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Images\\Slide8.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Texts\\Slide8.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide8.json",
        "parsed": {
          "term": "n is very big",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake. And say you're a toaster coin, and it's a certain probability P, and you see one result. And the other possibility will be Q. Q equals 1 minus P.\\n\\nSo you keep doing multiple experiments. And you know how many times you see high, how many times you see tails, this is a good model. And like the example shown here, if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you can use by nominal formula. Basically, something like a toast coin. And the probability for you to see one side may not be exactly half. And in general, you can call it P and Q, Q equal to 1 minus P. And the personal distribution is derived from this binomial distribution. One, the number n is very big.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"binomial distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"nominal formula\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"events\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"series\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability stake\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"toaster coin\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"P and Q\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"personal distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"binomial distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"n is very big\\\", \\\"category\\\": \\\"mathematics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"And by nominal formula, basically, you have a series of events.\\\", \\n               \\\"And for an easy event, it's a probability stake.\\\", \\n               \\\"And say you're a toaster coin, and it's a certain probability P, and you see one result.\\\", \\n               \\\"And the other possibility will be Q. Q equals 1\", \"parsed\": {\"term\": \"n is very big\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide8.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake. And say you're a toaster coin, and it's a certain probability P, and you see one result. And the other possibility will be Q. Q equals 1 minus P.\\n\\nSo you keep doing multiple experiments. And you know how many times you see high, how many times you see tails, this is a good model. And like the example shown here, if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you can use by nominal formula. Basically, something like a toast coin. And the probability for you to see one side may not be exactly half. And in general, you can call it P and Q, Q equal to 1 minus P. And the personal distribution is derived from this binomial distribution. One, the number n is very big.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"probability\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"stochastic event\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"And by nominal formula, basically, you have a series of events.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide8.json",
        "parsed": {
          "concepts": [
            {
              "term": "nominal formula",
              "category": "mathematics"
            },
            {
              "term": "probability stake",
              "category": "mathematics"
            },
            {
              "term": "probability P",
              "category": "mathematics"
            },
            {
              "term": "binomial distribution",
              "category": "mathematics"
            },
            {
              "term": "number n",
              "category": "mathematics"
            }
          ],
          "evidence": [
            "nominal formula",
            "probability stake",
            "probability P",
            "Q equals 1 minus P",
            "binomial distribution",
            "number n"
          ]
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"nominal formula\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability stake\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability P\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability Q\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"binomial distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"number n\\\", \\\"category\\\": \\\"mathematics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"nominal formula\\\",\\n    \\\"probability stake\\\",\\n    \\\"probability P\\\",\\n    \\\"Q equals 1 minus P\\\",\\n    \\\"binomial distribution\\\",\\n    \\\"number n\\\"\\n  ]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"nominal formula\", \"category\": \"mathematics\"}, {\"term\": \"probability stake\", \"category\": \"mathematics\"}, {\"term\": \"probability P\", \"category\": \"mathematics\"}, {\"term\": \"binomial distribution\", \"category\": \"mathematics\"}, {\"term\": \"number n\", \"category\": \"mathematics\"}], \"evidence\": [\"nominal formula\", \"probability stake\", \"probability P\", \"Q equals 1 minus P\", \"binomial distribution\", \"number n\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide8.json",
        "parsed": {
          "s": "nominal formula",
          "p": "represents",
          "o": "toast coin",
          "modalities": [
            "text"
          ],
          "confidence": 0.9,
          "evidence": [
            "And say you're a toaster coin, and it's a certain probability P, and you see one result."
          ]
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"nominal formula\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"probability stake\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"And by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"nominal formula\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"toast coin\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"And say you're a toaster coin, and it's a certain probability P, and you see one result.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"nominal formula\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"defective rate\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you\", \"parsed\": {\"s\": \"nominal formula\", \"p\": \"represents\", \"o\": \"toast coin\", \"modalities\": [\"text\"], \"confidence\": 0.9, \"evidence\": [\"And say you're a toaster coin, and it's a certain probability P, and you see one result.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide8.json",
        "parsed": {
          "term": "probability of purchasing a defective computer",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-12T19:35:45.143931+00:00\", \"text_length\": 904, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake. And say you're a toaster coin, and it's a certain probability P, and you see one result. And the other possibility will be Q. Q equals 1 minus P.\\n\\nSo you keep doing multiple experiments. And you know how many times you see high, how many times you see tails, this is a good model. And like the example shown here, if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you can use by nominal formula. Basically, something like a toast coin. And the probability for you to see one side may not be exactly half. And in general, you can call it P and Q, Q equal to 1 minus P. And the personal distribution is derived from this binomial distribution. One, the number n is very big.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"binomial probability model\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"number of trials\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability of success\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability of failure\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"successes in n trials\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"P(X=k)\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C(n, k)\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"p^k\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"q^(n-k)\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"μ = np\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"σ = √npq\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"binomial distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"nominal formula\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability of purchasing a defective computer\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"probability of purchasing 2 defective computers in a\", \"parsed\": {\"term\": \"probability of purchasing a defective computer\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide8.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T12:08:37.201410+00:00\", \"text_length\": 904, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake. And say you're a toaster coin, and it's a certain probability P, and you see one result. And the other possibility will be Q. Q equals 1 minus P.\\n\\nSo you keep doing multiple experiments. And you know how many times you see high, how many times you see tails, this is a good model. And like the example shown here, if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you can use by nominal formula. Basically, something like a toast coin. And the probability for you to see one side may not be exactly half. And in general, you can call it P and Q, Q equal to 1 minus P. And the personal distribution is derived from this binomial distribution. One, the number n is very big.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide8.json",
        "parsed": {
          "term": "number n is very big",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-12T19:07:57.659550+00:00\", \"text_length\": 904, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake. And say you're a toaster coin, and it's a certain probability P, and you see one result. And the other possibility will be Q. Q equals 1 minus P.\\n\\nSo you keep doing multiple experiments. And you know how many times you see high, how many times you see tails, this is a good model. And like the example shown here, if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you can use by nominal formula. Basically, something like a toast coin. And the probability for you to see one side may not be exactly half. And in general, you can call it P and Q, Q equal to 1 minus P. And the personal distribution is derived from this binomial distribution. One, the number n is very big.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"binomial formula\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"series of events\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"probability stake\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"toaster coin\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"probability P\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Q equals 1 minus P\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"multiple experiments\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"personal distribution\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"number n is very big\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"by nominal formula, basically, you have a series of events.\\\",\\n    \\\"And for an easy event, it's a probability stake.\\\",\\n    \\\"And say you're a toaster coin, and it's a certain probability P, and you see one\", \"parsed\": {\"term\": \"number n is very big\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide8.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide8\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-12T19:16:02.341771+00:00\", \"text_length\": 904, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd by nominal formula, basically, you have a series of events. And for an easy event, it's a probability stake. And say you're a toaster coin, and it's a certain probability P, and you see one result. And the other possibility will be Q. Q equals 1 minus P.\\n\\nSo you keep doing multiple experiments. And you know how many times you see high, how many times you see tails, this is a good model. And like the example shown here, if you purchase 10 computers. And individually, you know the defective rate is 2%. If you buy 10 computers in a row, what's the chance you get to buy the computer, then you can use by nominal formula. Basically, something like a toast coin. And the probability for you to see one side may not be exactly half. And in general, you can call it P and Q, Q equal to 1 minus P. And the personal distribution is derived from this binomial distribution. One, the number n is very big.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}