{
  "lecture": "Lecture 17",
  "slide_id": "Slide23",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Images\\Slide23.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Texts\\Slide23.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide23.json",
        "parsed": {
          "term": "iterative",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nWe begin with the idea that each gamma ray measurement is modeled independently. The underlying framework is a plasma model. Consider an image made up of pixels. Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another. To capture this mathematically, we partition time into small intervals—for example, 10 milliseconds each. One interval, the next interval, and another further away all behave independently. This independence is crucial because it allows us to express the probability of the entire measurement as the product of many small probabilities. Each detector, each pixel, each time interval contributes its own probability, and multiplying them together gives the overall likelihood.\\n\\nThis setup naturally leads to probabilistic modeling. Bayes’ rule, which many of us first learned in high school, becomes central here. Imagine a patient comes in, and we perform data acquisition using a camera or a PET scanner. The raw measurements are then organized into sinograms in 2D or 3D. To understand error and uncertainty, we rely on the power of mathematical notation, which is both compact and expressive. In fact, the measured counts can be modeled as random variables following a Poisson distribution. The problem can then be phrased as: given the measured data, what is the most likely underlying image, denoted by capital lambda (Λ)?\\nThis probability depends on several factors. First, assume the true image is known, along with the source distribution and any background activity. If we also know the imaging geometry, then we can predict what each detector should record. For example, a detector may be expected to receive around 3,000 gamma photons during a five-minute scan. The difficulty is that in reality, the image is not known—we only have the measured data. That’s why we must also consider prior knowledge about the image distribution. For younger patients without cancer, we may expect little to no radioactive uptake in major organs. For older patients, there may be a higher probability of uptake, for instance, in the colon if there is a tumor. These expectations form a prior distribution on the image.\\n\\nHowever, in many cases, especially when data is scarce, we may not want to assume anything specific. In that case, we take the prior distribution to be uniform, meaning every image is equally likely. This constant prior does not affect the statistical estimation, since it cancels out in maximization.\\nFrom here, two key concepts arise: maximum a posteriori (MAP) estimation and maximum likelihood (ML) estimation. MAP seeks the image that maximizes the posterior probability, combining both the likelihood of the measured data given the image and the prior probability of the image itself. If we assume the prior is uniform, MAP reduces to maximum likelihood estimation. In ML, we search for the image that makes the measured data most probable.\\n\\nThe process is iterative: we try candidate images, compute the probability that they would have produced the measured data, and adjust until we find one with the highest probability. That image is then reported as our reconstruction. In summary, if the prior distribution is non-informative, MAP and ML give the same result. Otherwise, MAP incorporates prior knowledge to guide the estimation.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"gamma ray measurement\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"plasma model\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"image made up of pixels\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"independent\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"partition time into small intervals\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Bayes’ rule\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"sinograms\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"measured counts\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"random variables\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"most likely underlying image\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"prior knowledge\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"uniform prior\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"maximum a posteriori (MAP) estimation\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"maximum likelihood (ML) estimation\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"iterative\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\", \"parsed\": {\"term\": \"iterative\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide23.json",
        "parsed": {
          "triples": [
            {
              "s": "gamma ray measurement",
              "p": "measures",
              "o": "image",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 0.0,
              "evidence": "Each pixel, along with its neighbors, contributes independently-meaning the measurement at one pixel does not directly depend on another."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nWe begin with the idea that each gamma ray measurement is modeled independently. The underlying framework is a plasma model. Consider an image made up of pixels. Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another. To capture this mathematically, we partition time into small intervals—for example, 10 milliseconds each. One interval, the next interval, and another further away all behave independently. This independence is crucial because it allows us to express the probability of the entire measurement as the product of many small probabilities. Each detector, each pixel, each time interval contributes its own probability, and multiplying them together gives the overall likelihood.\\n\\nThis setup naturally leads to probabilistic modeling. Bayes’ rule, which many of us first learned in high school, becomes central here. Imagine a patient comes in, and we perform data acquisition using a camera or a PET scanner. The raw measurements are then organized into sinograms in 2D or 3D. To understand error and uncertainty, we rely on the power of mathematical notation, which is both compact and expressive. In fact, the measured counts can be modeled as random variables following a Poisson distribution. The problem can then be phrased as: given the measured data, what is the most likely underlying image, denoted by capital lambda (Λ)?\\nThis probability depends on several factors. First, assume the true image is known, along with the source distribution and any background activity. If we also know the imaging geometry, then we can predict what each detector should record. For example, a detector may be expected to receive around 3,000 gamma photons during a five-minute scan. The difficulty is that in reality, the image is not known—we only have the measured data. That’s why we must also consider prior knowledge about the image distribution. For younger patients without cancer, we may expect little to no radioactive uptake in major organs. For older patients, there may be a higher probability of uptake, for instance, in the colon if there is a tumor. These expectations form a prior distribution on the image.\\n\\nHowever, in many cases, especially when data is scarce, we may not want to assume anything specific. In that case, we take the prior distribution to be uniform, meaning every image is equally likely. This constant prior does not affect the statistical estimation, since it cancels out in maximization.\\nFrom here, two key concepts arise: maximum a posteriori (MAP) estimation and maximum likelihood (ML) estimation. MAP seeks the image that maximizes the posterior probability, combining both the likelihood of the measured data given the image and the prior probability of the image itself. If we assume the prior is uniform, MAP reduces to maximum likelihood estimation. In ML, we search for the image that makes the measured data most probable.\\n\\nThe process is iterative: we try candidate images, compute the probability that they would have produced the measured data, and adjust until we find one with the highest probability. That image is then reported as our reconstruction. In summary, if the prior distribution is non-informative, MAP and ML give the same result. Otherwise, MAP incorporates prior knowledge to guide the estimation.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"gamma ray measurement\\\", \\\"p\\\":\\\"measures\\\",\\n     \\\"o\\\":\\\"image\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"gamma ray measurement\", \"p\": \"measures\", \"o\": \"image\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.0, \"evidence\": \"Each pixel, along with its neighbors, contributes independently-meaning the measurement at one pixel does not directly depend on another.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide23.json",
        "parsed": {
          "term": "Likelihood",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Bayes’ rule\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Maximum a-posteriori Probability (MAP)\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Maximum Likelihood (ML) Estimation\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Poisson distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Prior distribution\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Iterative process\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Uniform prior\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Candidate images\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Measured data\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"Gamma ray measurement\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Plasma model\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Independence\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Probability\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Likelihood\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Detector\\\", \\\"category\\\": \\\"\", \"parsed\": {\"term\": \"Likelihood\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide23.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Bayesian Approach\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"Bayes' Rule\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Bayes’ Rule: p(Λ|Q) = p(Q|Λ)p(Λ) / p(Q)\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"MAP Estimation Problem\\\",\\n      \\\"p\\\": \\\"becomes\\\",\\n      \\\"o\\\": \\\"Maximum Likelihood (ML) Estimation Problem\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Then, the MAP Estimation Problem Becomes the Maximum Likelihood (ML) Estimation Problem\\\"\\n    }\\n  ]\\n}\\n```\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide23.json",
        "parsed": {
          "term": "reconstruction",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T11:07:31.567290+00:00\", \"text_length\": 3356, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nWe begin with the idea that each gamma ray measurement is modeled independently. The underlying framework is a plasma model. Consider an image made up of pixels. Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another. To capture this mathematically, we partition time into small intervals—for example, 10 milliseconds each. One interval, the next interval, and another further away all behave independently. This independence is crucial because it allows us to express the probability of the entire measurement as the product of many small probabilities. Each detector, each pixel, each time interval contributes its own probability, and multiplying them together gives the overall likelihood.\\n\\nThis setup naturally leads to probabilistic modeling. Bayes’ rule, which many of us first learned in high school, becomes central here. Imagine a patient comes in, and we perform data acquisition using a camera or a PET scanner. The raw measurements are then organized into sinograms in 2D or 3D. To understand error and uncertainty, we rely on the power of mathematical notation, which is both compact and expressive. In fact, the measured counts can be modeled as random variables following a Poisson distribution. The problem can then be phrased as: given the measured data, what is the most likely underlying image, denoted by capital lambda (Λ)?\\nThis probability depends on several factors. First, assume the true image is known, along with the source distribution and any background activity. If we also know the imaging geometry, then we can predict what each detector should record. For example, a detector may be expected to receive around 3,000 gamma photons during a five-minute scan. The difficulty is that in reality, the image is not known—we only have the measured data. That’s why we must also consider prior knowledge about the image distribution. For younger patients without cancer, we may expect little to no radioactive uptake in major organs. For older patients, there may be a higher probability of uptake, for instance, in the colon if there is a tumor. These expectations form a prior distribution on the image.\\n\\nHowever, in many cases, especially when data is scarce, we may not want to assume anything specific. In that case, we take the prior distribution to be uniform, meaning every image is equally likely. This constant prior does not affect the statistical estimation, since it cancels out in maximization.\\nFrom here, two key concepts arise: maximum a posteriori (MAP) estimation and maximum likelihood (ML) estimation. MAP seeks the image that maximizes the posterior probability, combining both the likelihood of the measured data given the image and the prior probability of the image itself. If we assume the prior is uniform, MAP reduces to maximum likelihood estimation. In ML, we search for the image that makes the measured data most probable.\\n\\nThe process is iterative: we try candidate images, compute the probability that they would have produced the measured data, and adjust until we find one with the highest probability. That image is then reported as our reconstruction. In summary, if the prior distribution is non-informative, MAP and ML give the same result. Otherwise, MAP incorporates prior knowledge to guide the estimation.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Bayes’ rule\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"maximum a-posteriori probability (MAP)\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"maximum likelihood (ML)\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"prior distribution\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"posterior probability\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"likelihood\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"gamma ray measurement\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"plasma model\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"sinogram\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Poisson distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"maximum a posteriori (MAP) estimation\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"maximum likelihood (ML) estimation\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"iterative process\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"reconstruction\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Bayes’ rule, which many of us first learned in high school,\", \"parsed\": {\"term\": \"reconstruction\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide23.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T12:17:52.346548+00:00\", \"text_length\": 3356, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nWe begin with the idea that each gamma ray measurement is modeled independently. The underlying framework is a plasma model. Consider an image made up of pixels. Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another. To capture this mathematically, we partition time into small intervals—for example, 10 milliseconds each. One interval, the next interval, and another further away all behave independently. This independence is crucial because it allows us to express the probability of the entire measurement as the product of many small probabilities. Each detector, each pixel, each time interval contributes its own probability, and multiplying them together gives the overall likelihood.\\n\\nThis setup naturally leads to probabilistic modeling. Bayes’ rule, which many of us first learned in high school, becomes central here. Imagine a patient comes in, and we perform data acquisition using a camera or a PET scanner. The raw measurements are then organized into sinograms in 2D or 3D. To understand error and uncertainty, we rely on the power of mathematical notation, which is both compact and expressive. In fact, the measured counts can be modeled as random variables following a Poisson distribution. The problem can then be phrased as: given the measured data, what is the most likely underlying image, denoted by capital lambda (Λ)?\\nThis probability depends on several factors. First, assume the true image is known, along with the source distribution and any background activity. If we also know the imaging geometry, then we can predict what each detector should record. For example, a detector may be expected to receive around 3,000 gamma photons during a five-minute scan. The difficulty is that in reality, the image is not known—we only have the measured data. That’s why we must also consider prior knowledge about the image distribution. For younger patients without cancer, we may expect little to no radioactive uptake in major organs. For older patients, there may be a higher probability of uptake, for instance, in the colon if there is a tumor. These expectations form a prior distribution on the image.\\n\\nHowever, in many cases, especially when data is scarce, we may not want to assume anything specific. In that case, we take the prior distribution to be uniform, meaning every image is equally likely. This constant prior does not affect the statistical estimation, since it cancels out in maximization.\\nFrom here, two key concepts arise: maximum a posteriori (MAP) estimation and maximum likelihood (ML) estimation. MAP seeks the image that maximizes the posterior probability, combining both the likelihood of the measured data given the image and the prior probability of the image itself. If we assume the prior is uniform, MAP reduces to maximum likelihood estimation. In ML, we search for the image that makes the measured data most probable.\\n\\nThe process is iterative: we try candidate images, compute the probability that they would have produced the measured data, and adjust until we find one with the highest probability. That image is then reported as our reconstruction. In summary, if the prior distribution is non-informative, MAP and ML give the same result. Otherwise, MAP incorporates prior knowledge to guide the estimation.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Bayes' rule\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"Bayesian Approach\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Bayes' rule is central in the Bayesian approach.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide23.json",
        "parsed": {
          "term": "probability of the entire measurement as the product of many small probabilities",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-12T19:10:29.437735+00:00\", \"text_length\": 3356, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nWe begin with the idea that each gamma ray measurement is modeled independently. The underlying framework is a plasma model. Consider an image made up of pixels. Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another. To capture this mathematically, we partition time into small intervals—for example, 10 milliseconds each. One interval, the next interval, and another further away all behave independently. This independence is crucial because it allows us to express the probability of the entire measurement as the product of many small probabilities. Each detector, each pixel, each time interval contributes its own probability, and multiplying them together gives the overall likelihood.\\n\\nThis setup naturally leads to probabilistic modeling. Bayes’ rule, which many of us first learned in high school, becomes central here. Imagine a patient comes in, and we perform data acquisition using a camera or a PET scanner. The raw measurements are then organized into sinograms in 2D or 3D. To understand error and uncertainty, we rely on the power of mathematical notation, which is both compact and expressive. In fact, the measured counts can be modeled as random variables following a Poisson distribution. The problem can then be phrased as: given the measured data, what is the most likely underlying image, denoted by capital lambda (Λ)?\\nThis probability depends on several factors. First, assume the true image is known, along with the source distribution and any background activity. If we also know the imaging geometry, then we can predict what each detector should record. For example, a detector may be expected to receive around 3,000 gamma photons during a five-minute scan. The difficulty is that in reality, the image is not known—we only have the measured data. That’s why we must also consider prior knowledge about the image distribution. For younger patients without cancer, we may expect little to no radioactive uptake in major organs. For older patients, there may be a higher probability of uptake, for instance, in the colon if there is a tumor. These expectations form a prior distribution on the image.\\n\\nHowever, in many cases, especially when data is scarce, we may not want to assume anything specific. In that case, we take the prior distribution to be uniform, meaning every image is equally likely. This constant prior does not affect the statistical estimation, since it cancels out in maximization.\\nFrom here, two key concepts arise: maximum a posteriori (MAP) estimation and maximum likelihood (ML) estimation. MAP seeks the image that maximizes the posterior probability, combining both the likelihood of the measured data given the image and the prior probability of the image itself. If we assume the prior is uniform, MAP reduces to maximum likelihood estimation. In ML, we search for the image that makes the measured data most probable.\\n\\nThe process is iterative: we try candidate images, compute the probability that they would have produced the measured data, and adjust until we find one with the highest probability. That image is then reported as our reconstruction. In summary, if the prior distribution is non-informative, MAP and ML give the same result. Otherwise, MAP incorporates prior knowledge to guide the estimation.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Bayes’ Rule\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"maximum a-posteriori Probability (MAP)\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"maximum Likelihood (ML) Estimation Problem\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"image to be estimated\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"data actually measured\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"each gamma ray measurement is modeled independently\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"plasma model\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"each pixel, along with its neighbors, contributes independently\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"partition time into small intervals\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"probability of the entire measurement as the product of many small probabilities\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"measured counts\", \"parsed\": {\"term\": \"probability of the entire measurement as the product of many small probabilities\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide23.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-12T19:17:53.129109+00:00\", \"text_length\": 3356, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nWe begin with the idea that each gamma ray measurement is modeled independently. The underlying framework is a plasma model. Consider an image made up of pixels. Each pixel, along with its neighbors, contributes independently—meaning the measurement at one pixel does not directly depend on another. To capture this mathematically, we partition time into small intervals—for example, 10 milliseconds each. One interval, the next interval, and another further away all behave independently. This independence is crucial because it allows us to express the probability of the entire measurement as the product of many small probabilities. Each detector, each pixel, each time interval contributes its own probability, and multiplying them together gives the overall likelihood.\\n\\nThis setup naturally leads to probabilistic modeling. Bayes’ rule, which many of us first learned in high school, becomes central here. Imagine a patient comes in, and we perform data acquisition using a camera or a PET scanner. The raw measurements are then organized into sinograms in 2D or 3D. To understand error and uncertainty, we rely on the power of mathematical notation, which is both compact and expressive. In fact, the measured counts can be modeled as random variables following a Poisson distribution. The problem can then be phrased as: given the measured data, what is the most likely underlying image, denoted by capital lambda (Λ)?\\nThis probability depends on several factors. First, assume the true image is known, along with the source distribution and any background activity. If we also know the imaging geometry, then we can predict what each detector should record. For example, a detector may be expected to receive around 3,000 gamma photons during a five-minute scan. The difficulty is that in reality, the image is not known—we only have the measured data. That’s why we must also consider prior knowledge about the image distribution. For younger patients without cancer, we may expect little to no radioactive uptake in major organs. For older patients, there may be a higher probability of uptake, for instance, in the colon if there is a tumor. These expectations form a prior distribution on the image.\\n\\nHowever, in many cases, especially when data is scarce, we may not want to assume anything specific. In that case, we take the prior distribution to be uniform, meaning every image is equally likely. This constant prior does not affect the statistical estimation, since it cancels out in maximization.\\nFrom here, two key concepts arise: maximum a posteriori (MAP) estimation and maximum likelihood (ML) estimation. MAP seeks the image that maximizes the posterior probability, combining both the likelihood of the measured data given the image and the prior probability of the image itself. If we assume the prior is uniform, MAP reduces to maximum likelihood estimation. In ML, we search for the image that makes the measured data most probable.\\n\\nThe process is iterative: we try candidate images, compute the probability that they would have produced the measured data, and adjust until we find one with the highest probability. That image is then reported as our reconstruction. In summary, if the prior distribution is non-informative, MAP and ML give the same result. Otherwise, MAP incorporates prior knowledge to guide the estimation.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}