{
  "lecture": "Lecture 17",
  "slide_id": "Slide6",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Images\\Slide6.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Texts\\Slide6.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide6.json",
        "parsed": {
          "term": "lambda",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\\n\\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\\n\\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\\n\\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"uniform distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Gaussian distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Poisson distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mean\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"independent random variables\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Gaussian curve\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Poisson distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"lambda\\\", \\\"category\\\": \\\"mathematics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely.\\\", \\n             \\\"The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma.\\\", \\n             \\\"If you have lots of independent random variables, each contributing a\", \"parsed\": {\"term\": \"lambda\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide6.json",
        "parsed": {
          "s": "Poisson distribution",
          "p": "represents",
          "o": "random variables that give you counts-like one, two, three, and so on-with different probabilities for each count",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "It’s controlled by the mean, which we call lambda"
          ]
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\\n\\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\\n\\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\\n\\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"uniform distribution\\\", \\\"p\\\":\\\"represents\\\",\\n     \\\"o\\\":\\\"every point in the interval, like zero to one or zero to five, has the same chance of being picked\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"every number in that range is equally likely\\\"}\\n  ],\\n    {\\\"s\\\":\\\"Gaussian distribution\\\", \\\"p\\\":\\\"represents\\\",\\n     \\\"o\\\":\\\"your classic bell-shaped curve\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"You usually describe it with a mean—called mu—and a standard deviation, sigma\\\"}\\n  ],\\n    {\\\"s\\\":\\\"Poisson distribution\\\", \\\"p\\\":\\\"represents\\\",\\n     \\\"o\\\":\\\"random variables that give you counts—like one, two, three, and so on—with different probabilities for each count\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"It’s controlled by the mean, which we call lambda\\\"}\\n  ],\\n    {\\\"s\\\":\\\"Gaussian\\\", \\\"p\\\":\\\"measures\\\",\\n     \\\"o\\\":\\\"mean and variance, with variance noted as sigma squared\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"For the\", \"parsed\": {\"s\": \"Poisson distribution\", \"p\": \"represents\", \"o\": \"random variables that give you counts-like one, two, three, and so on-with different probabilities for each count\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"It’s controlled by the mean, which we call lambda\"]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide6.json",
        "parsed": {
          "term": "image reconstruction",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"uniform distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Gaussian distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"normal distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mean\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard normal distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Poisson distribution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"lambda\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"variance\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"convolution\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"noise\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"random variables\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"image reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"every point in the interval, like zero to one or zero to five, has the same chance of being picked\\\",\\n    \\\"Gaussian distribution, also called the normal distribution, is your classic bell-shaped\", \"parsed\": {\"term\": \"image reconstruction\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide6.json",
        "parsed": {
          "triples": [
            {
              "s": "Gaussian distribution",
              "p": "represents",
              "o": "bell-shaped curve",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 1.0,
              "evidence": "The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve."
            },
            {
              "s": "Poisson distribution",
              "p": "represents",
              "o": "counts",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "The Poisson describes random variables that give you counts-like one, two, three, and so on-with different probabilities for each count."
            },
            {
              "s": "Gaussian distribution",
              "p": "depends_on",
              "o": "mean and variance",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "For the Gaussian, you have mean and variance, with variance noted as sigma squared."
            },
            {
              "s": "Poisson distribution",
              "p": "depends_on",
              "o": "mean",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "For Poisson, both mean and variance are just lambda."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Gaussian distribution\\\", \\\"p\\\":\\\"represents\\\", \\\"o\\\":\\\"bell-shaped curve\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve.\\\"},\\n    {\\\"s\\\":\\\"Poisson distribution\\\", \\\"p\\\":\\\"represents\\\", \\\"o\\\":\\\"counts\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count.\\\"},\\n    {\\\"s\\\":\\\"Gaussian distribution\\\", \\\"p\\\":\\\"depends_on\\\", \\\"o\\\":\\\"mean and variance\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"For the Gaussian, you have mean and variance, with variance noted as sigma squared.\\\"},\\n    {\\\"s\\\":\\\"Poisson distribution\\\", \\\"p\\\":\\\"depends_on\\\", \\\"o\\\":\\\"mean\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"For Poisson, both mean and variance are just lambda.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"Gaussian distribution\", \"p\": \"represents\", \"o\": \"bell-shaped curve\", \"modalities\": [\"text\", \"image\"], \"confidence\": 1.0, \"evidence\": \"The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve.\"}, {\"s\": \"Poisson distribution\", \"p\": \"represents\", \"o\": \"counts\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"The Poisson describes random variables that give you counts-like one, two, three, and so on-with different probabilities for each count.\"}, {\"s\": \"Gaussian distribution\", \"p\": \"depends_on\", \"o\": \"mean and variance\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"For the Gaussian, you have mean and variance, with variance noted as sigma squared.\"}, {\"s\": \"Poisson distribution\", \"p\": \"depends_on\", \"o\": \"mean\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"For Poisson, both mean and variance are just lambda.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide6.json",
        "parsed": {
          "term": "Poisson noise",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-12T19:32:22.940513+00:00\", \"text_length\": 2335, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\\n\\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\\n\\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\\n\\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Gaussian distribution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Poisson distribution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"mean\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"convolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"bell-shaped curve\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"lambda\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"measurement\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"image reconstruction\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Gaussian noise\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Poisson noise\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"The Gaussian distribution is your classic bell-shaped curve.\\\",\\n    \\\"The Poisson distribution is related to the Gaussian, but looks very different, especially with small means.\\\",\\n    \\\"The Poisson distribution is controlled by the mean, which we call lambda.\\\",\\n    \\\"For the Gaussian, you have mean and variance, with variance noted as sigma squared.\\\",\\n    \\\"\", \"parsed\": {\"term\": \"Poisson noise\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide6.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T12:07:23.676053+00:00\", \"text_length\": 2335, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\\n\\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\\n\\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\\n\\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Gaussian distribution\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"normal distribution\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide6.json",
        "parsed": {
          "term": "random variables that give you counts",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-12T19:07:38.115605+00:00\", \"text_length\": 2335, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\\n\\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\\n\\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\\n\\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"statistical distributions\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"uniform distribution\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"gaussian distribution\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"poisson distribution\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mean—called mu\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"standard deviation, sigma\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"standard normal distribution\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mathematical scaling factor and exponential factor\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"variance noted as sigma squared\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mean, which we call lambda\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"random variables that give you counts\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\", \"parsed\": {\"term\": \"random variables that give you counts\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 17\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide6.json",
        "parsed": {
          "s": "Gaussian & Poisson Noise",
          "p": "uses",
          "o": "mean and variance",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.8,
          "evidence": [
            "For the Gaussian, you have mean and variance, with variance noted as sigma squared."
          ]
        },
        "raw": "{\"slide_id\": \"Slide6\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-12T19:16:01.064668+00:00\", \"text_length\": 2335, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\\n\\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\\n\\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\\n\\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Gaussian & Poisson Noise\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"bell-shaped curve\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Gaussian & Poisson Noise\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"mean and variance\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.8,\\n      \\\"evidence\\\": \\\"For the Gaussian, you have mean and variance, with variance noted as sigma squared.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Gaussian & Poisson Noise\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"counts\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.7,\\n      \\\"evidence\\\": \\\"The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count.\\\"\", \"parsed\": {\"s\": \"Gaussian & Poisson Noise\", \"p\": \"uses\", \"o\": \"mean and variance\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.8, \"evidence\": [\"For the Gaussian, you have mean and variance, with variance noted as sigma squared.\"]}}"
      }
    }
  }
}