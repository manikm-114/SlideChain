{
  "lecture": "Lecture 4",
  "slide_id": "Slide46",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Images\\Slide46.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Texts\\Slide46.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide46.json",
        "parsed": {
          "term": "structural features",
          "category": "image_analysis"
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\nIn this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\nWe begin with the source image, represented as a grid of pixel intensity values.\\u000bThe Sobel kernel, shown here as a 3-by-3 matrix, contains weights:\\u000bnegative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\nHere’s what happens:\\u000bWe align the filter over a 3-by-3 region of the input image.\\u000bThen, we compute the sum of products between the kernel weights and the underlying pixel values.\\nFor instance, at this highlighted region, the computation looks like this:\\n –1 times 3, plus 0 times 0, plus 1 times 1,\\u000b plus –2 times 2, plus 0 times 6, plus 2 times 2,\\u000b plus –1 times 2, plus 0 times 4, plus 1 times 1.\\nWhen we add those up, we get –3.\\u000bThat value becomes the output for the corresponding destination pixel.\\nNow, as the filter slides across the image — pixel by pixel — this process repeats.\\u000bWherever there’s a strong horizontal transition, the filter produces a large response.\\u000bWhere the region is uniform, the response is small or zero.\\nThis is how edge detection works:\\u000bIt uses convolution to detect where intensity changes rapidly, allowing us to extract important structural features from an image.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"convolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"edge detection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Sobel filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pixel intensity values\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"3-by-3 matrix\\\", \\\"category\\\": \\\"matrix_operations\\\"},\\n    {\\\"term\\\": \\\"kernel weights\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"sum of products\\\", \\\"category\\\": \\\"matrix_operations\\\"},\\n    {\\\"term\\\": \\\"destination pixel\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"strong horizontal transition\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"structural features\\\", \\\"category\\\": \\\"image_analysis\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Let’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\\", \\\"In this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\\", \\\"We begin with the source image, represented as a grid of pixel intensity values.\\\", \\\"The Sobel kernel, shown here as a 3-by-\", \"parsed\": {\"term\": \"structural features\", \"category\": \"image_analysis\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide46.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\nIn this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\nWe begin with the source image, represented as a grid of pixel intensity values.\\u000bThe Sobel kernel, shown here as a 3-by-3 matrix, contains weights:\\u000bnegative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\nHere’s what happens:\\u000bWe align the filter over a 3-by-3 region of the input image.\\u000bThen, we compute the sum of products between the kernel weights and the underlying pixel values.\\nFor instance, at this highlighted region, the computation looks like this:\\n –1 times 3, plus 0 times 0, plus 1 times 1,\\u000b plus –2 times 2, plus 0 times 6, plus 2 times 2,\\u000b plus –1 times 2, plus 0 times 4, plus 1 times 1.\\nWhen we add those up, we get –3.\\u000bThat value becomes the output for the corresponding destination pixel.\\nNow, as the filter slides across the image — pixel by pixel — this process repeats.\\u000bWherever there’s a strong horizontal transition, the filter produces a large response.\\u000bWhere the region is uniform, the response is small or zero.\\nThis is how edge detection works:\\u000bIt uses convolution to detect where intensity changes rapidly, allowing us to extract important structural features from an image.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Sobel filter\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Convolution\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<Sobel filter, often used to detect edges in the horizontal direction. We begin with the source image, represented as a grid of pixel intensity values. The Sobel kernel, shown here as a 3-by-3 matrix, contains weights: negative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide46.json",
        "parsed": {
          "term": "structural features",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"convolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"feature extraction\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"edge detection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Sobel filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Sobel kernel\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pixel intensity values\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"3-by-3 matrix\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"weights\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"horizontal changes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"sum of products\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"output\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"filter slides\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"intensity changes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural features\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"convolution helps with feature extraction\\\",\\n    \\\"edge detection\\\",\\n    \\\"Sobel filter\\\",\\n    \\\"Sobel kernel\\\",\", \"parsed\": {\"term\": \"structural features\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide46.json",
        "parsed": {
          "s": "Sobel filter",
          "p": "produces",
          "o": "output for the corresponding destination pixel",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "That value becomes the output for the corresponding destination pixel."
          ]
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"convolution\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"Sobel filter\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Let’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Sobel filter\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"3-by-3 matrix\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"The Sobel kernel, shown here as a 3-by-3 matrix, contains weights: negative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Sobel filter\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"output for the corresponding destination pixel\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"That value becomes the output for the corresponding destination pixel.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"convolution\\\",\\n      \\\"p\", \"parsed\": {\"s\": \"Sobel filter\", \"p\": \"produces\", \"o\": \"output for the corresponding destination pixel\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"That value becomes the output for the corresponding destination pixel.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide46.json",
        "parsed": {
          "term": "structural features",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T22:16:17.014653+00:00\", \"text_length\": 1404, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\nIn this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\nWe begin with the source image, represented as a grid of pixel intensity values.\\u000bThe Sobel kernel, shown here as a 3-by-3 matrix, contains weights:\\u000bnegative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\nHere’s what happens:\\u000bWe align the filter over a 3-by-3 region of the input image.\\u000bThen, we compute the sum of products between the kernel weights and the underlying pixel values.\\nFor instance, at this highlighted region, the computation looks like this:\\n –1 times 3, plus 0 times 0, plus 1 times 1,\\u000b plus –2 times 2, plus 0 times 6, plus 2 times 2,\\u000b plus –1 times 2, plus 0 times 4, plus 1 times 1.\\nWhen we add those up, we get –3.\\u000bThat value becomes the output for the corresponding destination pixel.\\nNow, as the filter slides across the image — pixel by pixel — this process repeats.\\u000bWherever there’s a strong horizontal transition, the filter produces a large response.\\u000bWhere the region is uniform, the response is small or zero.\\nThis is how edge detection works:\\u000bIt uses convolution to detect where intensity changes rapidly, allowing us to extract important structural features from an image.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"convolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"feature extraction\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"edge detection\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Sobel filter\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"horizontal direction\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"source image\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"destination pixel\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"kernel weights\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"pixel intensity values\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"horizontal transition\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"intensity changes\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"structural features\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"convolution helps with feature extraction\\\",\\n    \\\"especially edge detection\\\",\\n    \\\"which is fundamental in medical imaging and computer vision\\\",\\n    \\\"we’re applying a Sobel filter\\\",\\n    \\\"often used to detect edges in the horizontal direction\\\",\\n    \\\"the Sobel kernel, shown here as a 3-by-3 matrix\\\",\\n    \\\"\", \"parsed\": {\"term\": \"structural features\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide46.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T22:52:36.928760+00:00\", \"text_length\": 1404, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\nIn this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\nWe begin with the source image, represented as a grid of pixel intensity values.\\u000bThe Sobel kernel, shown here as a 3-by-3 matrix, contains weights:\\u000bnegative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\nHere’s what happens:\\u000bWe align the filter over a 3-by-3 region of the input image.\\u000bThen, we compute the sum of products between the kernel weights and the underlying pixel values.\\nFor instance, at this highlighted region, the computation looks like this:\\n –1 times 3, plus 0 times 0, plus 1 times 1,\\u000b plus –2 times 2, plus 0 times 6, plus 2 times 2,\\u000b plus –1 times 2, plus 0 times 4, plus 1 times 1.\\nWhen we add those up, we get –3.\\u000bThat value becomes the output for the corresponding destination pixel.\\nNow, as the filter slides across the image — pixel by pixel — this process repeats.\\u000bWherever there’s a strong horizontal transition, the filter produces a large response.\\u000bWhere the region is uniform, the response is small or zero.\\nThis is how edge detection works:\\u000bIt uses convolution to detect where intensity changes rapidly, allowing us to extract important structural features from an image.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide46.json",
        "parsed": {
          "term": "Wherever there's a strong horizontal transition, the filter produces a large response",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-07T23:11:15.189840+00:00\", \"text_length\": 1404, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\nIn this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\nWe begin with the source image, represented as a grid of pixel intensity values.\\u000bThe Sobel kernel, shown here as a 3-by-3 matrix, contains weights:\\u000bnegative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\nHere’s what happens:\\u000bWe align the filter over a 3-by-3 region of the input image.\\u000bThen, we compute the sum of products between the kernel weights and the underlying pixel values.\\nFor instance, at this highlighted region, the computation looks like this:\\n –1 times 3, plus 0 times 0, plus 1 times 1,\\u000b plus –2 times 2, plus 0 times 6, plus 2 times 2,\\u000b plus –1 times 2, plus 0 times 4, plus 1 times 1.\\nWhen we add those up, we get –3.\\u000bThat value becomes the output for the corresponding destination pixel.\\nNow, as the filter slides across the image — pixel by pixel — this process repeats.\\u000bWherever there’s a strong horizontal transition, the filter produces a large response.\\u000bWhere the region is uniform, the response is small or zero.\\nThis is how edge detection works:\\u000bIt uses convolution to detect where intensity changes rapidly, allowing us to extract important structural features from an image.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"convolution helps with feature extraction\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"edge detection\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Sobel filter\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"source image\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"convolution filter (Sobel Gx)\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"destination pixel\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"weights: negative one, zero, and positive one across columns\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"compute the sum of products between the kernel weights and the underlying pixel values\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"the computation looks like this\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Wherever there’s a strong horizontal transition, the filter produces a large response\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"\", \"parsed\": {\"term\": \"Wherever there's a strong horizontal transition, the filter produces a large response\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 4\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide46.json",
        "parsed": {
          "s": "Sobel filter",
          "p": "represents",
          "o": "horizontal direction",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.95,
          "evidence": [
            "In this example, we're applying a Sobel filter, often used to detect edges in the horizontal direction."
          ]
        },
        "raw": "{\"slide_id\": \"Slide46\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-07T23:17:35.207319+00:00\", \"text_length\": 1404, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\nIn this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\nWe begin with the source image, represented as a grid of pixel intensity values.\\u000bThe Sobel kernel, shown here as a 3-by-3 matrix, contains weights:\\u000bnegative one, zero, and positive one across columns — designed to emphasize horizontal changes.\\nHere’s what happens:\\u000bWe align the filter over a 3-by-3 region of the input image.\\u000bThen, we compute the sum of products between the kernel weights and the underlying pixel values.\\nFor instance, at this highlighted region, the computation looks like this:\\n –1 times 3, plus 0 times 0, plus 1 times 1,\\u000b plus –2 times 2, plus 0 times 6, plus 2 times 2,\\u000b plus –1 times 2, plus 0 times 4, plus 1 times 1.\\nWhen we add those up, we get –3.\\u000bThat value becomes the output for the corresponding destination pixel.\\nNow, as the filter slides across the image — pixel by pixel — this process repeats.\\u000bWherever there’s a strong horizontal transition, the filter produces a large response.\\u000bWhere the region is uniform, the response is small or zero.\\nThis is how edge detection works:\\u000bIt uses convolution to detect where intensity changes rapidly, allowing us to extract important structural features from an image.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Sobel filter\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"convolution\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Let’s take a look at how convolution helps with feature extraction — especially edge detection — which is fundamental in medical imaging and computer vision.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Sobel filter\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"destination pixel\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"That value becomes the output for the corresponding destination pixel.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Sobel filter\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"horizontal direction\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"In this example, we’re applying a Sobel filter, often used to detect edges in the horizontal direction.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Sobel filter\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\", \"parsed\": {\"s\": \"Sobel filter\", \"p\": \"represents\", \"o\": \"horizontal direction\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.95, \"evidence\": [\"In this example, we're applying a Sobel filter, often used to detect edges in the horizontal direction.\"]}}"
      }
    }
  }
}