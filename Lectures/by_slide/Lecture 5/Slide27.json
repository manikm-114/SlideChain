{
  "lecture": "Lecture 5",
  "slide_id": "Slide27",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Images\\Slide27.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Texts\\Slide27.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide27.json",
        "parsed": {
          "term": "Fourier coefficients",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\n\\nNow, this idea might sound a bit abstract at first. But if we break it down, it’s very intuitive.\\nIn the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\nThe same idea applies in function space. But instead of using a dot product like we do for regular vectors, we use something called an inner product — which is defined using an integral. This inner product helps us measure both length and angle between functions.\\n\\nLet’s walk through the specific relationships shown here.\\nFirst, the constant function — just the number one — has unit length. That means if we take its inner product with itself, we get one. So it’s normalized.\\nNow let’s see what happens when we compare the constant function with a cosine or a sine function. If we take the inner product of the constant with cosine of two pi times n times t, we get zero — for any positive integer n. The same is true for sine.\\n\\nWhy does this happen? Well, cosine and sine both oscillate above and below the horizontal axis, and over a full cycle, the positive and negative areas cancel out. So when you compare either of them with the constant, the result is zero — meaning they’re orthogonal.\\n\\nNext, let’s compare sine and cosine functions with each other. Say, cosine of two pi times m times t and sine of two pi times n times t. Regardless of which frequencies m and n we choose, their inner product is zero. So sine and cosine are always orthogonal to each other.\\n\\nNow here’s where it gets a bit more subtle.\\nIf we compare cosine functions with other cosine functions — or sine with sine — the result depends on the frequencies.\\nIf the frequencies are different, meaning m is not equal to n, the inner product is zero. They’re orthogonal.\\nBut if the frequencies match — so m equals n — the inner product is one-half. That means the functions are not quite unit-length yet. They’re orthogonal but not normalized.\\n\\nTo fix that, we just scale the sine and cosine functions by the square root of two. Then, their inner product with themselves becomes exactly one, making the whole set orthonormal.\\nSo here’s the big picture: we now have a set of functions — the constant, sine waves, and cosine waves — that are all mutually perpendicular and have unit length. Together, they form a complete orthonormal basis.\\n\\nAnd once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\nNext, we’ll explore how to actually compute those coefficients using integrals.\\nLet’s keep going.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"orthonormal basis\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"sine and cosine functions\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"inner product\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"integral\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"unit length\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"orthogonality\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier series\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Fourier coefficients\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Let’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\\", \\\"In the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\\", \\\"The same idea applies in function space. But instead of using a dot product like we do for regular vectors,\", \"parsed\": {\"term\": \"Fourier coefficients\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide27.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\n\\nNow, this idea might sound a bit abstract at first. But if we break it down, it’s very intuitive.\\nIn the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\nThe same idea applies in function space. But instead of using a dot product like we do for regular vectors, we use something called an inner product — which is defined using an integral. This inner product helps us measure both length and angle between functions.\\n\\nLet’s walk through the specific relationships shown here.\\nFirst, the constant function — just the number one — has unit length. That means if we take its inner product with itself, we get one. So it’s normalized.\\nNow let’s see what happens when we compare the constant function with a cosine or a sine function. If we take the inner product of the constant with cosine of two pi times n times t, we get zero — for any positive integer n. The same is true for sine.\\n\\nWhy does this happen? Well, cosine and sine both oscillate above and below the horizontal axis, and over a full cycle, the positive and negative areas cancel out. So when you compare either of them with the constant, the result is zero — meaning they’re orthogonal.\\n\\nNext, let’s compare sine and cosine functions with each other. Say, cosine of two pi times m times t and sine of two pi times n times t. Regardless of which frequencies m and n we choose, their inner product is zero. So sine and cosine are always orthogonal to each other.\\n\\nNow here’s where it gets a bit more subtle.\\nIf we compare cosine functions with other cosine functions — or sine with sine — the result depends on the frequencies.\\nIf the frequencies are different, meaning m is not equal to n, the inner product is zero. They’re orthogonal.\\nBut if the frequencies match — so m equals n — the inner product is one-half. That means the functions are not quite unit-length yet. They’re orthogonal but not normalized.\\n\\nTo fix that, we just scale the sine and cosine functions by the square root of two. Then, their inner product with themselves becomes exactly one, making the whole set orthonormal.\\nSo here’s the big picture: we now have a set of functions — the constant, sine waves, and cosine waves — that are all mutually perpendicular and have unit length. Together, they form a complete orthonormal basis.\\n\\nAnd once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\nNext, we’ll explore how to actually compute those coefficients using integrals.\\nLet’s keep going.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"sine and cosine functions\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"orthonormal basis\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Let’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide27.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"\", \"parsed\": null}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide27.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"\", \"parsed\": null}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide27.json",
        "parsed": {
          "term": "Fourier coefficients",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T22:16:04.276935+00:00\", \"text_length\": 2976, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\n\\nNow, this idea might sound a bit abstract at first. But if we break it down, it’s very intuitive.\\nIn the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\nThe same idea applies in function space. But instead of using a dot product like we do for regular vectors, we use something called an inner product — which is defined using an integral. This inner product helps us measure both length and angle between functions.\\n\\nLet’s walk through the specific relationships shown here.\\nFirst, the constant function — just the number one — has unit length. That means if we take its inner product with itself, we get one. So it’s normalized.\\nNow let’s see what happens when we compare the constant function with a cosine or a sine function. If we take the inner product of the constant with cosine of two pi times n times t, we get zero — for any positive integer n. The same is true for sine.\\n\\nWhy does this happen? Well, cosine and sine both oscillate above and below the horizontal axis, and over a full cycle, the positive and negative areas cancel out. So when you compare either of them with the constant, the result is zero — meaning they’re orthogonal.\\n\\nNext, let’s compare sine and cosine functions with each other. Say, cosine of two pi times m times t and sine of two pi times n times t. Regardless of which frequencies m and n we choose, their inner product is zero. So sine and cosine are always orthogonal to each other.\\n\\nNow here’s where it gets a bit more subtle.\\nIf we compare cosine functions with other cosine functions — or sine with sine — the result depends on the frequencies.\\nIf the frequencies are different, meaning m is not equal to n, the inner product is zero. They’re orthogonal.\\nBut if the frequencies match — so m equals n — the inner product is one-half. That means the functions are not quite unit-length yet. They’re orthogonal but not normalized.\\n\\nTo fix that, we just scale the sine and cosine functions by the square root of two. Then, their inner product with themselves becomes exactly one, making the whole set orthonormal.\\nSo here’s the big picture: we now have a set of functions — the constant, sine waves, and cosine waves — that are all mutually perpendicular and have unit length. Together, they form a complete orthonormal basis.\\n\\nAnd once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\nNext, we’ll explore how to actually compute those coefficients using integrals.\\nLet’s keep going.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"orthonormal basis\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"inner product\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier series\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier coefficients\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"orthogonal functions\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier transform\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier analysis\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier coefficients\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier series\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier transform\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier analysis\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"orthogonal functions\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"orthonormal basis\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier series\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier coefficients\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"orthogonal functions\", \"parsed\": {\"term\": \"Fourier coefficients\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide27.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T23:13:53.210148+00:00\", \"text_length\": 2976, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\n\\nNow, this idea might sound a bit abstract at first. But if we break it down, it’s very intuitive.\\nIn the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\nThe same idea applies in function space. But instead of using a dot product like we do for regular vectors, we use something called an inner product — which is defined using an integral. This inner product helps us measure both length and angle between functions.\\n\\nLet’s walk through the specific relationships shown here.\\nFirst, the constant function — just the number one — has unit length. That means if we take its inner product with itself, we get one. So it’s normalized.\\nNow let’s see what happens when we compare the constant function with a cosine or a sine function. If we take the inner product of the constant with cosine of two pi times n times t, we get zero — for any positive integer n. The same is true for sine.\\n\\nWhy does this happen? Well, cosine and sine both oscillate above and below the horizontal axis, and over a full cycle, the positive and negative areas cancel out. So when you compare either of them with the constant, the result is zero — meaning they’re orthogonal.\\n\\nNext, let’s compare sine and cosine functions with each other. Say, cosine of two pi times m times t and sine of two pi times n times t. Regardless of which frequencies m and n we choose, their inner product is zero. So sine and cosine are always orthogonal to each other.\\n\\nNow here’s where it gets a bit more subtle.\\nIf we compare cosine functions with other cosine functions — or sine with sine — the result depends on the frequencies.\\nIf the frequencies are different, meaning m is not equal to n, the inner product is zero. They’re orthogonal.\\nBut if the frequencies match — so m equals n — the inner product is one-half. That means the functions are not quite unit-length yet. They’re orthogonal but not normalized.\\n\\nTo fix that, we just scale the sine and cosine functions by the square root of two. Then, their inner product with themselves becomes exactly one, making the whole set orthonormal.\\nSo here’s the big picture: we now have a set of functions — the constant, sine waves, and cosine waves — that are all mutually perpendicular and have unit length. Together, they form a complete orthonormal basis.\\n\\nAnd once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\nNext, we’ll explore how to actually compute those coefficients using integrals.\\nLet’s keep going.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"orthogonal functions\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Fourier series\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide27.json",
        "parsed": {
          "term": "scaling",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-07T22:50:42.379973+00:00\", \"text_length\": 2976, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\n\\nNow, this idea might sound a bit abstract at first. But if we break it down, it’s very intuitive.\\nIn the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\nThe same idea applies in function space. But instead of using a dot product like we do for regular vectors, we use something called an inner product — which is defined using an integral. This inner product helps us measure both length and angle between functions.\\n\\nLet’s walk through the specific relationships shown here.\\nFirst, the constant function — just the number one — has unit length. That means if we take its inner product with itself, we get one. So it’s normalized.\\nNow let’s see what happens when we compare the constant function with a cosine or a sine function. If we take the inner product of the constant with cosine of two pi times n times t, we get zero — for any positive integer n. The same is true for sine.\\n\\nWhy does this happen? Well, cosine and sine both oscillate above and below the horizontal axis, and over a full cycle, the positive and negative areas cancel out. So when you compare either of them with the constant, the result is zero — meaning they’re orthogonal.\\n\\nNext, let’s compare sine and cosine functions with each other. Say, cosine of two pi times m times t and sine of two pi times n times t. Regardless of which frequencies m and n we choose, their inner product is zero. So sine and cosine are always orthogonal to each other.\\n\\nNow here’s where it gets a bit more subtle.\\nIf we compare cosine functions with other cosine functions — or sine with sine — the result depends on the frequencies.\\nIf the frequencies are different, meaning m is not equal to n, the inner product is zero. They’re orthogonal.\\nBut if the frequencies match — so m equals n — the inner product is one-half. That means the functions are not quite unit-length yet. They’re orthogonal but not normalized.\\n\\nTo fix that, we just scale the sine and cosine functions by the square root of two. Then, their inner product with themselves becomes exactly one, making the whole set orthonormal.\\nSo here’s the big picture: we now have a set of functions — the constant, sine waves, and cosine waves — that are all mutually perpendicular and have unit length. Together, they form a complete orthonormal basis.\\n\\nAnd once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\nNext, we’ll explore how to actually compute those coefficients using integrals.\\nLet’s keep going.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"orthonormal basis\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"inner product\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"constant function\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"cosine function\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"sine function\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"orthogonal\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"unit length\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Fourier series\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Fourier coefficients\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"frequency\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"normalized\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"scaling\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\":\", \"parsed\": {\"term\": \"scaling\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 5\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide27.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide27\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-07T22:57:35.382114+00:00\", \"text_length\": 2976, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s now take a closer look at something we claimed earlier — that the set of sine and cosine functions, together with the constant function, form what we call an orthonormal basis.\\n\\nNow, this idea might sound a bit abstract at first. But if we break it down, it’s very intuitive.\\nIn the world of regular vectors — say, in two or three dimensions — we say vectors are orthogonal if they’re at right angles to each other. And if each one also has a length of one, we call them orthonormal.\\nThe same idea applies in function space. But instead of using a dot product like we do for regular vectors, we use something called an inner product — which is defined using an integral. This inner product helps us measure both length and angle between functions.\\n\\nLet’s walk through the specific relationships shown here.\\nFirst, the constant function — just the number one — has unit length. That means if we take its inner product with itself, we get one. So it’s normalized.\\nNow let’s see what happens when we compare the constant function with a cosine or a sine function. If we take the inner product of the constant with cosine of two pi times n times t, we get zero — for any positive integer n. The same is true for sine.\\n\\nWhy does this happen? Well, cosine and sine both oscillate above and below the horizontal axis, and over a full cycle, the positive and negative areas cancel out. So when you compare either of them with the constant, the result is zero — meaning they’re orthogonal.\\n\\nNext, let’s compare sine and cosine functions with each other. Say, cosine of two pi times m times t and sine of two pi times n times t. Regardless of which frequencies m and n we choose, their inner product is zero. So sine and cosine are always orthogonal to each other.\\n\\nNow here’s where it gets a bit more subtle.\\nIf we compare cosine functions with other cosine functions — or sine with sine — the result depends on the frequencies.\\nIf the frequencies are different, meaning m is not equal to n, the inner product is zero. They’re orthogonal.\\nBut if the frequencies match — so m equals n — the inner product is one-half. That means the functions are not quite unit-length yet. They’re orthogonal but not normalized.\\n\\nTo fix that, we just scale the sine and cosine functions by the square root of two. Then, their inner product with themselves becomes exactly one, making the whole set orthonormal.\\nSo here’s the big picture: we now have a set of functions — the constant, sine waves, and cosine waves — that are all mutually perpendicular and have unit length. Together, they form a complete orthonormal basis.\\n\\nAnd once we have this basis, we can represent any periodic function as a combination of these building blocks. That combination is what we call the Fourier series, and the weights we use — the Fourier coefficients — tell us how much of each wave is present in the function.\\nNext, we’ll explore how to actually compute those coefficients using integrals.\\nLet’s keep going.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}