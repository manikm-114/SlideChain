{
  "lecture": "Lecture 8",
  "slide_id": "Slide2",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Images\\Slide2.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Texts\\Slide2.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide2.json",
        "parsed": {
          "term": "reinforcing concepts",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nWe’re moving along right on track in our journey through this course.\\u000b\\nIf you’ve had the chance to preview the reading materials for today, that’s great — it will help you connect the concepts more quickly. If not, that’s fine too.\\n\\nJust follow along closely, and make time afterward to review the main ideas. Building this habit of reinforcing concepts as we go will make your understanding stronger and more intuitive, especially as the topics become more mathematical.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"connect\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"main ideas\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"reinforcing concepts\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"understanding\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"more intuitive\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"more mathematical\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"preview\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"connect\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"main ideas\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"review\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"reinforcing concepts\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"stronger\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"intuitive\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"more mathematical\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"building\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"habit\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"reinforcing concepts\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"\", \"parsed\": {\"term\": \"reinforcing concepts\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nWe’re moving along right on track in our journey through this course.\\u000b\\nIf you’ve had the chance to preview the reading materials for today, that’s great — it will help you connect the concepts more quickly. If not, that’s fine too.\\n\\nJust follow along closely, and make time afterward to review the main ideas. Building this habit of reinforcing concepts as we go will make your understanding stronger and more intuitive, especially as the topics become more mathematical.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<SLIDE_TEXT>\\\",\\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<SLIDE_TEXT>\\\",\\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide2.json",
        "parsed": {
          "concepts": [
            {
              "term": "review the main ideas",
              "category": "workflow"
            },
            {
              "term": "reinforcing concepts",
              "category": "workflow"
            },
            {
              "term": "mathematical",
              "category": "mathematics"
            }
          ],
          "evidence": [
            "Building this habit of reinforcing concepts as we go",
            "especially as the topics become more mathematical"
          ]
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"review the main ideas\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"reinforcing concepts\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"mathematical\\\", \\\"category\\\": \\\"mathematics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Building this habit of reinforcing concepts as we go\\\", \\\"especially as the topics become more mathematical\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"review the main ideas\", \"category\": \"workflow\"}, {\"term\": \"reinforcing concepts\", \"category\": \"workflow\"}, {\"term\": \"mathematical\", \"category\": \"mathematics\"}], \"evidence\": [\"Building this habit of reinforcing concepts as we go\", \"especially as the topics become more mathematical\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": []\\n}\\n```\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide2.json",
        "parsed": {
          "concepts": [],
          "evidence": [
            "Fourier Transform",
            "Discrete FT & FFT",
            "Network",
            "X-ray & Radiography",
            "CT Scanner",
            "Nuclear Physics",
            "MRI",
            "Ultrasound",
            "Optical Imaging",
            "Deep Imaging"
          ]
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T01:04:05.169627+00:00\", \"text_length\": 471, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nWe’re moving along right on track in our journey through this course.\\u000b\\nIf you’ve had the chance to preview the reading materials for today, that’s great — it will help you connect the concepts more quickly. If not, that’s fine too.\\n\\nJust follow along closely, and make time afterward to review the main ideas. Building this habit of reinforcing concepts as we go will make your understanding stronger and more intuitive, especially as the topics become more mathematical.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Fourier Transform\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Discrete FT & FFT\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Network\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"X-ray & Radiography\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"CT Scanner\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Nuclear Physics\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"MRI\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Ultrasound\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Optical Imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Deep Imaging\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Fourier Transform\\\",\\n    \\\"Discrete FT & FFT\\\",\\n    \\\"Network\\\",\\n    \\\"X-ray & Radiography\\\",\\n    \\\"CT Scanner\\\",\\n    \\\"Nuclear Physics\\\",\\n    \\\"MRI\\\",\\n    \\\"Ultrasound\\\",\\n    \\\"Optical Imaging\\\",\\n    \\\"Deep Imaging\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [], \"evidence\": [\"Fourier Transform\", \"Discrete FT & FFT\", \"Network\", \"X-ray & Radiography\", \"CT Scanner\", \"Nuclear Physics\", \"MRI\", \"Ultrasound\", \"Optical Imaging\", \"Deep Imaging\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T02:18:28.842048+00:00\", \"text_length\": 471, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nWe’re moving along right on track in our journey through this course.\\u000b\\nIf you’ve had the chance to preview the reading materials for today, that’s great — it will help you connect the concepts more quickly. If not, that’s fine too.\\n\\nJust follow along closely, and make time afterward to review the main ideas. Building this habit of reinforcing concepts as we go will make your understanding stronger and more intuitive, especially as the topics become more mathematical.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide2.json",
        "parsed": {
          "concepts": [],
          "evidence": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T01:01:16.411306+00:00\", \"text_length\": 471, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nWe’re moving along right on track in our journey through this course.\\u000b\\nIf you’ve had the chance to preview the reading materials for today, that’s great — it will help you connect the concepts more quickly. If not, that’s fine too.\\n\\nJust follow along closely, and make time afterward to review the main ideas. Building this habit of reinforcing concepts as we go will make your understanding stronger and more intuitive, especially as the topics become more mathematical.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [],\\n  \\\"evidence\\\": []\\n}\", \"parsed\": {\"concepts\": [], \"evidence\": []}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 8\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide2.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide2\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T01:07:57.124224+00:00\", \"text_length\": 471, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nWe’re moving along right on track in our journey through this course.\\u000b\\nIf you’ve had the chance to preview the reading materials for today, that’s great — it will help you connect the concepts more quickly. If not, that’s fine too.\\n\\nJust follow along closely, and make time afterward to review the main ideas. Building this habit of reinforcing concepts as we go will make your understanding stronger and more intuitive, especially as the topics become more mathematical.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}