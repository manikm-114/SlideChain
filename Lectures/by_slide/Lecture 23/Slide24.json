{
  "lecture": "Lecture 23",
  "slide_id": "Slide24",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Images\\Slide24.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Texts\\Slide24.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide24.json",
        "parsed": {
          "term": " Michelson interferometer",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s talk about the principle of OCT. It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source — so not a pure single wavelength, but a broadband light with many wavelengths mixed together. This beam first passes through a collimation lens to make the light travel in a parallel direction. Then it reaches the beam splitter, where the light is divided into two paths. One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward the sample under test.\\n\\nThe light going to the reference mirror bounces back after reflection and returns to the beam splitter. Meanwhile, the light that goes toward the sample also gets reflected — but from within the tissue itself. Think of this like sending the beam into the sample; it penetrates a little, hits various microstructures at different depths, and each layer reflects part of the light back. Those reflected signals travel back toward the beam splitter and are then combined with the reference beam.\\n\\nNow, depending on the phase difference between the reference signal and the reflected signal from the sample, the two waves interfere either constructively or destructively. This means that at each position — at each depth — the detector receives a slightly different intensity. You measure those variations point by point, and as the reference mirror scans along the axial direction, you record all the interference signals that come from different depths of the sample. Each point corresponds to a small reflection site inside the tissue.\\n\\nSo what happens next is that these interference signals are detected by the photodetector, digitized, and sent to a computer for processing. One depth scan gives you a one-dimensional line — we call that an A-scan. When you move the beam laterally across the sample — for example, in the x or y direction — you collect many A-scans side by side, building up a full cross-sectional image. That’s the essential idea of optical coherence tomography — measuring optical interference point by point, and reconstructing the internal microstructure of a sample in depth.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"low-coherence light source\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"collimation lens\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"beam splitter\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"reference mirror\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"sample under test\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"frequency_domain\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\" Michelson interferometer\\\", \\\"category\\\": \\\"algorithm\\\"},\", \"parsed\": {\"term\": \" Michelson interferometer\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide24.json",
        "parsed": {
          "triples": [
            {
              "s": "light beam",
              "p": "uses",
              "o": "Michelson interferometer",
              "modalities": [
                "text"
              ],
              "confidence": 0.0,
              "evidence": "It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s talk about the principle of OCT. It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source — so not a pure single wavelength, but a broadband light with many wavelengths mixed together. This beam first passes through a collimation lens to make the light travel in a parallel direction. Then it reaches the beam splitter, where the light is divided into two paths. One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward the sample under test.\\n\\nThe light going to the reference mirror bounces back after reflection and returns to the beam splitter. Meanwhile, the light that goes toward the sample also gets reflected — but from within the tissue itself. Think of this like sending the beam into the sample; it penetrates a little, hits various microstructures at different depths, and each layer reflects part of the light back. Those reflected signals travel back toward the beam splitter and are then combined with the reference beam.\\n\\nNow, depending on the phase difference between the reference signal and the reflected signal from the sample, the two waves interfere either constructively or destructively. This means that at each position — at each depth — the detector receives a slightly different intensity. You measure those variations point by point, and as the reference mirror scans along the axial direction, you record all the interference signals that come from different depths of the sample. Each point corresponds to a small reflection site inside the tissue.\\n\\nSo what happens next is that these interference signals are detected by the photodetector, digitized, and sent to a computer for processing. One depth scan gives you a one-dimensional line — we call that an A-scan. When you move the beam laterally across the sample — for example, in the x or y direction — you collect many A-scans side by side, building up a full cross-sectional image. That’s the essential idea of optical coherence tomography — measuring optical interference point by point, and reconstructing the internal microstructure of a sample in depth.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"light beam\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\" Michelson interferometer\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"light beam\", \"p\": \"uses\", \"o\": \"Michelson interferometer\", \"modalities\": [\"text\"], \"confidence\": 0.0, \"evidence\": \"It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide24.json",
        "parsed": {
          "term": "reconstruction",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"low-coherence light source\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"collimation lens\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"beam splitter\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"reference mirror\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"objective lens\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"photodetector\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"interference\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"constructive or destructive interference\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"phase difference\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"A-scan\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"cross-sectional image\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"optical coherence tomography\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"digitized\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"light beam that comes from a low-coherence light source\\\",\\n    \\\"passes\", \"parsed\": {\"term\": \"reconstruction\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide24.json",
        "parsed": {
          "s": "OCT",
          "p": "uses",
          "o": "reference mirror",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "One part of the beam goes upward toward the reference mirror"
          ]
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"OCT\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"low-coherence light source\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source\\\"},\\n    {\\\"s\\\":\\\"OCT\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"collimation lens\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"This beam first passes through a collimation lens to make the light travel in a parallel direction\\\"},\\n    {\\\"s\\\":\\\"OCT\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"beam splitter\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Then it reaches the beam splitter, where the light is divided into two paths\\\"},\\n    {\\\"s\\\":\\\"OCT\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"reference mirror\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"One part of the beam goes upward toward the reference mirror\\\"},\\n    {\\\"s\\\":\\\"OCT\\\", \\\"p\\\":\\\"uses\\\", \\\"o\", \"parsed\": {\"s\": \"OCT\", \"p\": \"uses\", \"o\": \"reference mirror\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"One part of the beam goes upward toward the reference mirror\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide24.json",
        "parsed": {
          "term": "A-scan",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T17:52:40.593179+00:00\", \"text_length\": 2243, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s talk about the principle of OCT. It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source — so not a pure single wavelength, but a broadband light with many wavelengths mixed together. This beam first passes through a collimation lens to make the light travel in a parallel direction. Then it reaches the beam splitter, where the light is divided into two paths. One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward the sample under test.\\n\\nThe light going to the reference mirror bounces back after reflection and returns to the beam splitter. Meanwhile, the light that goes toward the sample also gets reflected — but from within the tissue itself. Think of this like sending the beam into the sample; it penetrates a little, hits various microstructures at different depths, and each layer reflects part of the light back. Those reflected signals travel back toward the beam splitter and are then combined with the reference beam.\\n\\nNow, depending on the phase difference between the reference signal and the reflected signal from the sample, the two waves interfere either constructively or destructively. This means that at each position — at each depth — the detector receives a slightly different intensity. You measure those variations point by point, and as the reference mirror scans along the axial direction, you record all the interference signals that come from different depths of the sample. Each point corresponds to a small reflection site inside the tissue.\\n\\nSo what happens next is that these interference signals are detected by the photodetector, digitized, and sent to a computer for processing. One depth scan gives you a one-dimensional line — we call that an A-scan. When you move the beam laterally across the sample — for example, in the x or y direction — you collect many A-scans side by side, building up a full cross-sectional image. That’s the essential idea of optical coherence tomography — measuring optical interference point by point, and reconstructing the internal microstructure of a sample in depth.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"low-coherence light source\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"collimation lens\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"beam splitter\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"reference mirror\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"sample under test\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"objective lens\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"photo detector\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"filtering\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"Demod / processing\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"ADC\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"computer & display\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"Axial (Z) scanning\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"Lateral (X or Y) scanning\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"interference signals\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"A-scan\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"cross-sectional\", \"parsed\": {\"term\": \"A-scan\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide24.json",
        "parsed": {
          "triples": [
            {
              "s": "low-coherence light source",
              "p": "uses",
              "o": "collimation lens",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 1.0,
              "evidence": "The light beam comes from a low-coherence light source."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T18:46:30.986542+00:00\", \"text_length\": 2243, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s talk about the principle of OCT. It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source — so not a pure single wavelength, but a broadband light with many wavelengths mixed together. This beam first passes through a collimation lens to make the light travel in a parallel direction. Then it reaches the beam splitter, where the light is divided into two paths. One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward the sample under test.\\n\\nThe light going to the reference mirror bounces back after reflection and returns to the beam splitter. Meanwhile, the light that goes toward the sample also gets reflected — but from within the tissue itself. Think of this like sending the beam into the sample; it penetrates a little, hits various microstructures at different depths, and each layer reflects part of the light back. Those reflected signals travel back toward the beam splitter and are then combined with the reference beam.\\n\\nNow, depending on the phase difference between the reference signal and the reflected signal from the sample, the two waves interfere either constructively or destructively. This means that at each position — at each depth — the detector receives a slightly different intensity. You measure those variations point by point, and as the reference mirror scans along the axial direction, you record all the interference signals that come from different depths of the sample. Each point corresponds to a small reflection site inside the tissue.\\n\\nSo what happens next is that these interference signals are detected by the photodetector, digitized, and sent to a computer for processing. One depth scan gives you a one-dimensional line — we call that an A-scan. When you move the beam laterally across the sample — for example, in the x or y direction — you collect many A-scans side by side, building up a full cross-sectional image. That’s the essential idea of optical coherence tomography — measuring optical interference point by point, and reconstructing the internal microstructure of a sample in depth.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"low-coherence light source\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"collimation lens\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The light beam comes from a low-coherence light source.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"low-coherence light source\", \"p\": \"uses\", \"o\": \"collimation lens\", \"modalities\": [\"text\", \"image\"], \"confidence\": 1.0, \"evidence\": \"The light beam comes from a low-coherence light source.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide24.json",
        "parsed": {
          "term": "axial (z) scanning",
          "category": "workflow"
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T15:57:08.752987+00:00\", \"text_length\": 2243, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s talk about the principle of OCT. It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source — so not a pure single wavelength, but a broadband light with many wavelengths mixed together. This beam first passes through a collimation lens to make the light travel in a parallel direction. Then it reaches the beam splitter, where the light is divided into two paths. One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward the sample under test.\\n\\nThe light going to the reference mirror bounces back after reflection and returns to the beam splitter. Meanwhile, the light that goes toward the sample also gets reflected — but from within the tissue itself. Think of this like sending the beam into the sample; it penetrates a little, hits various microstructures at different depths, and each layer reflects part of the light back. Those reflected signals travel back toward the beam splitter and are then combined with the reference beam.\\n\\nNow, depending on the phase difference between the reference signal and the reflected signal from the sample, the two waves interfere either constructively or destructively. This means that at each position — at each depth — the detector receives a slightly different intensity. You measure those variations point by point, and as the reference mirror scans along the axial direction, you record all the interference signals that come from different depths of the sample. Each point corresponds to a small reflection site inside the tissue.\\n\\nSo what happens next is that these interference signals are detected by the photodetector, digitized, and sent to a computer for processing. One depth scan gives you a one-dimensional line — we call that an A-scan. When you move the beam laterally across the sample — for example, in the x or y direction — you collect many A-scans side by side, building up a full cross-sectional image. That’s the essential idea of optical coherence tomography — measuring optical interference point by point, and reconstructing the internal microstructure of a sample in depth.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"low-coherence light source\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"collimation lens\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"beam splitter\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"reference mirror\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"beam reducer\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"objective lens\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"photo detector\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"filtering\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"demod / processing\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"adc\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"computer & display\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"axial (z) scanning\\\",\\n      \\\"category\\\": \\\"workflow\\\"\\n    },\", \"parsed\": {\"term\": \"axial (z) scanning\", \"category\": \"workflow\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide24.json",
        "parsed": {
          "s": "beam splitter",
          "p": "represents",
          "o": "division of light into two paths",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.9,
          "evidence": [
            "Then it reaches the beam splitter, where the light is divided into two paths."
          ]
        },
        "raw": "{\"slide_id\": \"Slide24\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T16:04:45.192321+00:00\", \"text_length\": 2243, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s talk about the principle of OCT. It’s really the same idea as what we just discussed with the Michelson interferometer, but now applied to imaging. You can see here, we have a light beam that comes from a low-coherence light source — so not a pure single wavelength, but a broadband light with many wavelengths mixed together. This beam first passes through a collimation lens to make the light travel in a parallel direction. Then it reaches the beam splitter, where the light is divided into two paths. One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward the sample under test.\\n\\nThe light going to the reference mirror bounces back after reflection and returns to the beam splitter. Meanwhile, the light that goes toward the sample also gets reflected — but from within the tissue itself. Think of this like sending the beam into the sample; it penetrates a little, hits various microstructures at different depths, and each layer reflects part of the light back. Those reflected signals travel back toward the beam splitter and are then combined with the reference beam.\\n\\nNow, depending on the phase difference between the reference signal and the reflected signal from the sample, the two waves interfere either constructively or destructively. This means that at each position — at each depth — the detector receives a slightly different intensity. You measure those variations point by point, and as the reference mirror scans along the axial direction, you record all the interference signals that come from different depths of the sample. Each point corresponds to a small reflection site inside the tissue.\\n\\nSo what happens next is that these interference signals are detected by the photodetector, digitized, and sent to a computer for processing. One depth scan gives you a one-dimensional line — we call that an A-scan. When you move the beam laterally across the sample — for example, in the x or y direction — you collect many A-scans side by side, building up a full cross-sectional image. That’s the essential idea of optical coherence tomography — measuring optical interference point by point, and reconstructing the internal microstructure of a sample in depth.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"low coherence light source\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"collimation lens\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"The light beam that comes from a low-coherence light source... first passes through a collimation lens to make the light travel in a parallel direction.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"beam splitter\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"division of light into two paths\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"Then it reaches the beam splitter, where the light is divided into two paths.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"reference mirror\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"return path for reference beam\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"One part of the beam goes upward toward the reference mirror, and the other part travels sideways toward\", \"parsed\": {\"s\": \"beam splitter\", \"p\": \"represents\", \"o\": \"division of light into two paths\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.9, \"evidence\": [\"Then it reaches the beam splitter, where the light is divided into two paths.\"]}}"
      }
    }
  }
}