{
  "lecture": "Lecture 23",
  "slide_id": "Slide28",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Images\\Slide28.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Texts\\Slide28.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide28.json",
        "parsed": {
          "term": "feasible",
          "category": "software"
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLight diffusion is the heart of the third part. These third and fourth parts aren’t in common clinical use yet, but in research settings, they’re very active. With X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\n\\nOptical imaging is different. Biological tissue scatters light strongly. I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones — and you’ve all seen this in real life. In a dark room, shine a bright laser pointer and you see a diffuse glow. Put the laser behind your finger: can you see details behind the finger? No. With X-ray, the projection already looks like a picture. With optical light, even if you send a parallel laser beam, what you see is a cloudy smear. And yet, diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\n\\nSo put it in simple words: we want to make a good image behind the finger. That sounds almost impossible, and it is hard. That’s why diffuse optical imaging is not as practical as X-ray and some other modalities. But optical interactions carry rich biological information, so we study them. Our job as engineers is to turn “impossible” into “feasible.” That’s the challenge — and that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"diffusion\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"attenuation\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"X-ray imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"diffuse optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"scattering\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Rayleigh\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Mie\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"laser\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"image reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"inverse problems\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"diffusion models\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"biological information\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"diffuse optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"practical\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"feasible\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"diff\", \"parsed\": {\"term\": \"feasible\", \"category\": \"software\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide28.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLight diffusion is the heart of the third part. These third and fourth parts aren’t in common clinical use yet, but in research settings, they’re very active. With X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\n\\nOptical imaging is different. Biological tissue scatters light strongly. I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones — and you’ve all seen this in real life. In a dark room, shine a bright laser pointer and you see a diffuse glow. Put the laser behind your finger: can you see details behind the finger? No. With X-ray, the projection already looks like a picture. With optical light, even if you send a parallel laser beam, what you see is a cloudy smear. And yet, diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\n\\nSo put it in simple words: we want to make a good image behind the finger. That sounds almost impossible, and it is hard. That’s why diffuse optical imaging is not as practical as X-ray and some other modalities. But optical interactions carry rich biological information, so we study them. Our job as engineers is to turn “impossible” into “feasible.” That’s the challenge — and that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"diffuse optical imaging\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"X-ray imaging\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide28.json",
        "parsed": {
          "concepts": [
            {
              "term": "Light diffusion",
              "category": "physics"
            },
            {
              "term": "X-ray imaging",
              "category": "modality"
            },
            {
              "term": "linear attenuation coefficient",
              "category": "physics"
            },
            {
              "term": "diffuse optical imaging",
              "category": "modality"
            },
            {
              "term": "inverse problems",
              "category": "algorithm"
            },
            {
              "term": "diffusion models",
              "category": "algorithm"
            }
          ],
          "evidence": [
            "Light diffusion is the heart of the third part.",
            "With X-ray imaging, rays go essentially straight.",
            "you can explain it with the linear attenuation coefficient along that ray.",
            "I showed you that little cartoon of scattering - Rayleigh at small scales, Mie at larger ones",
            "diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.",
            "that’s why we dig into diffusion models and inverse problems to see what can be recovered."
          ]
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Light diffusion\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"X-ray imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"linear attenuation coefficient\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Rayleigh scattering\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Mie scattering\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"diffuse optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"inverse problems\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"diffusion models\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Light diffusion is the heart of the third part.\\\",\\n    \\\"With X-ray imaging, rays go essentially straight.\\\",\\n    \\\"you can explain it with the linear attenuation coefficient along that ray.\\\",\\n    \\\"I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones\\\",\\n    \\\"diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\\",\\n    \\\"that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\\"\\n  ]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"Light diffusion\", \"category\": \"physics\"}, {\"term\": \"X-ray imaging\", \"category\": \"modality\"}, {\"term\": \"linear attenuation coefficient\", \"category\": \"physics\"}, {\"term\": \"diffuse optical imaging\", \"category\": \"modality\"}, {\"term\": \"inverse problems\", \"category\": \"algorithm\"}, {\"term\": \"diffusion models\", \"category\": \"algorithm\"}], \"evidence\": [\"Light diffusion is the heart of the third part.\", \"With X-ray imaging, rays go essentially straight.\", \"you can explain it with the linear attenuation coefficient along that ray.\", \"I showed you that little cartoon of scattering - Rayleigh at small scales, Mie at larger ones\", \"diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\", \"that’s why we dig into diffusion models and inverse problems to see what can be recovered.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide28.json",
        "parsed": {
          "triples": [
            {
              "s": "X-ray imaging",
              "p": "produces",
              "o": "projection",
              "modalities": [
                "text"
              ],
              "confidence": 0.9,
              "evidence": "With X-ray, the projection already looks like a picture."
            },
            {
              "s": "optical imaging",
              "p": "measures",
              "o": "biological information",
              "modalities": [
                "text"
              ],
              "confidence": 0.9,
              "evidence": "optical interactions carry rich biological information"
            },
            {
              "s": "diffuse optical imaging",
              "p": "reconstructs_with",
              "o": "image",
              "modalities": [
                "text"
              ],
              "confidence": 0.9,
              "evidence": "diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"X-ray imaging\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"projection\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"With X-ray, the projection already looks like a picture.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"optical imaging\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"biological information\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"optical interactions carry rich biological information\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"diffuse optical imaging\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"image\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\\"\\n    }\\n  ]\\n}\\n```\", \"parsed\": {\"triples\": [{\"s\": \"X-ray imaging\", \"p\": \"produces\", \"o\": \"projection\", \"modalities\": [\"text\"], \"confidence\": 0.9, \"evidence\": \"With X-ray, the projection already looks like a picture.\"}, {\"s\": \"optical imaging\", \"p\": \"measures\", \"o\": \"biological information\", \"modalities\": [\"text\"], \"confidence\": 0.9, \"evidence\": \"optical interactions carry rich biological information\"}, {\"s\": \"diffuse optical imaging\", \"p\": \"reconstructs_with\", \"o\": \"image\", \"modalities\": [\"text\"], \"confidence\": 0.9, \"evidence\": \"diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide28.json",
        "parsed": {
          "term": "Reconstruction",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T17:58:38.227585+00:00\", \"text_length\": 1630, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLight diffusion is the heart of the third part. These third and fourth parts aren’t in common clinical use yet, but in research settings, they’re very active. With X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\n\\nOptical imaging is different. Biological tissue scatters light strongly. I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones — and you’ve all seen this in real life. In a dark room, shine a bright laser pointer and you see a diffuse glow. Put the laser behind your finger: can you see details behind the finger? No. With X-ray, the projection already looks like a picture. With optical light, even if you send a parallel laser beam, what you see is a cloudy smear. And yet, diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\n\\nSo put it in simple words: we want to make a good image behind the finger. That sounds almost impossible, and it is hard. That’s why diffuse optical imaging is not as practical as X-ray and some other modalities. But optical interactions carry rich biological information, so we study them. Our job as engineers is to turn “impossible” into “feasible.” That’s the challenge — and that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Light diffusion\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"X-ray imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Rayleigh scattering\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Mie scattering\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Diffuse optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Inverse problems\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Diffusion models\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Biological information\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Engineers\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"Difficult\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Imaging behind the finger\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Diffusion\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Light diffusion is the heart of the third part.\\\",\\n    \\\"With X-ray imaging, rays go essentially straight.\\\",\\n    \\\"\", \"parsed\": {\"term\": \"Reconstruction\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide28.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T18:48:34.193310+00:00\", \"text_length\": 1630, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLight diffusion is the heart of the third part. These third and fourth parts aren’t in common clinical use yet, but in research settings, they’re very active. With X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\n\\nOptical imaging is different. Biological tissue scatters light strongly. I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones — and you’ve all seen this in real life. In a dark room, shine a bright laser pointer and you see a diffuse glow. Put the laser behind your finger: can you see details behind the finger? No. With X-ray, the projection already looks like a picture. With optical light, even if you send a parallel laser beam, what you see is a cloudy smear. And yet, diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\n\\nSo put it in simple words: we want to make a good image behind the finger. That sounds almost impossible, and it is hard. That’s why diffuse optical imaging is not as practical as X-ray and some other modalities. But optical interactions carry rich biological information, so we study them. Our job as engineers is to turn “impossible” into “feasible.” That’s the challenge — and that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Light diffusion\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Biological tissue\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Biological tissue scatters light strongly.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide28.json",
        "parsed": {
          "term": "signal is a line integral along the path",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T15:57:50.600222+00:00\", \"text_length\": 1630, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLight diffusion is the heart of the third part. These third and fourth parts aren’t in common clinical use yet, but in research settings, they’re very active. With X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\n\\nOptical imaging is different. Biological tissue scatters light strongly. I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones — and you’ve all seen this in real life. In a dark room, shine a bright laser pointer and you see a diffuse glow. Put the laser behind your finger: can you see details behind the finger? No. With X-ray, the projection already looks like a picture. With optical light, even if you send a parallel laser beam, what you see is a cloudy smear. And yet, diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\n\\nSo put it in simple words: we want to make a good image behind the finger. That sounds almost impossible, and it is hard. That’s why diffuse optical imaging is not as practical as X-ray and some other modalities. But optical interactions carry rich biological information, so we study them. Our job as engineers is to turn “impossible” into “feasible.” That’s the challenge — and that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"light diffusion\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"X-ray imaging\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"optical imaging\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Rayleigh\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Mie\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"linear attenuation coefficient\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"line integral\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"diffuse optical imaging\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"inverse problems\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"diffusion models\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"signal is a line integral along the path\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"strong localization claim\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\", \"parsed\": {\"term\": \"signal is a line integral along the path\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide28.json",
        "parsed": {
          "s": "diffuse optical imaging",
          "p": "reconstructs_with",
          "o": "image behind the finger",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.8,
          "evidence": [
            "we want to make a good image behind the finger."
          ]
        },
        "raw": "{\"slide_id\": \"Slide28\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T16:05:16.915484+00:00\", \"text_length\": 1630, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLight diffusion is the heart of the third part. These third and fourth parts aren’t in common clinical use yet, but in research settings, they’re very active. With X-ray imaging, rays go essentially straight. Think of that purple straight line: the signal is a line integral along the path. Everything contributes additively, and you can explain it with the linear attenuation coefficient along that ray. Any change in the measurement must come from features located along that ray — that’s a strong localization claim, and it’s very clear.\\n\\nOptical imaging is different. Biological tissue scatters light strongly. I showed you that little cartoon of scattering — Rayleigh at small scales, Mie at larger ones — and you’ve all seen this in real life. In a dark room, shine a bright laser pointer and you see a diffuse glow. Put the laser behind your finger: can you see details behind the finger? No. With X-ray, the projection already looks like a picture. With optical light, even if you send a parallel laser beam, what you see is a cloudy smear. And yet, diffuse optical imaging says, despite that strong scattering, we still want to reconstruct an image.\\n\\nSo put it in simple words: we want to make a good image behind the finger. That sounds almost impossible, and it is hard. That’s why diffuse optical imaging is not as practical as X-ray and some other modalities. But optical interactions carry rich biological information, so we study them. Our job as engineers is to turn “impossible” into “feasible.” That’s the challenge — and that’s why we dig into diffusion models and inverse problems to see what can be recovered.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"X-ray imaging\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"straight rays\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"With X-ray imaging, rays go essentially straight.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Optical imaging\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"strong scattering\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"Optical imaging is different. Biological tissue scatters light strongly.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"diffuse optical imaging\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"image behind the finger\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.8,\\n      \\\"evidence\\\": \\\"we want to make a good image behind the finger.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"diffuse optical imaging\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"rich biological information\\\",\\n      \\\"modal\", \"parsed\": {\"s\": \"diffuse optical imaging\", \"p\": \"reconstructs_with\", \"o\": \"image behind the finger\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.8, \"evidence\": [\"we want to make a good image behind the finger.\"]}}"
      }
    }
  }
}