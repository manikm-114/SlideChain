{
  "lecture": "Lecture 23",
  "slide_id": "Slide4",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Images\\Slide4.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Texts\\Slide4.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide4.json",
        "parsed": {
          "concepts": [
            {
              "term": "visible light",
              "category": "physics"
            },
            {
              "term": "wavelength",
              "category": "physics"
            },
            {
              "term": "optical imaging",
              "category": "modality"
            },
            {
              "term": "visible and near-infrared range",
              "category": "frequency_domain"
            }
          ],
          "evidence": [
            "Visible light, however, occupies only a very narrow portion of this vast spectrum.",
            "Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength.",
            "Within this band, our eyes perceive different colors - violet, blue, green, yellow, and red - depending on the wavelength.",
            "Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique."
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, let’s begin our story — and at the beginning, there is light.\\n\\u000bLight is part of the electromagnetic, or EM, wave spectrum, which spans an enormous range of wavelengths. We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging and X-rays used in computed tomography. On the other end, we have radio waves and microwaves, which are much longer and used in applications like MRI and even cooking.\\n\\nVisible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength. You’ve seen this effect when light passes through a prism, spreading into a rainbow of colors.\\n\\nSome animals can detect wavelengths beyond our range. For example, certain species can see ultraviolet or even X-ray light, as confirmed by electroretinogram studies. Among humans, individual sensitivity also varies, and a small percentage of people are color-blind, perceiving only shades of gray.\\n\\nFor medical imaging, each modality uses a different part of the spectrum depending on its purpose. In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range. These wavelengths penetrate tissue to a useful depth, making them ideal for studying cells, tissues, and biological processes using light. Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"visible light\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"wavelength\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"color blindness\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visible and near-infrared range\\\", \\\"category\\\": \\\"frequency_domain\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Visible light, however, occupies only a very narrow portion of this vast spectrum.\\\", \\n               \\\"Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength.\\\", \\n               \\\"Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength.\\\", \\n               \\\"Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"visible light\", \"category\": \"physics\"}, {\"term\": \"wavelength\", \"category\": \"physics\"}, {\"term\": \"optical imaging\", \"category\": \"modality\"}, {\"term\": \"visible and near-infrared range\", \"category\": \"frequency_domain\"}], \"evidence\": [\"Visible light, however, occupies only a very narrow portion of this vast spectrum.\", \"Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength.\", \"Within this band, our eyes perceive different colors - violet, blue, green, yellow, and red - depending on the wavelength.\", \"Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, let’s begin our story — and at the beginning, there is light.\\n\\u000bLight is part of the electromagnetic, or EM, wave spectrum, which spans an enormous range of wavelengths. We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging and X-rays used in computed tomography. On the other end, we have radio waves and microwaves, which are much longer and used in applications like MRI and even cooking.\\n\\nVisible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength. You’ve seen this effect when light passes through a prism, spreading into a rainbow of colors.\\n\\nSome animals can detect wavelengths beyond our range. For example, certain species can see ultraviolet or even X-ray light, as confirmed by electroretinogram studies. Among humans, individual sensitivity also varies, and a small percentage of people are color-blind, perceiving only shades of gray.\\n\\nFor medical imaging, each modality uses a different part of the spectrum depending on its purpose. In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range. These wavelengths penetrate tissue to a useful depth, making them ideal for studying cells, tissues, and biological processes using light. Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"visible light\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"medical imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Visible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide4.json",
        "parsed": {
          "term": "tissue penetration",
          "category": "physics"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"electromagnetic wave spectrum\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"gamma rays\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"X-rays\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"radio waves\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"microwaves\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visible light\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"wavelength\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"near-infrared range\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"tissue penetration\\\", \\\"category\\\": \\\"physics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Light is part of the electromagnetic, or EM, wave spectrum\\\",\\n    \\\"gamma rays used in nuclear imaging and X-rays used in computed tomography\\\",\\n    \\\"radio waves and microwaves\\\",\\n    \\\"Visible light, however, occupies only a very narrow portion of this vast spectrum\\\",\\n    \\\"ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength\\\",\\n    \\\"\", \"parsed\": {\"term\": \"tissue penetration\", \"category\": \"physics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide4.json",
        "parsed": {
          "s": "optical imaging",
          "p": "focuses on",
          "o": "visible and near-infrared range",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "In optical imaging, we focus on the portion we can directly see - the visible and near-infrared range"
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"gamma rays\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"nuclear imaging\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging\\\"},\\n    {\\\"s\\\":\\\"X-rays\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"computed tomography\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"X-rays used in computed tomography\\\"},\\n    {\\\"s\\\":\\\"MRI\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"radio waves\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"radio waves and microwaves, which are much longer and used in applications like MRI\\\"},\\n    {\\\"s\\\":\\\"optical imaging\\\", \\\"p\\\":\\\"focuses on\\\", \\\"o\\\":\\\"visible and near-infrared range\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range\\\"},\\n    {\\\"s\\\":\\\"optical imaging\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"light\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"\", \"parsed\": {\"s\": \"optical imaging\", \"p\": \"focuses on\", \"o\": \"visible and near-infrared range\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"In optical imaging, we focus on the portion we can directly see - the visible and near-infrared range\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide4.json",
        "parsed": {
          "term": "powerful technique",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T17:20:07.670746+00:00\", \"text_length\": 1609, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, let’s begin our story — and at the beginning, there is light.\\n\\u000bLight is part of the electromagnetic, or EM, wave spectrum, which spans an enormous range of wavelengths. We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging and X-rays used in computed tomography. On the other end, we have radio waves and microwaves, which are much longer and used in applications like MRI and even cooking.\\n\\nVisible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength. You’ve seen this effect when light passes through a prism, spreading into a rainbow of colors.\\n\\nSome animals can detect wavelengths beyond our range. For example, certain species can see ultraviolet or even X-ray light, as confirmed by electroretinogram studies. Among humans, individual sensitivity also varies, and a small percentage of people are color-blind, perceiving only shades of gray.\\n\\nFor medical imaging, each modality uses a different part of the spectrum depending on its purpose. In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range. These wavelengths penetrate tissue to a useful depth, making them ideal for studying cells, tissues, and biological processes using light. Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"electromagnetic wave spectrum\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"gamma rays\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"X-rays\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"radio waves\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"microwaves\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visible light\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"ultraviolet light\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"infrared light\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"visible range\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"near-infrared range\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"color blindness\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"optical imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"physical foundation\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"powerful technique\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Light is part\", \"parsed\": {\"term\": \"powerful technique\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T18:35:41.041043+00:00\", \"text_length\": 1609, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, let’s begin our story — and at the beginning, there is light.\\n\\u000bLight is part of the electromagnetic, or EM, wave spectrum, which spans an enormous range of wavelengths. We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging and X-rays used in computed tomography. On the other end, we have radio waves and microwaves, which are much longer and used in applications like MRI and even cooking.\\n\\nVisible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength. You’ve seen this effect when light passes through a prism, spreading into a rainbow of colors.\\n\\nSome animals can detect wavelengths beyond our range. For example, certain species can see ultraviolet or even X-ray light, as confirmed by electroretinogram studies. Among humans, individual sensitivity also varies, and a small percentage of people are color-blind, perceiving only shades of gray.\\n\\nFor medical imaging, each modality uses a different part of the spectrum depending on its purpose. In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range. These wavelengths penetrate tissue to a useful depth, making them ideal for studying cells, tissues, and biological processes using light. Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide4.json",
        "parsed": {
          "term": "these wavelengths penetrate tissue to a useful depth",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T15:53:39.978691+00:00\", \"text_length\": 1609, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, let’s begin our story — and at the beginning, there is light.\\n\\u000bLight is part of the electromagnetic, or EM, wave spectrum, which spans an enormous range of wavelengths. We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging and X-rays used in computed tomography. On the other end, we have radio waves and microwaves, which are much longer and used in applications like MRI and even cooking.\\n\\nVisible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength. You’ve seen this effect when light passes through a prism, spreading into a rainbow of colors.\\n\\nSome animals can detect wavelengths beyond our range. For example, certain species can see ultraviolet or even X-ray light, as confirmed by electroretinogram studies. Among humans, individual sensitivity also varies, and a small percentage of people are color-blind, perceiving only shades of gray.\\n\\nFor medical imaging, each modality uses a different part of the spectrum depending on its purpose. In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range. These wavelengths penetrate tissue to a useful depth, making them ideal for studying cells, tissues, and biological processes using light. Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"light is part of the electromagnetic, or EM, wave spectrum\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"electromagnetic wave spectrum spans an enormous range of wavelengths\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"visible light ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"medical imaging, each modality uses a different part of the spectrum depending on its purpose\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"optical imaging, we focus on the portion we can directly see — the visible and near-infrared range\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"these wavelengths penetrate tissue to a useful depth\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"understanding this basic physical foundation will\", \"parsed\": {\"term\": \"these wavelengths penetrate tissue to a useful depth\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 23\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T16:01:45.695693+00:00\", \"text_length\": 1609, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow, let’s begin our story — and at the beginning, there is light.\\n\\u000bLight is part of the electromagnetic, or EM, wave spectrum, which spans an enormous range of wavelengths. We’ve already talked about the shorter wavelengths, such as gamma rays used in nuclear imaging and X-rays used in computed tomography. On the other end, we have radio waves and microwaves, which are much longer and used in applications like MRI and even cooking.\\n\\nVisible light, however, occupies only a very narrow portion of this vast spectrum. Specifically, it ranges roughly from 400 nanometers to about 1,000 nanometers in wavelength. Within this band, our eyes perceive different colors — violet, blue, green, yellow, and red — depending on the wavelength. You’ve seen this effect when light passes through a prism, spreading into a rainbow of colors.\\n\\nSome animals can detect wavelengths beyond our range. For example, certain species can see ultraviolet or even X-ray light, as confirmed by electroretinogram studies. Among humans, individual sensitivity also varies, and a small percentage of people are color-blind, perceiving only shades of gray.\\n\\nFor medical imaging, each modality uses a different part of the spectrum depending on its purpose. In optical imaging, we focus on the portion we can directly see — the visible and near-infrared range. These wavelengths penetrate tissue to a useful depth, making them ideal for studying cells, tissues, and biological processes using light. Understanding this basic physical foundation will help you appreciate how optical imaging works and why it’s such a powerful technique.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}