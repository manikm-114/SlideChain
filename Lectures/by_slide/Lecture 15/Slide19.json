{
  "lecture": "Lecture 15",
  "slide_id": "Slide19",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Images\\Slide19.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Texts\\Slide19.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide19.json",
        "parsed": {
          "term": "useful and accurate",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s walk through Example 2: Parallel-beam back-projection.\\n\\nThe code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection.\\n\\nIn this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\nNow let’s compare the results. On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\nOn the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter removes the smearing and helps reveal the actual structure.\\n\\nIf you change the phantom, such as using the Shepp–Logan phantom, you may notice that different filters give slightly different results. Some filters are better for enhancing edges, while others help reduce blurriness or noise. This is why in practice, the choice of filter depends on what details are most important for your application.\\n\\nSo this example shows us the power of filtering—without it, back-projection images can be full of artifacts, but with it, we get reconstructions that are much more useful and accurate.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Hamming filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"streaks\\\", \\\"category\\\": \\\"artifacts\\\"},\\n    {\\\"term\\\": \\\"cross pattern\\\", \\\"category\\\": \\\"artifacts\\\"},\\n    {\\\"term\\\": \\\"phantom\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"Shepp-Logan phantom\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"filtering\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"artifacts\\\", \\\"category\\\": \\\"artifacts\\\"},\\n    {\\\"term\\\": \\\"useful and accurate\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\\", \\\"On the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter\", \"parsed\": {\"term\": \"useful and accurate\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide19.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s walk through Example 2: Parallel-beam back-projection.\\n\\nThe code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection.\\n\\nIn this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\nNow let’s compare the results. On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\nOn the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter removes the smearing and helps reveal the actual structure.\\n\\nIf you change the phantom, such as using the Shepp–Logan phantom, you may notice that different filters give slightly different results. Some filters are better for enhancing edges, while others help reduce blurriness or noise. This is why in practice, the choice of filter depends on what details are most important for your application.\\n\\nSo this example shows us the power of filtering—without it, back-projection images can be full of artifacts, but with it, we get reconstructions that are much more useful and accurate.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Parallel-beam back-projection\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Filtered back-projection\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection. In this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide19.json",
        "parsed": {
          "term": "smearing",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Parallel-beam back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Hamming filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Ram-Lak\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Shepp–Logan\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Cosine\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Hann\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"artifact\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"MATLAB\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"unfiltered back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Shepp–Logan phantom\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"edges\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"background noise\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"smearing\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\":\", \"parsed\": {\"term\": \"smearing\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide19.json",
        "parsed": {
          "s": "Line 35",
          "p": "implements",
          "o": "filtered BP",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "Line 35 implements filtered BP"
          ]
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Example 2: Parallel-Beam BP\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"Ex2_parallel_back.m\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Run Ex2_parallel_back.m\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Line 32\\\",\\n      \\\"p\\\": \\\"implements\\\",\\n      \\\"o\\\": \\\"normal BP (no filter)\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Line 32 implements normal BP (no filter)\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Line 35\\\",\\n      \\\"p\\\": \\\"implements\\\",\\n      \\\"o\\\": \\\"filtered BP\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Line 35 implements filtered BP\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"filtered BP\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"Hamming filter\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"'Hamming' can be\", \"parsed\": {\"s\": \"Line 35\", \"p\": \"implements\", \"o\": \"filtered BP\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"Line 35 implements filtered BP\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide19.json",
        "parsed": {
          "term": "image quality",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:45:44.741201+00:00\", \"text_length\": 1475, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s walk through Example 2: Parallel-beam back-projection.\\n\\nThe code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection.\\n\\nIn this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\nNow let’s compare the results. On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\nOn the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter removes the smearing and helps reveal the actual structure.\\n\\nIf you change the phantom, such as using the Shepp–Logan phantom, you may notice that different filters give slightly different results. Some filters are better for enhancing edges, while others help reduce blurriness or noise. This is why in practice, the choice of filter depends on what details are most important for your application.\\n\\nSo this example shows us the power of filtering—without it, back-projection images can be full of artifacts, but with it, we get reconstructions that are much more useful and accurate.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Parallel-beam back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Hamming filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Ram-Lak filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Shepp-Logan filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Cosine filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Hann filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"artifact\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtered back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"unfiltered back-projection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"phantom\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"filtering\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"artifact reduction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"image quality\\\", \\\"category\\\": \\\"reconstruction\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Line 32 implements normal BP (no filter)\\\",\\n    \\\"Line 35 implements filtered BP\\\",\\n    \\\"'Hamming' can\", \"parsed\": {\"term\": \"image quality\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide19.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T09:13:21.426193+00:00\", \"text_length\": 1475, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s walk through Example 2: Parallel-beam back-projection.\\n\\nThe code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection.\\n\\nIn this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\nNow let’s compare the results. On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\nOn the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter removes the smearing and helps reveal the actual structure.\\n\\nIf you change the phantom, such as using the Shepp–Logan phantom, you may notice that different filters give slightly different results. Some filters are better for enhancing edges, while others help reduce blurriness or noise. This is why in practice, the choice of filter depends on what details are most important for your application.\\n\\nSo this example shows us the power of filtering—without it, back-projection images can be full of artifacts, but with it, we get reconstructions that are much more useful and accurate.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Example 2: Parallel-Beam BP\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Ex2_parallel_back.m\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Run Ex2_parallel_back.m\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide19.json",
        "parsed": {
          "term": "filtered backprojected image",
          "category": "reconstruction"
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:11:25.195966+00:00\", \"text_length\": 1475, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s walk through Example 2: Parallel-beam back-projection.\\n\\nThe code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection.\\n\\nIn this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\nNow let’s compare the results. On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\nOn the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter removes the smearing and helps reveal the actual structure.\\n\\nIf you change the phantom, such as using the Shepp–Logan phantom, you may notice that different filters give slightly different results. Some filters are better for enhancing edges, while others help reduce blurriness or noise. This is why in practice, the choice of filter depends on what details are most important for your application.\\n\\nSo this example shows us the power of filtering—without it, back-projection images can be full of artifacts, but with it, we get reconstructions that are much more useful and accurate.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Run Ex2_parallel_back.m\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Line 32 implements normal BP (no filter)\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Line 35 implements filtered BP\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"‘Hamming’ can be replaced with other filter types\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"‘Ram-Lak’\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"‘Shepp-Logan’\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"‘Cosine’\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"‘Hann’\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"backprojected image\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"filtered backprojected image\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"\", \"parsed\": {\"term\": \"filtered backprojected image\", \"category\": \"reconstruction\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide19.json",
        "parsed": {
          "s": "filtered backprojected image",
          "p": "reconstructs_with",
          "o": "filtered BP",
          "modalities": [
            "image"
          ],
          "confidence": 0.9,
          "evidence": [
            "On the right, you see the result with filtered back-projection."
          ]
        },
        "raw": "{\"slide_id\": \"Slide19\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T08:15:49.884905+00:00\", \"text_length\": 1475, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s walk through Example 2: Parallel-beam back-projection.\\n\\nThe code for this is called E x 2 parallel back dot m. Inside the script, line 32 runs a normal back-projection with no filter, and line 35 applies a filtered back-projection.\\n\\nIn this case, I’ve included the Hamming filter as an example. But MATLAB also supports other filter types, such as Ram-Lak, Shepp–Logan, Cosine, and Hann. You can even design your own filter and add it as an input if you want to experiment.\\nNow let’s compare the results. On the left, you see the reconstruction of a simple white square using unfiltered back-projection. Notice how the image shows streaks and a kind of “cross” pattern—that’s the artifact caused by overlapping unfiltered projections.\\nOn the right, you see the result with filtered back-projection. The square is much cleaner, with sharper edges and less background noise. The filter removes the smearing and helps reveal the actual structure.\\n\\nIf you change the phantom, such as using the Shepp–Logan phantom, you may notice that different filters give slightly different results. Some filters are better for enhancing edges, while others help reduce blurriness or noise. This is why in practice, the choice of filter depends on what details are most important for your application.\\n\\nSo this example shows us the power of filtering—without it, back-projection images can be full of artifacts, but with it, we get reconstructions that are much more useful and accurate.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Ex2_parallel_back.m\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"normal BP (no filter)\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"Line 32 implements normal BP (no filter)\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Ex2_parallel_back.m\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"filtered BP\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"Line 35 implements filtered BP\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"filtered backprojected image\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"filtered BP\\\",\\n      \\\"modalities\\\": [\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"On the right, you see the result with filtered back-projection.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"backprojected image\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"normal BP (no\", \"parsed\": {\"s\": \"filtered backprojected image\", \"p\": \"reconstructs_with\", \"o\": \"filtered BP\", \"modalities\": [\"image\"], \"confidence\": 0.9, \"evidence\": [\"On the right, you see the result with filtered back-projection.\"]}}"
      }
    }
  }
}