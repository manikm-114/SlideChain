{
  "lecture": "Lecture 15",
  "slide_id": "Slide15",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Images\\Slide15.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Texts\\Slide15.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide15.json",
        "parsed": {
          "term": "every possible angle",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s look at our first MATLAB example for parallel-beam CT.\\n\\nIf you’ve downloaded the materials, the code is called E x 1 parallel dot m. You can try running it now or later on your own. Inside the script, at line 5, there’s a variable called p type. By changing the p-type to 1, 2, or 3, you can switch between the three phantoms: the square, the circle with a small circle inside, or the Shepp–Logan phantom.\\n\\nHere’s what happens when you run the code. On the left, you see the image domain, in this case, just a simple white square. As the red arrow rotates, it represents the projection angle, which we call theta. Each angle contributes new data to the sinogram.\\nOn the right, you see the sinogram domain. Notice how information is gradually added as theta changes. For the square, the sinogram has a symmetric, crisscrossing pattern.\\n\\nIf you switch to the second phantom—the large circle with a small white dot—the sinogram looks different. The small dot produces a wavy curve in the sinogram because the detector gets closer to and farther from the dot as it rotates.\\n\\nFinally, with the Shepp–Logan phantom, the sinogram becomes much more complex. There are many structures inside that phantom, and each one leaves its signature on the sinogram. This complexity is much closer to what you would see in a real CT scan of the human brain, where multiple tissues and structures contribute overlapping patterns.\\n\\nSo the sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"MATLAB\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"parallel-beam CT\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"sinogram\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"projection angle\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"Shepp-Logan phantom\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"sinogram domain\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"image domain\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"white square\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"red arrow\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"theta\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"wavy curve\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"complexity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"object\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"every possible angle\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Let’s look at our first MATLAB example for parallel-beam CT.\\\", \\n               \\\"If you’ve downloaded the materials, the\", \"parsed\": {\"term\": \"every possible angle\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide15.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s look at our first MATLAB example for parallel-beam CT.\\n\\nIf you’ve downloaded the materials, the code is called E x 1 parallel dot m. You can try running it now or later on your own. Inside the script, at line 5, there’s a variable called p type. By changing the p-type to 1, 2, or 3, you can switch between the three phantoms: the square, the circle with a small circle inside, or the Shepp–Logan phantom.\\n\\nHere’s what happens when you run the code. On the left, you see the image domain, in this case, just a simple white square. As the red arrow rotates, it represents the projection angle, which we call theta. Each angle contributes new data to the sinogram.\\nOn the right, you see the sinogram domain. Notice how information is gradually added as theta changes. For the square, the sinogram has a symmetric, crisscrossing pattern.\\n\\nIf you switch to the second phantom—the large circle with a small white dot—the sinogram looks different. The small dot produces a wavy curve in the sinogram because the detector gets closer to and farther from the dot as it rotates.\\n\\nFinally, with the Shepp–Logan phantom, the sinogram becomes much more complex. There are many structures inside that phantom, and each one leaves its signature on the sinogram. This complexity is much closer to what you would see in a real CT scan of the human brain, where multiple tissues and structures contribute overlapping patterns.\\n\\nSo the sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"MATLAB code\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"code\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"You can try running it now or later on your own.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide15.json",
        "parsed": {
          "term": "detector",
          "category": "instrumentation"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"parallel-beam CT\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"MATLAB\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"projection angle\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"sinogram\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"phantom\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"Shepp–Logan phantom\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"rotation angle\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"square\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"circle\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"detector\\\", \\\"category\\\": \\\"instrumentation\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Let’s look at our first MATLAB example for parallel-beam CT.\\\",\\n    \\\"the code is called E x 1 parallel dot m.\\\",\\n    \\\"projection angle, which we call theta.\\\",\\n    \\\"On the right, you see the sinogram domain.\\\",\\n    \\\"switch between the three phantoms: the square, the circle with a small circle inside\", \"parsed\": {\"term\": \"detector\", \"category\": \"instrumentation\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide15.json",
        "parsed": {
          "s": "sinogram",
          "p": "produces",
          "o": "information",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "As θ (red arrow) is changing, information is added to the sinogram!"
          ]
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Example 1: Parallel beam\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"Ex1_parallel.m\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Run Ex1_parallel.m\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"theta (red arrow)\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"projection angle\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"As θ (red arrow) is changing, information is added to the sinogram!\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"sinogram\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"information\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"As θ (red arrow) is changing, information is added to the sinogram!\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"p_type (Line 5)\\\",\\n      \\\"p\\\": \\\"depends_on\\\",\\n      \\\"o\\\": \\\"sample types\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.\", \"parsed\": {\"s\": \"sinogram\", \"p\": \"produces\", \"o\": \"information\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"As θ (red arrow) is changing, information is added to the sinogram!\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide15.json",
        "parsed": {
          "term": "overlapping patterns",
          "category": "data_processing"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:40:04.812395+00:00\", \"text_length\": 1525, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s look at our first MATLAB example for parallel-beam CT.\\n\\nIf you’ve downloaded the materials, the code is called E x 1 parallel dot m. You can try running it now or later on your own. Inside the script, at line 5, there’s a variable called p type. By changing the p-type to 1, 2, or 3, you can switch between the three phantoms: the square, the circle with a small circle inside, or the Shepp–Logan phantom.\\n\\nHere’s what happens when you run the code. On the left, you see the image domain, in this case, just a simple white square. As the red arrow rotates, it represents the projection angle, which we call theta. Each angle contributes new data to the sinogram.\\nOn the right, you see the sinogram domain. Notice how information is gradually added as theta changes. For the square, the sinogram has a symmetric, crisscrossing pattern.\\n\\nIf you switch to the second phantom—the large circle with a small white dot—the sinogram looks different. The small dot produces a wavy curve in the sinogram because the detector gets closer to and farther from the dot as it rotates.\\n\\nFinally, with the Shepp–Logan phantom, the sinogram becomes much more complex. There are many structures inside that phantom, and each one leaves its signature on the sinogram. This complexity is much closer to what you would see in a real CT scan of the human brain, where multiple tissues and structures contribute overlapping patterns.\\n\\nSo the sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"parallel-beam CT\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"sinogram\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"projection angle\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"phantom\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"theta\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"detector\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"rotation angle\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"complexity\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"real CT scan\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"human brain\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"signature\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"overlapping patterns\\\", \\\"category\\\": \\\"data_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"As the red arrow rotates, it represents the projection angle, which we call theta.\\\",\\n    \\\"Each angle contributes new data to the sinogram.\\\",\\n    \\\"The sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\\",\\n    \\\"The sinogram becomes\", \"parsed\": {\"term\": \"overlapping patterns\", \"category\": \"data_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide15.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T09:11:03.735932+00:00\", \"text_length\": 1525, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s look at our first MATLAB example for parallel-beam CT.\\n\\nIf you’ve downloaded the materials, the code is called E x 1 parallel dot m. You can try running it now or later on your own. Inside the script, at line 5, there’s a variable called p type. By changing the p-type to 1, 2, or 3, you can switch between the three phantoms: the square, the circle with a small circle inside, or the Shepp–Logan phantom.\\n\\nHere’s what happens when you run the code. On the left, you see the image domain, in this case, just a simple white square. As the red arrow rotates, it represents the projection angle, which we call theta. Each angle contributes new data to the sinogram.\\nOn the right, you see the sinogram domain. Notice how information is gradually added as theta changes. For the square, the sinogram has a symmetric, crisscrossing pattern.\\n\\nIf you switch to the second phantom—the large circle with a small white dot—the sinogram looks different. The small dot produces a wavy curve in the sinogram because the detector gets closer to and farther from the dot as it rotates.\\n\\nFinally, with the Shepp–Logan phantom, the sinogram becomes much more complex. There are many structures inside that phantom, and each one leaves its signature on the sinogram. This complexity is much closer to what you would see in a real CT scan of the human brain, where multiple tissues and structures contribute overlapping patterns.\\n\\nSo the sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide15.json",
        "parsed": {
          "term": "the Shepp-Logan phantom",
          "category": "anatomy"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:10:44.846194+00:00\", \"text_length\": 1525, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s look at our first MATLAB example for parallel-beam CT.\\n\\nIf you’ve downloaded the materials, the code is called E x 1 parallel dot m. You can try running it now or later on your own. Inside the script, at line 5, there’s a variable called p type. By changing the p-type to 1, 2, or 3, you can switch between the three phantoms: the square, the circle with a small circle inside, or the Shepp–Logan phantom.\\n\\nHere’s what happens when you run the code. On the left, you see the image domain, in this case, just a simple white square. As the red arrow rotates, it represents the projection angle, which we call theta. Each angle contributes new data to the sinogram.\\nOn the right, you see the sinogram domain. Notice how information is gradually added as theta changes. For the square, the sinogram has a symmetric, crisscrossing pattern.\\n\\nIf you switch to the second phantom—the large circle with a small white dot—the sinogram looks different. The small dot produces a wavy curve in the sinogram because the detector gets closer to and farther from the dot as it rotates.\\n\\nFinally, with the Shepp–Logan phantom, the sinogram becomes much more complex. There are many structures inside that phantom, and each one leaves its signature on the sinogram. This complexity is much closer to what you would see in a real CT scan of the human brain, where multiple tissues and structures contribute overlapping patterns.\\n\\nSo the sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Run Ex1_parallel.m\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"As θ (red arrow) is changing, information is added to the sinogram!\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Image domain\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Sinogram\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Change p_type (Line 5) to 1, 2, or 3 for different sample types\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"projection angle, which we call theta\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"the sinogram is really just another way of saying: here’s how the object looks from every possible angle\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"the Shepp–Logan phantom\\\",\\n      \\\"category\\\": \\\"anatomy\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"the large circle with a small white dot\\\",\\n      \\\"category\\\": \\\"anatomy\\\"\", \"parsed\": {\"term\": \"the Shepp-Logan phantom\", \"category\": \"anatomy\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide15.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T08:15:15.795312+00:00\", \"text_length\": 1525, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nLet’s look at our first MATLAB example for parallel-beam CT.\\n\\nIf you’ve downloaded the materials, the code is called E x 1 parallel dot m. You can try running it now or later on your own. Inside the script, at line 5, there’s a variable called p type. By changing the p-type to 1, 2, or 3, you can switch between the three phantoms: the square, the circle with a small circle inside, or the Shepp–Logan phantom.\\n\\nHere’s what happens when you run the code. On the left, you see the image domain, in this case, just a simple white square. As the red arrow rotates, it represents the projection angle, which we call theta. Each angle contributes new data to the sinogram.\\nOn the right, you see the sinogram domain. Notice how information is gradually added as theta changes. For the square, the sinogram has a symmetric, crisscrossing pattern.\\n\\nIf you switch to the second phantom—the large circle with a small white dot—the sinogram looks different. The small dot produces a wavy curve in the sinogram because the detector gets closer to and farther from the dot as it rotates.\\n\\nFinally, with the Shepp–Logan phantom, the sinogram becomes much more complex. There are many structures inside that phantom, and each one leaves its signature on the sinogram. This complexity is much closer to what you would see in a real CT scan of the human brain, where multiple tissues and structures contribute overlapping patterns.\\n\\nSo the sinogram is really just another way of saying: here’s how the object looks from every possible angle.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"As θ (red arrow) is changing\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"information added to the sinogram\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"As θ (red arrow) is changing, information is added to the sinogram!\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}