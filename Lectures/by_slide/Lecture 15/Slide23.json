{
  "lecture": "Lecture 15",
  "slide_id": "Slide23",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Images\\Slide23.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Texts\\Slide23.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide23.json",
        "parsed": {
          "term": "scanner geometry",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s look at the fanbeam function in MATLAB in more detail.\\n\\nThis function calculates projection data for a specified fan-beam geometry. Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees. That means you can’t restrict the scan to only half a circle, like 0 to 180, or just 0 to 45. The fanbeam function always assumes a full rotation.\\n\\nHere’s what the function looks like:\\nF1, sensor pos 1, fan rot angles 1] equals fan beam P, D, ‘Fan Sensor Spacing', dsensor1;\\nLet’s break it down:\\nF1 is the fan-beam projection data, the main output you need.\\nSensor pos 1 gives the positions of the detectors.\\nFan rot angles 1 lists the rotation angles used.\\nP is your input image, or phantom.\\nD is the distance from the source vertex to the object’s center of rotation.\\n‘Fan Sensor Spacing' is a property name, which tells MATLAB you’re specifying the spacing between detectors.\\nDsensor 1 is the actual spacing value.\\n\\nThose last two inputs are optional. You can run the function with just the image and the distance, and MATLAB will use default detector spacing. But if you want more control—say, to change the resolution or field of view—you can specify these additional arguments.\\nSo in short: fanbeam gives you projection data over a full 360 degrees, with flexibility to adjust sensor spacing if needed.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"fanbeam\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"projection data\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"MATLAB\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"rotation angles\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"detectors\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"image\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"phantom\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"distance\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"field of view\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"resolution\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"scanner\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"scanner geometry\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Now let’s look at the fanbeam function in MATLAB in more detail.\\\", \\n               \\\"This function calculates projection data for a specified fan-beam geometry.\\\", \\n               \\\"Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees.\\\", \\n               \\\"Those last\", \"parsed\": {\"term\": \"scanner geometry\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide23.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s look at the fanbeam function in MATLAB in more detail.\\n\\nThis function calculates projection data for a specified fan-beam geometry. Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees. That means you can’t restrict the scan to only half a circle, like 0 to 180, or just 0 to 45. The fanbeam function always assumes a full rotation.\\n\\nHere’s what the function looks like:\\nF1, sensor pos 1, fan rot angles 1] equals fan beam P, D, ‘Fan Sensor Spacing', dsensor1;\\nLet’s break it down:\\nF1 is the fan-beam projection data, the main output you need.\\nSensor pos 1 gives the positions of the detectors.\\nFan rot angles 1 lists the rotation angles used.\\nP is your input image, or phantom.\\nD is the distance from the source vertex to the object’s center of rotation.\\n‘Fan Sensor Spacing' is a property name, which tells MATLAB you’re specifying the spacing between detectors.\\nDsensor 1 is the actual spacing value.\\n\\nThose last two inputs are optional. You can run the function with just the image and the distance, and MATLAB will use default detector spacing. But if you want more control—say, to change the resolution or field of view—you can specify these additional arguments.\\nSo in short: fanbeam gives you projection data over a full 360 degrees, with flexibility to adjust sensor spacing if needed.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"fanbeam function\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"projection data\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Calculates projection data for a specified fan-beam geometry.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide23.json",
        "parsed": {
          "concepts": [
            {
              "term": "fanbeam function",
              "category": "software"
            },
            {
              "term": "projection data",
              "category": "data_processing"
            },
            {
              "term": "fan-beam geometry",
              "category": "modality"
            },
            {
              "term": "rotation angles",
              "category": "instrumentation"
            },
            {
              "term": "input image",
              "category": "data_processing"
            },
            {
              "term": "detector spacing",
              "category": "instrumentation"
            },
            {
              "term": "full rotation",
              "category": "workflow"
            }
          ],
          "evidence": [
            "This function calculates projection data for a specified fan-beam geometry.",
            "Rotation angles (θ) fixed at 0 to 360 degrees",
            "sensor positions",
            "input image",
            "distance to object",
            "spacing between sensors",
            "always assumes a full rotation"
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"fanbeam function\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"projection data\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"fan-beam geometry\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"rotation angles\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"sensor positions\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"input image\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"distance to object\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"detector spacing\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"full rotation\\\", \\\"category\\\": \\\"workflow\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"This function calculates projection data for a specified fan-beam geometry.\\\",\\n    \\\"Rotation angles (θ) fixed at 0 to 360 degrees\\\",\\n    \\\"sensor positions\\\",\\n    \\\"input image\\\",\\n    \\\"distance to object\\\",\\n    \\\"spacing between sensors\\\",\\n    \\\"always assumes a full rotation\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"fanbeam function\", \"category\": \"software\"}, {\"term\": \"projection data\", \"category\": \"data_processing\"}, {\"term\": \"fan-beam geometry\", \"category\": \"modality\"}, {\"term\": \"rotation angles\", \"category\": \"instrumentation\"}, {\"term\": \"input image\", \"category\": \"data_processing\"}, {\"term\": \"detector spacing\", \"category\": \"instrumentation\"}, {\"term\": \"full rotation\", \"category\": \"workflow\"}], \"evidence\": [\"This function calculates projection data for a specified fan-beam geometry.\", \"Rotation angles (θ) fixed at 0 to 360 degrees\", \"sensor positions\", \"input image\", \"distance to object\", \"spacing between sensors\", \"always assumes a full rotation\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide23.json",
        "parsed": {
          "s": "fanbeam function",
          "p": "uses",
          "o": "distance to object (D)",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "D is the distance from the source vertex to the object’s center of rotation."
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"fanbeam function\\\", \\\"p\\\":\\\"produces\\\", \\\"o\\\":\\\"projection data\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"This function calculates projection data for a specified fan-beam geometry.\\\"},\\n    {\\\"s\\\":\\\"fanbeam function\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"rotation angles (θ) fixed at 0 to 360 degrees\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Rotation angles (θ) fixed at 0 to 360 degrees\\\"},\\n    {\\\"s\\\":\\\"fanbeam function\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"input image (P)\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"P is your input image, or phantom.\\\"},\\n    {\\\"s\\\":\\\"fanbeam function\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"distance to object (D)\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"D is the distance from the source vertex to the object’s center of rotation.\\\"},\\n    {\\\"s\\\":\\\"fanbeam function\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"FanSensorSpacing\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0\", \"parsed\": {\"s\": \"fanbeam function\", \"p\": \"uses\", \"o\": \"distance to object (D)\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"D is the distance from the source vertex to the object’s center of rotation.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide23.json",
        "parsed": {
          "term": "flexibility to adjust sensor spacing",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:52:10.334316+00:00\", \"text_length\": 1339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s look at the fanbeam function in MATLAB in more detail.\\n\\nThis function calculates projection data for a specified fan-beam geometry. Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees. That means you can’t restrict the scan to only half a circle, like 0 to 180, or just 0 to 45. The fanbeam function always assumes a full rotation.\\n\\nHere’s what the function looks like:\\nF1, sensor pos 1, fan rot angles 1] equals fan beam P, D, ‘Fan Sensor Spacing', dsensor1;\\nLet’s break it down:\\nF1 is the fan-beam projection data, the main output you need.\\nSensor pos 1 gives the positions of the detectors.\\nFan rot angles 1 lists the rotation angles used.\\nP is your input image, or phantom.\\nD is the distance from the source vertex to the object’s center of rotation.\\n‘Fan Sensor Spacing' is a property name, which tells MATLAB you’re specifying the spacing between detectors.\\nDsensor 1 is the actual spacing value.\\n\\nThose last two inputs are optional. You can run the function with just the image and the distance, and MATLAB will use default detector spacing. But if you want more control—say, to change the resolution or field of view—you can specify these additional arguments.\\nSo in short: fanbeam gives you projection data over a full 360 degrees, with flexibility to adjust sensor spacing if needed.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"fanbeam\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"projection data\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"fan-beam geometry\\\", \\\"category\\\": \\\"geometry\\\"},\\n    {\\\"term\\\": \\\"rotation angles\\\", \\\"category\\\": \\\"geometry\\\"},\\n    {\\\"term\\\": \\\"sensor positions\\\", \\\"category\\\": \\\"geometry\\\"},\\n    {\\\"term\\\": \\\"fan rotation angles\\\", \\\"category\\\": \\\"geometry\\\"},\\n    {\\\"term\\\": \\\"input image\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"distance to object\\\", \\\"category\\\": \\\"geometry\\\"},\\n    {\\\"term\\\": \\\"Fan Sensor Spacing\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Dsensor1\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"full 360 degrees\\\", \\\"category\\\": \\\"geometry\\\"},\\n    {\\\"term\\\": \\\"flexibility to adjust sensor spacing\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Calculates projection data for a specified fan beam geometry\\\",\\n    \\\"Rotation angles (θ) fixed at 0 to 360 degrees\\\",\\n    \\\"F1, sensor_pos1, fan_rot_angles1] equals fanbeam(P, D, ‘Fan\", \"parsed\": {\"term\": \"flexibility to adjust sensor spacing\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide23.json",
        "parsed": {
          "triples": [
            {
              "s": "fanbeam",
              "p": "uses",
              "o": "projection data",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 0.0,
              "evidence": "Calculates projection data for a specified fan beam geometry"
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T09:15:29.253531+00:00\", \"text_length\": 1339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s look at the fanbeam function in MATLAB in more detail.\\n\\nThis function calculates projection data for a specified fan-beam geometry. Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees. That means you can’t restrict the scan to only half a circle, like 0 to 180, or just 0 to 45. The fanbeam function always assumes a full rotation.\\n\\nHere’s what the function looks like:\\nF1, sensor pos 1, fan rot angles 1] equals fan beam P, D, ‘Fan Sensor Spacing', dsensor1;\\nLet’s break it down:\\nF1 is the fan-beam projection data, the main output you need.\\nSensor pos 1 gives the positions of the detectors.\\nFan rot angles 1 lists the rotation angles used.\\nP is your input image, or phantom.\\nD is the distance from the source vertex to the object’s center of rotation.\\n‘Fan Sensor Spacing' is a property name, which tells MATLAB you’re specifying the spacing between detectors.\\nDsensor 1 is the actual spacing value.\\n\\nThose last two inputs are optional. You can run the function with just the image and the distance, and MATLAB will use default detector spacing. But if you want more control—say, to change the resolution or field of view—you can specify these additional arguments.\\nSo in short: fanbeam gives you projection data over a full 360 degrees, with flexibility to adjust sensor spacing if needed.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"fanbeam\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"projection data\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Calculates projection data for a specified fan beam geometry\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"fanbeam\", \"p\": \"uses\", \"o\": \"projection data\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.0, \"evidence\": \"Calculates projection data for a specified fan beam geometry\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide23.json",
        "parsed": {
          "term": "FanSensorSpacing, dsensor1 are optional",
          "category": "software"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T08:12:06.594346+00:00\", \"text_length\": 1339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s look at the fanbeam function in MATLAB in more detail.\\n\\nThis function calculates projection data for a specified fan-beam geometry. Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees. That means you can’t restrict the scan to only half a circle, like 0 to 180, or just 0 to 45. The fanbeam function always assumes a full rotation.\\n\\nHere’s what the function looks like:\\nF1, sensor pos 1, fan rot angles 1] equals fan beam P, D, ‘Fan Sensor Spacing', dsensor1;\\nLet’s break it down:\\nF1 is the fan-beam projection data, the main output you need.\\nSensor pos 1 gives the positions of the detectors.\\nFan rot angles 1 lists the rotation angles used.\\nP is your input image, or phantom.\\nD is the distance from the source vertex to the object’s center of rotation.\\n‘Fan Sensor Spacing' is a property name, which tells MATLAB you’re specifying the spacing between detectors.\\nDsensor 1 is the actual spacing value.\\n\\nThose last two inputs are optional. You can run the function with just the image and the distance, and MATLAB will use default detector spacing. But if you want more control—say, to change the resolution or field of view—you can specify these additional arguments.\\nSo in short: fanbeam gives you projection data over a full 360 degrees, with flexibility to adjust sensor spacing if needed.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Calculates projection data for a specified fan beam geometry\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Rotation angles (θ) fixed at 0 to 360 degrees\\\",\\n      \\\"category\\\": \\\"workflow\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"F1 - output\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"sensor_pos1 - sensor positions\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"fan_rot_angles1 - fan rotation angles\\\",\\n      \\\"category\\\": \\\"workflow\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"P - input image\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"D - distance to object\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"FanSensorSpacing - specific property\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Dsensor1- spacing between sensors\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"FanSensorSpacing, dsensor1 are optional\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    },\", \"parsed\": {\"term\": \"FanSensorSpacing, dsensor1 are optional\", \"category\": \"software\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 15\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide23.json",
        "parsed": {
          "s": "fanbeam",
          "p": "uses",
          "o": "distance to object",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.95,
          "evidence": [
            "D - distance to object"
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T08:16:26.638690+00:00\", \"text_length\": 1339, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow let’s look at the fanbeam function in MATLAB in more detail.\\n\\nThis function calculates projection data for a specified fan-beam geometry. Unlike the parallel-beam case, here the rotation angles are fixed from 0 to 360 degrees. That means you can’t restrict the scan to only half a circle, like 0 to 180, or just 0 to 45. The fanbeam function always assumes a full rotation.\\n\\nHere’s what the function looks like:\\nF1, sensor pos 1, fan rot angles 1] equals fan beam P, D, ‘Fan Sensor Spacing', dsensor1;\\nLet’s break it down:\\nF1 is the fan-beam projection data, the main output you need.\\nSensor pos 1 gives the positions of the detectors.\\nFan rot angles 1 lists the rotation angles used.\\nP is your input image, or phantom.\\nD is the distance from the source vertex to the object’s center of rotation.\\n‘Fan Sensor Spacing' is a property name, which tells MATLAB you’re specifying the spacing between detectors.\\nDsensor 1 is the actual spacing value.\\n\\nThose last two inputs are optional. You can run the function with just the image and the distance, and MATLAB will use default detector spacing. But if you want more control—say, to change the resolution or field of view—you can specify these additional arguments.\\nSo in short: fanbeam gives you projection data over a full 360 degrees, with flexibility to adjust sensor spacing if needed.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"fanbeam\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"projection data\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Calculates projection data for a specified fan beam geometry\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"fanbeam\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"input image\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"P - input image\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"fanbeam\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"distance to object\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"D - distance to object\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"fanbeam\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"FanSensorSpacing\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0\", \"parsed\": {\"s\": \"fanbeam\", \"p\": \"uses\", \"o\": \"distance to object\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.95, \"evidence\": [\"D - distance to object\"]}}"
      }
    }
  }
}