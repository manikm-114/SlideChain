{
  "lecture": "Lecture 22",
  "slide_id": "Slide7",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Images\\Slide7.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Texts\\Slide7.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide7.json",
        "parsed": {
          "term": "pencil-beam X-ray imaging",
          "category": "physics"
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the last one—and I would say—is C-mode, C for coronal image. You know, three-dimensionally, if you cut a patient with a virtual plane this way, we usually call that the transverse plane. If you cut the patient this way, you call it sagittal. But if you cut the patient this way—think I am facing you and you cut like this—that is called the coronal image. So you have three views. I will show some images.\\n\\nYou do A-mode imaging along this direction. You have all the information, and the spatial dimension along this direction is your coordinate system—just one axis. But you can do some echo-gated imaging. You send the pulse in that direction, you wait a certain amount of time, then you see—within a small time window—if the echo comes back. Given the delay time, you really target a specific depth. So from this one line, you roughly calculate: the ultrasound goes a round trip from the transducer to the plane and back. Suppose this round-trip time is, for example, 100 microseconds—let’s say 100 milliseconds in my example. You only see the amplitude at 100 microseconds. That is the round-trip echo time—the echo goes here, hits the plane, comes back—so, 100 microseconds.\\n\\nThis 100-microsecond sample is reported as your pixel value. Then, on this two-dimensional coronal plane, you keep scanning—line by line, pixel by pixel. You make sure the round-trip time is targeted to that depth position. You put all these amplitude values together, and you form a two-dimensional image. That is the so-called coronal image.\\n\\nHere is an example: you have a hand here. You put the ultrasound into the hand, and you record the echoes. With all the timing coordinated right, you form an internal image that cuts through the hand. You can see certain pieces of bone. There is some terminology I just learned—metacarpals—these light-blue bones; you can see these light-blue bones. The transducer is operated in C-mode here. There are some good ideas; details are in this article.\\n\\nYou have the image—the image is really formed here. Then the image in a pixel here is reflected by a half-silvered mirror and viewed by the reader or doctor. Through this half-silvered mirror, you see the patient’s body, and the image you see is really superimposed onto the patient’s internal structure. It gives you the illusion that you see into the patient directly—you see the beating heart—and you can maybe use this as guidance to put the catheter there, make a blood vessel open wider.\\n\\nThis is a good idea. It kind of works with augmented-reality things, and it’s a good idea. But the C-mode has nothing to do with this viewer. C-mode can be understood only with this sub-figure—so that’s the idea. And ultrasound imaging so far is straightforward. I have explained to you A, B, C, M—so you see later, a word you need to remember.\\n\\nOK, this is a single-crystal–based transducer that can be used to do all these kinds of things. But when you want to form two-dimensional images, you need an easy scan, or you need to do multiple times—so you have a time dimension. With the time dimension, with a single transducer, you can still form two-dimensional images. Certainly, this is quite a lot like pencil-beam X-ray imaging. In the first generation, you have a pencil beam of X-rays and a single detector; you can do a scan. That is very inefficient.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"A-mode imaging\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"C-mode imaging\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"echo-gated imaging\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"round-trip echo time\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pixel value\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"two-dimensional coronal plane\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"coronal image\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"metacarpals\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"half-silvered mirror\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"single-crystal-based transducer\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"two-dimensional images\\\", \\\"category\\\": \\\"image_processing\\\"},\\n    {\\\"term\\\": \\\"time dimension\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pencil-beam X-ray imaging\\\", \\\"category\\\": \\\"physics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"You do A-mode imaging along this direction.\\\", \\n               \\\"You have the image—the image\", \"parsed\": {\"term\": \"pencil-beam X-ray imaging\", \"category\": \"physics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide7.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the last one—and I would say—is C-mode, C for coronal image. You know, three-dimensionally, if you cut a patient with a virtual plane this way, we usually call that the transverse plane. If you cut the patient this way, you call it sagittal. But if you cut the patient this way—think I am facing you and you cut like this—that is called the coronal image. So you have three views. I will show some images.\\n\\nYou do A-mode imaging along this direction. You have all the information, and the spatial dimension along this direction is your coordinate system—just one axis. But you can do some echo-gated imaging. You send the pulse in that direction, you wait a certain amount of time, then you see—within a small time window—if the echo comes back. Given the delay time, you really target a specific depth. So from this one line, you roughly calculate: the ultrasound goes a round trip from the transducer to the plane and back. Suppose this round-trip time is, for example, 100 microseconds—let’s say 100 milliseconds in my example. You only see the amplitude at 100 microseconds. That is the round-trip echo time—the echo goes here, hits the plane, comes back—so, 100 microseconds.\\n\\nThis 100-microsecond sample is reported as your pixel value. Then, on this two-dimensional coronal plane, you keep scanning—line by line, pixel by pixel. You make sure the round-trip time is targeted to that depth position. You put all these amplitude values together, and you form a two-dimensional image. That is the so-called coronal image.\\n\\nHere is an example: you have a hand here. You put the ultrasound into the hand, and you record the echoes. With all the timing coordinated right, you form an internal image that cuts through the hand. You can see certain pieces of bone. There is some terminology I just learned—metacarpals—these light-blue bones; you can see these light-blue bones. The transducer is operated in C-mode here. There are some good ideas; details are in this article.\\n\\nYou have the image—the image is really formed here. Then the image in a pixel here is reflected by a half-silvered mirror and viewed by the reader or doctor. Through this half-silvered mirror, you see the patient’s body, and the image you see is really superimposed onto the patient’s internal structure. It gives you the illusion that you see into the patient directly—you see the beating heart—and you can maybe use this as guidance to put the catheter there, make a blood vessel open wider.\\n\\nThis is a good idea. It kind of works with augmented-reality things, and it’s a good idea. But the C-mode has nothing to do with this viewer. C-mode can be understood only with this sub-figure—so that’s the idea. And ultrasound imaging so far is straightforward. I have explained to you A, B, C, M—so you see later, a word you need to remember.\\n\\nOK, this is a single-crystal–based transducer that can be used to do all these kinds of things. But when you want to form two-dimensional images, you need an easy scan, or you need to do multiple times—so you have a time dimension. With the time dimension, with a single transducer, you can still form two-dimensional images. Certainly, this is quite a lot like pencil-beam X-ray imaging. In the first generation, you have a pencil beam of X-rays and a single detector; you can do a scan. That is very inefficient.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n```json\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"ultrasound imaging\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"C-mode imaging\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"'...C-mode imaging is a way to form two-dimensional images by scanning the patient with a transducer in a specific direction.'\\\"}\\n  ]\\n}\\n```\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide7.json",
        "parsed": {
          "term": "single-crystal-based transducer",
          "category": "instrumentation"
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"C-mode imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"coronal image\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"A-mode data\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"half-silvered mirror\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"3D ultrasound scan\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"echo-gated imaging\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"round-trip echo time\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"metacarpals\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"ultrasound transducer\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"pixel value\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"two-dimensional coronal plane\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"single-crystal–based transducer\\\", \\\"category\\\": \\\"instrumentation\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth.\\\",\\n    \\\"Phalanges\\\",\\n    \\\"Metacarpals\\\",\", \"parsed\": {\"term\": \"single-crystal-based transducer\", \"category\": \"instrumentation\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide7.json",
        "parsed": {
          "s": "C-mode imaging",
          "p": "reconstructs_with",
          "o": "A-mode data",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "C-mode imaging produces a coronal image by gating A-mode data to a specific depth."
          ]
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"C-mode imaging\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"coronal image\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"half-silvered mirror\\\",\\n      \\\"p\\\": \\\"used to\\\",\\n      \\\"o\\\": \\\"merge the body surface with his/her interior\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"A half-silvered mirror can be used to merge the body surface with his/her interior without a head-mounted display.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"C-mode imaging\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"A-mode data\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"C-mode slice\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"\", \"parsed\": {\"s\": \"C-mode imaging\", \"p\": \"reconstructs_with\", \"o\": \"A-mode data\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide7.json",
        "parsed": {
          "term": "pencil-beam X-ray imaging",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T17:20:03.271264+00:00\", \"text_length\": 3336, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the last one—and I would say—is C-mode, C for coronal image. You know, three-dimensionally, if you cut a patient with a virtual plane this way, we usually call that the transverse plane. If you cut the patient this way, you call it sagittal. But if you cut the patient this way—think I am facing you and you cut like this—that is called the coronal image. So you have three views. I will show some images.\\n\\nYou do A-mode imaging along this direction. You have all the information, and the spatial dimension along this direction is your coordinate system—just one axis. But you can do some echo-gated imaging. You send the pulse in that direction, you wait a certain amount of time, then you see—within a small time window—if the echo comes back. Given the delay time, you really target a specific depth. So from this one line, you roughly calculate: the ultrasound goes a round trip from the transducer to the plane and back. Suppose this round-trip time is, for example, 100 microseconds—let’s say 100 milliseconds in my example. You only see the amplitude at 100 microseconds. That is the round-trip echo time—the echo goes here, hits the plane, comes back—so, 100 microseconds.\\n\\nThis 100-microsecond sample is reported as your pixel value. Then, on this two-dimensional coronal plane, you keep scanning—line by line, pixel by pixel. You make sure the round-trip time is targeted to that depth position. You put all these amplitude values together, and you form a two-dimensional image. That is the so-called coronal image.\\n\\nHere is an example: you have a hand here. You put the ultrasound into the hand, and you record the echoes. With all the timing coordinated right, you form an internal image that cuts through the hand. You can see certain pieces of bone. There is some terminology I just learned—metacarpals—these light-blue bones; you can see these light-blue bones. The transducer is operated in C-mode here. There are some good ideas; details are in this article.\\n\\nYou have the image—the image is really formed here. Then the image in a pixel here is reflected by a half-silvered mirror and viewed by the reader or doctor. Through this half-silvered mirror, you see the patient’s body, and the image you see is really superimposed onto the patient’s internal structure. It gives you the illusion that you see into the patient directly—you see the beating heart—and you can maybe use this as guidance to put the catheter there, make a blood vessel open wider.\\n\\nThis is a good idea. It kind of works with augmented-reality things, and it’s a good idea. But the C-mode has nothing to do with this viewer. C-mode can be understood only with this sub-figure—so that’s the idea. And ultrasound imaging so far is straightforward. I have explained to you A, B, C, M—so you see later, a word you need to remember.\\n\\nOK, this is a single-crystal–based transducer that can be used to do all these kinds of things. But when you want to form two-dimensional images, you need an easy scan, or you need to do multiple times—so you have a time dimension. With the time dimension, with a single transducer, you can still form two-dimensional images. Certainly, this is quite a lot like pencil-beam X-ray imaging. In the first generation, you have a pencil beam of X-rays and a single detector; you can do a scan. That is very inefficient.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"C-mode\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"A-mode imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"coronal image\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"transverse plane\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"sagittal plane\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"ultrasound imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"echo-gated imaging\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"round-trip time\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coronal image formation\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"half-silvered mirror\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"augmented reality\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"single-crystal-based transducer\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"time dimension\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pencil-beam X-ray imaging\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"single detector\\\", \\\"category\\\": \\\"signal_processing\", \"parsed\": {\"term\": \"pencil-beam X-ray imaging\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide7.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T18:36:00.364040+00:00\", \"text_length\": 3336, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the last one—and I would say—is C-mode, C for coronal image. You know, three-dimensionally, if you cut a patient with a virtual plane this way, we usually call that the transverse plane. If you cut the patient this way, you call it sagittal. But if you cut the patient this way—think I am facing you and you cut like this—that is called the coronal image. So you have three views. I will show some images.\\n\\nYou do A-mode imaging along this direction. You have all the information, and the spatial dimension along this direction is your coordinate system—just one axis. But you can do some echo-gated imaging. You send the pulse in that direction, you wait a certain amount of time, then you see—within a small time window—if the echo comes back. Given the delay time, you really target a specific depth. So from this one line, you roughly calculate: the ultrasound goes a round trip from the transducer to the plane and back. Suppose this round-trip time is, for example, 100 microseconds—let’s say 100 milliseconds in my example. You only see the amplitude at 100 microseconds. That is the round-trip echo time—the echo goes here, hits the plane, comes back—so, 100 microseconds.\\n\\nThis 100-microsecond sample is reported as your pixel value. Then, on this two-dimensional coronal plane, you keep scanning—line by line, pixel by pixel. You make sure the round-trip time is targeted to that depth position. You put all these amplitude values together, and you form a two-dimensional image. That is the so-called coronal image.\\n\\nHere is an example: you have a hand here. You put the ultrasound into the hand, and you record the echoes. With all the timing coordinated right, you form an internal image that cuts through the hand. You can see certain pieces of bone. There is some terminology I just learned—metacarpals—these light-blue bones; you can see these light-blue bones. The transducer is operated in C-mode here. There are some good ideas; details are in this article.\\n\\nYou have the image—the image is really formed here. Then the image in a pixel here is reflected by a half-silvered mirror and viewed by the reader or doctor. Through this half-silvered mirror, you see the patient’s body, and the image you see is really superimposed onto the patient’s internal structure. It gives you the illusion that you see into the patient directly—you see the beating heart—and you can maybe use this as guidance to put the catheter there, make a blood vessel open wider.\\n\\nThis is a good idea. It kind of works with augmented-reality things, and it’s a good idea. But the C-mode has nothing to do with this viewer. C-mode can be understood only with this sub-figure—so that’s the idea. And ultrasound imaging so far is straightforward. I have explained to you A, B, C, M—so you see later, a word you need to remember.\\n\\nOK, this is a single-crystal–based transducer that can be used to do all these kinds of things. But when you want to form two-dimensional images, you need an easy scan, or you need to do multiple times—so you have a time dimension. With the time dimension, with a single transducer, you can still form two-dimensional images. Certainly, this is quite a lot like pencil-beam X-ray imaging. In the first generation, you have a pencil beam of X-rays and a single detector; you can do a scan. That is very inefficient.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"C-mode imaging\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"A-mode data\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide7.json",
        "parsed": {
          "term": "phalanges",
          "category": "anatomy"
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T14:24:30.431771+00:00\", \"text_length\": 3336, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the last one—and I would say—is C-mode, C for coronal image. You know, three-dimensionally, if you cut a patient with a virtual plane this way, we usually call that the transverse plane. If you cut the patient this way, you call it sagittal. But if you cut the patient this way—think I am facing you and you cut like this—that is called the coronal image. So you have three views. I will show some images.\\n\\nYou do A-mode imaging along this direction. You have all the information, and the spatial dimension along this direction is your coordinate system—just one axis. But you can do some echo-gated imaging. You send the pulse in that direction, you wait a certain amount of time, then you see—within a small time window—if the echo comes back. Given the delay time, you really target a specific depth. So from this one line, you roughly calculate: the ultrasound goes a round trip from the transducer to the plane and back. Suppose this round-trip time is, for example, 100 microseconds—let’s say 100 milliseconds in my example. You only see the amplitude at 100 microseconds. That is the round-trip echo time—the echo goes here, hits the plane, comes back—so, 100 microseconds.\\n\\nThis 100-microsecond sample is reported as your pixel value. Then, on this two-dimensional coronal plane, you keep scanning—line by line, pixel by pixel. You make sure the round-trip time is targeted to that depth position. You put all these amplitude values together, and you form a two-dimensional image. That is the so-called coronal image.\\n\\nHere is an example: you have a hand here. You put the ultrasound into the hand, and you record the echoes. With all the timing coordinated right, you form an internal image that cuts through the hand. You can see certain pieces of bone. There is some terminology I just learned—metacarpals—these light-blue bones; you can see these light-blue bones. The transducer is operated in C-mode here. There are some good ideas; details are in this article.\\n\\nYou have the image—the image is really formed here. Then the image in a pixel here is reflected by a half-silvered mirror and viewed by the reader or doctor. Through this half-silvered mirror, you see the patient’s body, and the image you see is really superimposed onto the patient’s internal structure. It gives you the illusion that you see into the patient directly—you see the beating heart—and you can maybe use this as guidance to put the catheter there, make a blood vessel open wider.\\n\\nThis is a good idea. It kind of works with augmented-reality things, and it’s a good idea. But the C-mode has nothing to do with this viewer. C-mode can be understood only with this sub-figure—so that’s the idea. And ultrasound imaging so far is straightforward. I have explained to you A, B, C, M—so you see later, a word you need to remember.\\n\\nOK, this is a single-crystal–based transducer that can be used to do all these kinds of things. But when you want to form two-dimensional images, you need an easy scan, or you need to do multiple times—so you have a time dimension. With the time dimension, with a single transducer, you can still form two-dimensional images. Certainly, this is quite a lot like pencil-beam X-ray imaging. In the first generation, you have a pencil beam of X-rays and a single detector; you can do a scan. That is very inefficient.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"A-mode imaging along this direction\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"echo-gated imaging\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"round-trip echo time\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"C-mode slice\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"half-silvered mirror\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"viewer\\\",\\n      \\\"category\\\": \\\"workflow\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"ultrasound transducer\\\",\\n      \\\"category\\\": \\\"instrumentation\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"metacarpals\\\",\\n      \\\"category\\\": \\\"anatomy\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"phalanges\\\",\\n      \\\"category\\\": \\\"anatomy\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"carpals\\\",\\n      \\\"category\\\": \\\"anatomy\\\"\", \"parsed\": {\"term\": \"phalanges\", \"category\": \"anatomy\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide7.json",
        "parsed": {
          "s": "C-mode imaging",
          "p": "uses",
          "o": "half-silvered mirror",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.9,
          "evidence": [
            "A half-silvered mirror can be used to merge the body surface with his/her interior without a head-mounted display."
          ]
        },
        "raw": "{\"slide_id\": \"Slide7\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T14:31:25.519877+00:00\", \"text_length\": 3336, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the last one—and I would say—is C-mode, C for coronal image. You know, three-dimensionally, if you cut a patient with a virtual plane this way, we usually call that the transverse plane. If you cut the patient this way, you call it sagittal. But if you cut the patient this way—think I am facing you and you cut like this—that is called the coronal image. So you have three views. I will show some images.\\n\\nYou do A-mode imaging along this direction. You have all the information, and the spatial dimension along this direction is your coordinate system—just one axis. But you can do some echo-gated imaging. You send the pulse in that direction, you wait a certain amount of time, then you see—within a small time window—if the echo comes back. Given the delay time, you really target a specific depth. So from this one line, you roughly calculate: the ultrasound goes a round trip from the transducer to the plane and back. Suppose this round-trip time is, for example, 100 microseconds—let’s say 100 milliseconds in my example. You only see the amplitude at 100 microseconds. That is the round-trip echo time—the echo goes here, hits the plane, comes back—so, 100 microseconds.\\n\\nThis 100-microsecond sample is reported as your pixel value. Then, on this two-dimensional coronal plane, you keep scanning—line by line, pixel by pixel. You make sure the round-trip time is targeted to that depth position. You put all these amplitude values together, and you form a two-dimensional image. That is the so-called coronal image.\\n\\nHere is an example: you have a hand here. You put the ultrasound into the hand, and you record the echoes. With all the timing coordinated right, you form an internal image that cuts through the hand. You can see certain pieces of bone. There is some terminology I just learned—metacarpals—these light-blue bones; you can see these light-blue bones. The transducer is operated in C-mode here. There are some good ideas; details are in this article.\\n\\nYou have the image—the image is really formed here. Then the image in a pixel here is reflected by a half-silvered mirror and viewed by the reader or doctor. Through this half-silvered mirror, you see the patient’s body, and the image you see is really superimposed onto the patient’s internal structure. It gives you the illusion that you see into the patient directly—you see the beating heart—and you can maybe use this as guidance to put the catheter there, make a blood vessel open wider.\\n\\nThis is a good idea. It kind of works with augmented-reality things, and it’s a good idea. But the C-mode has nothing to do with this viewer. C-mode can be understood only with this sub-figure—so that’s the idea. And ultrasound imaging so far is straightforward. I have explained to you A, B, C, M—so you see later, a word you need to remember.\\n\\nOK, this is a single-crystal–based transducer that can be used to do all these kinds of things. But when you want to form two-dimensional images, you need an easy scan, or you need to do multiple times—so you have a time dimension. With the time dimension, with a single transducer, you can still form two-dimensional images. Certainly, this is quite a lot like pencil-beam X-ray imaging. In the first generation, you have a pencil beam of X-rays and a single detector; you can do a scan. That is very inefficient.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"C-mode imaging\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"coronal image\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"C-mode imaging produces a coronal image by gating A-mode data to a specific depth.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"C-mode imaging\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"half-silvered mirror\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"A half-silvered mirror can be used to merge the body surface with his/her interior without a head-mounted display.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"C-mode imaging\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"ultrasound transducer\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.85,\\n      \\\"evidence\\\": \\\"You have the image—the image is really formed here. Then the image in a pixel here is reflected\", \"parsed\": {\"s\": \"C-mode imaging\", \"p\": \"uses\", \"o\": \"half-silvered mirror\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.9, \"evidence\": [\"A half-silvered mirror can be used to merge the body surface with his/her interior without a head-mounted display.\"]}}"
      }
    }
  }
}