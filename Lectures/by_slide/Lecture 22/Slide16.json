{
  "lecture": "Lecture 22",
  "slide_id": "Slide16",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Images\\Slide16.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Texts\\Slide16.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide16.json",
        "parsed": {
          "term": "overall performance",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the beam-forming idea is that you introduce time delays across the array. Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\n\\nOn the receiver side, you receive all these signals and keep guiding or aligning them properly. If you add those signals together—but with individual delays as shown here—you can make them sum coherently. The tall bars in the diagram indicate a larger time delay. Different modulations of these delays determine which echo signal you want to detect.\\n\\nAt this location, the phase difference between the central element and the peripheral elements will be large, so the relative delay will be large too. You take the signal from the central channel and keep it. Then, you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element. That longer time becomes the time delay.\\n\\nYou add all the signals together, each with its own individualized time delay. When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one. But if you use a uniform time delay for all, you are focusing to infinity—that’s a remote point. So, by changing the distribution of time delays, you can guide coherent echoes at different depths.\\n\\nThis is the basic beam-forming idea. And of course, scanning and beam forming can be combined to achieve the best image quality and overall performance.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"beam-forming\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"time delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"central element\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"peripheral elements\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"phase difference\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"time delay\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"beam-forming idea\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"scanning and beam forming\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"best image quality\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"overall performance\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"So, the beam-forming idea is that you introduce time delays across the array.\\\", \\n               \\\"Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\\", \\n               \\\"The tall bars in the\", \"parsed\": {\"term\": \"overall performance\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide16.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the beam-forming idea is that you introduce time delays across the array. Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\n\\nOn the receiver side, you receive all these signals and keep guiding or aligning them properly. If you add those signals together—but with individual delays as shown here—you can make them sum coherently. The tall bars in the diagram indicate a larger time delay. Different modulations of these delays determine which echo signal you want to detect.\\n\\nAt this location, the phase difference between the central element and the peripheral elements will be large, so the relative delay will be large too. You take the signal from the central channel and keep it. Then, you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element. That longer time becomes the time delay.\\n\\nYou add all the signals together, each with its own individualized time delay. When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one. But if you use a uniform time delay for all, you are focusing to infinity—that’s a remote point. So, by changing the distribution of time delays, you can guide coherent echoes at different depths.\\n\\nThis is the basic beam-forming idea. And of course, scanning and beam forming can be combined to achieve the best image quality and overall performance.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"beam-forming\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"time delays\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide16.json",
        "parsed": {
          "term": "coherent echoes",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"time delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"beam-forming\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent sum\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"phase difference\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"central element\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"peripheral elements\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"transducer\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"signal alignment\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"modulations of delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"echo signal detection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"uniform time delay\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"focus to infinity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"distribution of time delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"scanning\\\", \\\"category\\\": \\\"workflow\", \"parsed\": {\"term\": \"coherent echoes\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide16.json",
        "parsed": {
          "triples": [
            {
              "s": "beam-forming",
              "p": "uses",
              "o": "time delays",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "the beam-forming idea is that you introduce time delays across the array"
            },
            {
              "s": "beam-forming",
              "p": "produces",
              "o": "strong echo",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "you add the five signals together, you form a strong echo"
            },
            {
              "s": "beam-forming",
              "p": "depends_on",
              "o": "distribution of time delays",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "by changing the distribution of time delays, you can guide coherent echoes at different depths"
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"beam-forming\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"time delays\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"the beam-forming idea is that you introduce time delays across the array\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"beam-forming\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"strong echo\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"you add the five signals together, you form a strong echo\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"beam-forming\\\",\\n      \\\"p\\\": \\\"depends_on\\\",\\n      \\\"o\\\": \\\"distribution of time delays\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"by changing the distribution of time delays, you can guide coherent echoes at different depths\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"beam-forming\", \"p\": \"uses\", \"o\": \"time delays\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"the beam-forming idea is that you introduce time delays across the array\"}, {\"s\": \"beam-forming\", \"p\": \"produces\", \"o\": \"strong echo\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"you add the five signals together, you form a strong echo\"}, {\"s\": \"beam-forming\", \"p\": \"depends_on\", \"o\": \"distribution of time delays\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"by changing the distribution of time delays, you can guide coherent echoes at different depths\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide16.json",
        "parsed": {
          "term": "coherent echoes",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T17:37:09.562465+00:00\", \"text_length\": 1544, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the beam-forming idea is that you introduce time delays across the array. Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\n\\nOn the receiver side, you receive all these signals and keep guiding or aligning them properly. If you add those signals together—but with individual delays as shown here—you can make them sum coherently. The tall bars in the diagram indicate a larger time delay. Different modulations of these delays determine which echo signal you want to detect.\\n\\nAt this location, the phase difference between the central element and the peripheral elements will be large, so the relative delay will be large too. You take the signal from the central channel and keep it. Then, you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element. That longer time becomes the time delay.\\n\\nYou add all the signals together, each with its own individualized time delay. When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one. But if you use a uniform time delay for all, you are focusing to infinity—that’s a remote point. So, by changing the distribution of time delays, you can guide coherent echoes at different depths.\\n\\nThis is the basic beam-forming idea. And of course, scanning and beam forming can be combined to achieve the best image quality and overall performance.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"beam-forming\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"time delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"array\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"echo signals\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"time delay\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"beam-forming idea\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"remote point\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"distribution of time delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"beam-forming\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"time delays\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"beam-forming\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"coherent echoes\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"time delays\\\", \\\"category\\\": \\\"signal_processing\", \"parsed\": {\"term\": \"coherent echoes\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide16.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T18:42:07.753440+00:00\", \"text_length\": 1544, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the beam-forming idea is that you introduce time delays across the array. Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\n\\nOn the receiver side, you receive all these signals and keep guiding or aligning them properly. If you add those signals together—but with individual delays as shown here—you can make them sum coherently. The tall bars in the diagram indicate a larger time delay. Different modulations of these delays determine which echo signal you want to detect.\\n\\nAt this location, the phase difference between the central element and the peripheral elements will be large, so the relative delay will be large too. You take the signal from the central channel and keep it. Then, you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element. That longer time becomes the time delay.\\n\\nYou add all the signals together, each with its own individualized time delay. When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one. But if you use a uniform time delay for all, you are focusing to infinity—that’s a remote point. So, by changing the distribution of time delays, you can guide coherent echoes at different depths.\\n\\nThis is the basic beam-forming idea. And of course, scanning and beam forming can be combined to achieve the best image quality and overall performance.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"time delays\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"array\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide16.json",
        "parsed": {
          "term": "you form a strong echo-for example, for echo one",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T14:26:00.935729+00:00\", \"text_length\": 1544, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the beam-forming idea is that you introduce time delays across the array. Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\n\\nOn the receiver side, you receive all these signals and keep guiding or aligning them properly. If you add those signals together—but with individual delays as shown here—you can make them sum coherently. The tall bars in the diagram indicate a larger time delay. Different modulations of these delays determine which echo signal you want to detect.\\n\\nAt this location, the phase difference between the central element and the peripheral elements will be large, so the relative delay will be large too. You take the signal from the central channel and keep it. Then, you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element. That longer time becomes the time delay.\\n\\nYou add all the signals together, each with its own individualized time delay. When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one. But if you use a uniform time delay for all, you are focusing to infinity—that’s a remote point. So, by changing the distribution of time delays, you can guide coherent echoes at different depths.\\n\\nThis is the basic beam-forming idea. And of course, scanning and beam forming can be combined to achieve the best image quality and overall performance.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"you introduce time delays across the array\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"you add those signals together—but with individual delays as shown here\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"you make them sum coherently\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"different modulations of these delays determine which echo signal you want to detect\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"you take the signal from the central channel and keep it\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"you add all the signals together, each with its own individualized time delay\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"you form a strong echo—for example, for echo one\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"\", \"parsed\": {\"term\": \"you form a strong echo-for example, for echo one\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide16.json",
        "parsed": {
          "s": "beam forming",
          "p": "produces",
          "o": "strong echo",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.85,
          "evidence": [
            "When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo-for example, for echo one."
          ]
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T14:32:39.106508+00:00\", \"text_length\": 1544, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo, the beam-forming idea is that you introduce time delays across the array. Imagine you have scatterers located at different positions, labeled E1, E2, and E3. These are the echoes or signals you receive from different points inside the tissue.\\n\\nOn the receiver side, you receive all these signals and keep guiding or aligning them properly. If you add those signals together—but with individual delays as shown here—you can make them sum coherently. The tall bars in the diagram indicate a larger time delay. Different modulations of these delays determine which echo signal you want to detect.\\n\\nAt this location, the phase difference between the central element and the peripheral elements will be large, so the relative delay will be large too. You take the signal from the central channel and keep it. Then, you take the signal from the outer element—it takes a longer time for the echo to reach that peripheral element. That longer time becomes the time delay.\\n\\nYou add all the signals together, each with its own individualized time delay. When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one. But if you use a uniform time delay for all, you are focusing to infinity—that’s a remote point. So, by changing the distribution of time delays, you can guide coherent echoes at different depths.\\n\\nThis is the basic beam-forming idea. And of course, scanning and beam forming can be combined to achieve the best image quality and overall performance.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"time delays\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"beam forming\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"The beam-forming idea is that you introduce time delays across the array.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"echoes\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"time delays\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"You add all the signals together, each with its own individualized time delay.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"beam forming\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"strong echo\\\",\\n      \\\"modalities\\\": [\\\"text\\\", \\\"image\\\"],\\n      \\\"confidence\\\": 0.85,\\n      \\\"evidence\\\": \\\"When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo—for example, for echo one.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"beam forming\\\",\\n      \\\"p\\\": \\\"depends_on\\\",\\n      \\\"o\\\": \\\"\", \"parsed\": {\"s\": \"beam forming\", \"p\": \"produces\", \"o\": \"strong echo\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.85, \"evidence\": [\"When the time delays are properly distributed like this, and you add the five signals together, you form a strong echo-for example, for echo one.\"]}}"
      }
    }
  }
}