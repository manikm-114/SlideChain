{
  "lecture": "Lecture 22",
  "slide_id": "Slide4",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Images\\Slide4.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Texts\\Slide4.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide4.json",
        "parsed": {
          "concepts": [],
          "evidence": [
            "The reconstruction process is crucial in medical imaging to obtain accurate images from raw data.",
            "Image quality is a critical factor in determining the reliability of medical imaging results.",
            "Signal processing techniques are used to enhance and analyze the signals obtained from medical imaging modalities.",
            "The frequency domain is essential for understanding the spectral properties of signals in medical imaging.",
            "Anatomical knowledge is necessary for interpreting medical imaging results accurately."
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\n\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"image quality\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"signal processing\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"frequency domain\\\", \\\"category\\\": \\\"frequency_domain\\\"},\\n    {\\\"term\\\": \\\"anatomy\\\", \\\"category\\\": \\\"anatomy\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"The reconstruction process is crucial in medical imaging to obtain accurate images from raw data.\\\", \\n               \\\"Image quality is a critical factor in determining the reliability of medical imaging results.\\\", \\n               \\\"Signal processing techniques are used to enhance and analyze the signals obtained from medical imaging modalities.\\\", \\n               \\\"The frequency domain is essential for understanding the spectral properties of signals in medical imaging.\\\", \\n               \\\"Anatomical knowledge is necessary for interpreting medical imaging results accurately.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [], \"evidence\": [\"The reconstruction process is crucial in medical imaging to obtain accurate images from raw data.\", \"Image quality is a critical factor in determining the reliability of medical imaging results.\", \"Signal processing techniques are used to enhance and analyze the signals obtained from medical imaging modalities.\", \"The frequency domain is essential for understanding the spectral properties of signals in medical imaging.\", \"Anatomical knowledge is necessary for interpreting medical imaging results accurately.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\n\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n```json\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"brain\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"neuron\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The brain uses neurons to process information.\\\"}\\n  ]\\n}\\n```\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide4.json",
        "parsed": {
          "concepts": [],
          "evidence": [
            "US Imaging Modes",
            "A mode (A = amplitude)",
            "ce = c x time",
            "for the different tissues"
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"US Imaging Modes\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"A mode\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"amplitude\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"ce = c x time\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"tissues\\\", \\\"category\\\": \\\"anatomy\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"US Imaging Modes\\\", \\\"A mode (A = amplitude)\\\", \\\"ce = c x time\\\", \\\"for the different tissues\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [], \"evidence\": [\"US Imaging Modes\", \"A mode (A = amplitude)\", \"ce = c x time\", \"for the different tissues\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"A mode\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"amplitude\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"A mode (A = amplitude)\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"ce\\\",\\n      \\\"p\\\": \\\"equals\\\",\\n      \\\"o\\\": \\\"c x time\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"ce = c x time\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide4.json",
        "parsed": {
          "concepts": [],
          "evidence": [
            "A mode (A = amplitude)",
            "c for the different tissues",
            "ce = c x time"
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T17:14:20.020737+00:00\", \"text_length\": 0, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\n\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"A mode\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"amplitude\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"US Imaging Modes\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"c for the different tissues\\\", \\\"category\\\": \\\"physics\\\"},\\n    {\\\"term\\\": \\\"ce = c x time\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"A mode (A = amplitude)\\\", \\\"c for the different tissues\\\", \\\"ce = c x time\\\"]\\n}\", \"parsed\": {\"concepts\": [], \"evidence\": [\"A mode (A = amplitude)\", \"c for the different tissues\", \"ce = c x time\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T18:34:14.393492+00:00\", \"text_length\": 0, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\n\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"A mode (A = amplitude)\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"US Imaging Modes\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"US Imaging Modes\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide4.json",
        "parsed": {
          "concepts": [],
          "evidence": [
            "US Imaging Modes",
            "A mode (A = amplitude)",
            "c for the different tissues",
            "ce = c x time"
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T14:24:00.013497+00:00\", \"text_length\": 0, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\n\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"US Imaging Modes\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"A mode (A = amplitude)\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"c for the different tissues\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"ce = c x time\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"US Imaging Modes\\\",\\n    \\\"A mode (A = amplitude)\\\",\\n    \\\"c for the different tissues\\\",\\n    \\\"ce = c x time\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [], \"evidence\": [\"US Imaging Modes\", \"A mode (A = amplitude)\", \"c for the different tissues\", \"ce = c x time\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 22\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide4.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T14:30:55.177376+00:00\", \"text_length\": 0, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\n\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"A mode\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"amplitude\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"A mode (A = amplitude)\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"A mode\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"c for the different tissues\\\",\\n      \\\"modalities\\\": [\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.7,\\n      \\\"evidence\\\": \\\"c for the different tissues\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"A mode\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"ce = c x time\\\",\\n      \\\"modalities\\\": [\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.6,\\n      \\\"evidence\\\": \\\"ce = c x time\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}