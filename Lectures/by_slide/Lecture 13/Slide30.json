{
  "lecture": "Lecture 13",
  "slide_id": "Slide30",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Images\\Slide30.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Texts\\Slide30.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide30.json",
        "parsed": {
          "term": "spatial-domain counterpart",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo here we have this picture. The backprojection is visualized. This is the projection profile after filtration, so it is a filtered projection profile. This filtered projection profile, Q theta i of t, is really smeared back over the field of view. Think of this projection profile as being smeared back from this particular direction. You have many filtered projection profiles; you sweep all of them and smear them back over the field of view. Add them together to get the result.\\n\\nFor a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then along that line every point gets one. This is what I call smearing back.\\n\\nThat was for this theta, theta i. For another angle, you smear back in a different way. The process is linear—the integral means summation. For each theta, you retrieve the value from Q theta, then add it back to the particular point x, y. For another angle you do the same. You can view it like this: from this filtered projection profile, you get the value here; along a different direction, another projection profile gives you another value through that same point x, y. So, heuristically, from the filtered projection domain, any profile is smeared back uniformly, its value covering all points along its line. All projection angles are added in the same way, and then you have the image value recovered. Think about that. I will show reconstructing examples in a few minutes, so you can get a better idea. OKay.\\n\\nNow, several slides with green buttons are about the reconstruction filter. Here, the reconstruction filter—a high-pass filter—is the absolute value of w. This filter does not have an inverse Fourier transform by itself, because the absolute value of w is not integrable. However, we can introduce a band-limited assumption: for a given projection profile, you have a maximum frequency, a maximum bandwidth W.\\n\\nSo the filtration really needs to be done with this truncated filter. In the original Fourier space, the ideal is the absolute value of omega extending to infinity. We assume a maximum bandwidth capital W; outside that, nothing is meaningful for the data. With this window, the spectrum becomes integrable. You truncate the otherwise divergent high-pass filter, then perform the inverse transform with respect to this truncated version, H of omega. You compute the inverse Fourier transform as the spatial-domain counterpart of the high-pass filter. You do the computation, and you get this part.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"filtered projection profile\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"backprojection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"smeared back\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"x, y\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"t = x cosine theta i + y sine theta i\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"smearing back\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"reconstruction filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"high-pass filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"band-limited assumption\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"maximum frequency\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"maximum bandwidth W\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"truncated filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"inverse Fourier transform\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"spatial-domain counterpart\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"This is the projection profile\", \"parsed\": {\"term\": \"spatial-domain counterpart\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide30.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo here we have this picture. The backprojection is visualized. This is the projection profile after filtration, so it is a filtered projection profile. This filtered projection profile, Q theta i of t, is really smeared back over the field of view. Think of this projection profile as being smeared back from this particular direction. You have many filtered projection profiles; you sweep all of them and smear them back over the field of view. Add them together to get the result.\\n\\nFor a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then along that line every point gets one. This is what I call smearing back.\\n\\nThat was for this theta, theta i. For another angle, you smear back in a different way. The process is linear—the integral means summation. For each theta, you retrieve the value from Q theta, then add it back to the particular point x, y. For another angle you do the same. You can view it like this: from this filtered projection profile, you get the value here; along a different direction, another projection profile gives you another value through that same point x, y. So, heuristically, from the filtered projection domain, any profile is smeared back uniformly, its value covering all points along its line. All projection angles are added in the same way, and then you have the image value recovered. Think about that. I will show reconstructing examples in a few minutes, so you can get a better idea. OKay.\\n\\nNow, several slides with green buttons are about the reconstruction filter. Here, the reconstruction filter—a high-pass filter—is the absolute value of w. This filter does not have an inverse Fourier transform by itself, because the absolute value of w is not integrable. However, we can introduce a band-limited assumption: for a given projection profile, you have a maximum frequency, a maximum bandwidth W.\\n\\nSo the filtration really needs to be done with this truncated filter. In the original Fourier space, the ideal is the absolute value of omega extending to infinity. We assume a maximum bandwidth capital W; outside that, nothing is meaningful for the data. With this window, the spectrum becomes integrable. You truncate the otherwise divergent high-pass filter, then perform the inverse transform with respect to this truncated version, H of omega. You compute the inverse Fourier transform as the spatial-domain counterpart of the high-pass filter. You do the computation, and you get this part.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"filtered projection profile\\\", \\\"p\\\":\\\"measures\\\",\\n     \\\"o\\\":\\\"t\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"For a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide30.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"\", \"parsed\": null}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide30.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"\", \"parsed\": null}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide30.json",
        "parsed": {
          "term": "maximum frequency",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T07:09:09.955947+00:00\", \"text_length\": 3282, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo here we have this picture. The backprojection is visualized. This is the projection profile after filtration, so it is a filtered projection profile. This filtered projection profile, Q theta i of t, is really smeared back over the field of view. Think of this projection profile as being smeared back from this particular direction. You have many filtered projection profiles; you sweep all of them and smear them back over the field of view. Add them together to get the result.\\n\\nFor a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then along that line every point gets one. This is what I call smearing back.\\n\\nThat was for this theta, theta i. For another angle, you smear back in a different way. The process is linear—the integral means summation. For each theta, you retrieve the value from Q theta, then add it back to the particular point x, y. For another angle you do the same. You can view it like this: from this filtered projection profile, you get the value here; along a different direction, another projection profile gives you another value through that same point x, y. So, heuristically, from the filtered projection domain, any profile is smeared back uniformly, its value covering all points along its line. All projection angles are added in the same way, and then you have the image value recovered. Think about that. I will show reconstructing examples in a few minutes, so you can get a better idea. OKay.\\n\\nNow, several slides with green buttons are about the reconstruction filter. Here, the reconstruction filter—a high-pass filter—is the absolute value of w. This filter does not have an inverse Fourier transform by itself, because the absolute value of w is not integrable. However, we can introduce a band-limited assumption: for a given projection profile, you have a maximum frequency, a maximum bandwidth W.\\n\\nSo the filtration really needs to be done with this truncated filter. In the original Fourier space, the ideal is the absolute value of omega extending to infinity. We assume a maximum bandwidth capital W; outside that, nothing is meaningful for the data. With this window, the spectrum becomes integrable. You truncate the otherwise divergent high-pass filter, then perform the inverse transform with respect to this truncated version, H of omega. You compute the inverse Fourier transform as the spatial-domain counterpart of the high-pass filter. You do the computation, and you get this part.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Ramp Filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"transfer function\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"impulse response\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Fourier transform\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"projection profile\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"backprojection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"filtered projection profile\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"smearing back\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"inner product\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"projection angles\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"reconstruction filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"high-pass filter\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"absolute value of w\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"band-limited assumption\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"maximum frequency\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"maximum bandwidth W\\\", \\\"category\\\": \\\"\", \"parsed\": {\"term\": \"maximum frequency\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide30.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T07:53:33.843734+00:00\", \"text_length\": 3282, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo here we have this picture. The backprojection is visualized. This is the projection profile after filtration, so it is a filtered projection profile. This filtered projection profile, Q theta i of t, is really smeared back over the field of view. Think of this projection profile as being smeared back from this particular direction. You have many filtered projection profiles; you sweep all of them and smear them back over the field of view. Add them together to get the result.\\n\\nFor a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then along that line every point gets one. This is what I call smearing back.\\n\\nThat was for this theta, theta i. For another angle, you smear back in a different way. The process is linear—the integral means summation. For each theta, you retrieve the value from Q theta, then add it back to the particular point x, y. For another angle you do the same. You can view it like this: from this filtered projection profile, you get the value here; along a different direction, another projection profile gives you another value through that same point x, y. So, heuristically, from the filtered projection domain, any profile is smeared back uniformly, its value covering all points along its line. All projection angles are added in the same way, and then you have the image value recovered. Think about that. I will show reconstructing examples in a few minutes, so you can get a better idea. OKay.\\n\\nNow, several slides with green buttons are about the reconstruction filter. Here, the reconstruction filter—a high-pass filter—is the absolute value of w. This filter does not have an inverse Fourier transform by itself, because the absolute value of w is not integrable. However, we can introduce a band-limited assumption: for a given projection profile, you have a maximum frequency, a maximum bandwidth W.\\n\\nSo the filtration really needs to be done with this truncated filter. In the original Fourier space, the ideal is the absolute value of omega extending to infinity. We assume a maximum bandwidth capital W; outside that, nothing is meaningful for the data. With this window, the spectrum becomes integrable. You truncate the otherwise divergent high-pass filter, then perform the inverse transform with respect to this truncated version, H of omega. You compute the inverse Fourier transform as the spatial-domain counterpart of the high-pass filter. You do the computation, and you get this part.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Ramp Filter\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"projection profile\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Ramp Filter, shown in Fig. 3.14, represents the transfer function of a filter with which the projections must be processed.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide30.json",
        "parsed": {
          "term": "inverse Fourier transform",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T11:41:16.908621+00:00\", \"text_length\": 3282, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo here we have this picture. The backprojection is visualized. This is the projection profile after filtration, so it is a filtered projection profile. This filtered projection profile, Q theta i of t, is really smeared back over the field of view. Think of this projection profile as being smeared back from this particular direction. You have many filtered projection profiles; you sweep all of them and smear them back over the field of view. Add them together to get the result.\\n\\nFor a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then along that line every point gets one. This is what I call smearing back.\\n\\nThat was for this theta, theta i. For another angle, you smear back in a different way. The process is linear—the integral means summation. For each theta, you retrieve the value from Q theta, then add it back to the particular point x, y. For another angle you do the same. You can view it like this: from this filtered projection profile, you get the value here; along a different direction, another projection profile gives you another value through that same point x, y. So, heuristically, from the filtered projection domain, any profile is smeared back uniformly, its value covering all points along its line. All projection angles are added in the same way, and then you have the image value recovered. Think about that. I will show reconstructing examples in a few minutes, so you can get a better idea. OKay.\\n\\nNow, several slides with green buttons are about the reconstruction filter. Here, the reconstruction filter—a high-pass filter—is the absolute value of w. This filter does not have an inverse Fourier transform by itself, because the absolute value of w is not integrable. However, we can introduce a band-limited assumption: for a given projection profile, you have a maximum frequency, a maximum bandwidth W.\\n\\nSo the filtration really needs to be done with this truncated filter. In the original Fourier space, the ideal is the absolute value of omega extending to infinity. We assume a maximum bandwidth capital W; outside that, nothing is meaningful for the data. With this window, the spectrum becomes integrable. You truncate the otherwise divergent high-pass filter, then perform the inverse transform with respect to this truncated version, H of omega. You compute the inverse Fourier transform as the spatial-domain counterpart of the high-pass filter. You do the computation, and you get this part.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"backprojection\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"filtered projection profile\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"smearing back\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"inner product\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"t equals x cosine theta i plus y sine theta i\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"reconstruction filter\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"high-pass filter\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"absolute value of w\\\",\\n      \\\"category\\\": \\\"frequency_domain\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"truncated filter\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"maximum bandwidth W\\\",\\n      \\\"category\\\": \\\"frequency_domain\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"inverse Fourier transform\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"H(w)\\\",\", \"parsed\": {\"term\": \"inverse Fourier transform\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide30.json",
        "parsed": {
          "s": "H(w)",
          "p": "uses",
          "o": "the inverse Fourier transform",
          "modalities": [
            "text"
          ],
          "confidence": 0.9,
          "evidence": [
            "The impulse response, h(t), of this filter is given by the inverse Fourier transform of H(w) and is"
          ]
        },
        "raw": "{\"slide_id\": \"Slide30\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T11:47:21.606841+00:00\", \"text_length\": 3282, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo here we have this picture. The backprojection is visualized. This is the projection profile after filtration, so it is a filtered projection profile. This filtered projection profile, Q theta i of t, is really smeared back over the field of view. Think of this projection profile as being smeared back from this particular direction. You have many filtered projection profiles; you sweep all of them and smear them back over the field of view. Add them together to get the result.\\n\\nFor a given x, y, what is the contribution from a given Q theta? That is the question I want to explain. Suppose x, y is here. For this x, y—the point in image space—how much contribution do we get from a particular filtered projection profile, here Q theta i? You do this inner product: you get t. Spoken clearly: t equals x cosine theta i plus y sine theta i. That t is the distance between this line and the central line, both perpendicular to this direction, making an angle theta i. For any point along this line, the inner product gives the same t. So, as long as the pixel is on this line at distance t, you retrieve this value from the filtered projection profile. For all points on this line, t is the same. You compute t, you get the value, and you put that value back for any x, y on this line. That value is the same here, here, and here—all along the line. If that value is one, then along that line every point gets one. This is what I call smearing back.\\n\\nThat was for this theta, theta i. For another angle, you smear back in a different way. The process is linear—the integral means summation. For each theta, you retrieve the value from Q theta, then add it back to the particular point x, y. For another angle you do the same. You can view it like this: from this filtered projection profile, you get the value here; along a different direction, another projection profile gives you another value through that same point x, y. So, heuristically, from the filtered projection domain, any profile is smeared back uniformly, its value covering all points along its line. All projection angles are added in the same way, and then you have the image value recovered. Think about that. I will show reconstructing examples in a few minutes, so you can get a better idea. OKay.\\n\\nNow, several slides with green buttons are about the reconstruction filter. Here, the reconstruction filter—a high-pass filter—is the absolute value of w. This filter does not have an inverse Fourier transform by itself, because the absolute value of w is not integrable. However, we can introduce a band-limited assumption: for a given projection profile, you have a maximum frequency, a maximum bandwidth W.\\n\\nSo the filtration really needs to be done with this truncated filter. In the original Fourier space, the ideal is the absolute value of omega extending to infinity. We assume a maximum bandwidth capital W; outside that, nothing is meaningful for the data. With this window, the spectrum becomes integrable. You truncate the otherwise divergent high-pass filter, then perform the inverse transform with respect to this truncated version, H of omega. You compute the inverse Fourier transform as the spatial-domain counterpart of the high-pass filter. You do the computation, and you get this part.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"H(w)\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"the transfer function of a filter with which the projections must be processed\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"H(w), shown in Fig. 3.14, represents the transfer function of a filter with which the projections must be processed.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"H(w)\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"the inverse Fourier transform\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"The impulse response, h(t), of this filter is given by the inverse Fourier transform of H(w) and is\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"b_w(w)\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"a window function\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"where, again, b_w(w) = { 1 |w| < W,\", \"parsed\": {\"s\": \"H(w)\", \"p\": \"uses\", \"o\": \"the inverse Fourier transform\", \"modalities\": [\"text\"], \"confidence\": 0.9, \"evidence\": [\"The impulse response, h(t), of this filter is given by the inverse Fourier transform of H(w) and is\"]}}"
      }
    }
  }
}