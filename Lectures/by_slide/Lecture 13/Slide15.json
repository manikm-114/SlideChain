{
  "lecture": "Lecture 13",
  "slide_id": "Slide15",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Images\\Slide15.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Texts\\Slide15.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide15.json",
        "parsed": {
          "term": "convergence",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error. \\n\\nWhy explain an iterative algorithm? For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently. You may not have enough computer memory, and other issues may arise. So you use an iterative algorithm to solve the situation. Also, the iterative algorithm I’m about to explain lets you impose prior knowledge, like non-negativity or smoothness. These topics are beyond the scope of this lecture.\\n\\nLet me give you the basic idea—how you can do trial and error to solve a system of linear equations. As I told you, this is your underlying image. You have four measurements—two horizontal and two vertical—and you try to solve this system. The starting point: whenever you use an iterative algorithm, you need a starting point. Here, because I know nothing about the image, I choose a neutral guess and assume nothing in the field of view, so every pixel is zero. This is my starting point, or guess zero. It is a natural and unbiased starting point.\\n\\nFirst, if this guess were correct, then the vertical integrals must be zero and zero. Based on the assumption, I get these two estimated values: zero, zero. We call this a predicted or synthetic projection. It’s not that you must accept zero, zero just because I say so—you can challenge it. You can say, “If everything is zero, the vertical integrals must be zero, zero.” But the physical measurement says six and four. It is not zero, zero. How do we explain the contradiction?\\nWe compare the measurement with the prediction. We see errors six and four—here you measured six but predicted zero, so the error is six; there you measured four but predicted zero, so the error is four. This positive error indicates my initial guess underestimates the pixel values.\\n\\nAlong this ray, the real measurement is four, but I predicted zero. Clearly, there must be something in these two pixels. Their values should add to six along the first vertical ray. I do not know whether to give more to the first pixel or the second pixel, so to be fair, I evenly divide the error: six becomes three and three. I put the error back. After this redistribution, the two values add to six, so that vertical error is removed. Likewise, for the second vertical ray, four becomes two and two. After this, I am vertically consistent: along the first column, three plus three equals six, and along the second column, two plus two equals four, matching the measurements.\\n\\nNext, let’s double-check the horizontal integrals. Now the row sums are five and five. The measured horizontal sums are seven and three. Comparing again, the errors are plus two and minus two. A positive error means I still underestimate that row; a negative error means the true sum is less than my current estimate.\\nI redistribute the errors: the plus two is decomposed into one and one and added back to the two pixels in the first row; the minus two is decomposed into minus one and minus one and subtracted from the two pixels in the second row. In this case, we are lucky—after this second iteration, we obtain the correct result. Once we reach this state, the vertical and horizontal data are both perfectly explained. We are done—this illustrates the idea.\\n\\nIn real situations, it is never this simple. You need many iterations and many unknowns go back and forth, and a well-designed iterative algorithm will ensure that after many iterations the solution converges. Sometimes the iterative process gives an oscillating solution, and you need regularization. But again, for this undergraduate-level course, notice the basic idea.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"iterative algorithm\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"linear system equations\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"trial and error\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"measurement\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"error\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"redistribution\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"vertical and horizontal integrals\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"predicted or synthetic projection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"measurement vs. prediction\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"initial guess\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"convergence\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Here, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error.\\\", \\\"For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently\", \"parsed\": {\"term\": \"convergence\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide15.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error. \\n\\nWhy explain an iterative algorithm? For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently. You may not have enough computer memory, and other issues may arise. So you use an iterative algorithm to solve the situation. Also, the iterative algorithm I’m about to explain lets you impose prior knowledge, like non-negativity or smoothness. These topics are beyond the scope of this lecture.\\n\\nLet me give you the basic idea—how you can do trial and error to solve a system of linear equations. As I told you, this is your underlying image. You have four measurements—two horizontal and two vertical—and you try to solve this system. The starting point: whenever you use an iterative algorithm, you need a starting point. Here, because I know nothing about the image, I choose a neutral guess and assume nothing in the field of view, so every pixel is zero. This is my starting point, or guess zero. It is a natural and unbiased starting point.\\n\\nFirst, if this guess were correct, then the vertical integrals must be zero and zero. Based on the assumption, I get these two estimated values: zero, zero. We call this a predicted or synthetic projection. It’s not that you must accept zero, zero just because I say so—you can challenge it. You can say, “If everything is zero, the vertical integrals must be zero, zero.” But the physical measurement says six and four. It is not zero, zero. How do we explain the contradiction?\\nWe compare the measurement with the prediction. We see errors six and four—here you measured six but predicted zero, so the error is six; there you measured four but predicted zero, so the error is four. This positive error indicates my initial guess underestimates the pixel values.\\n\\nAlong this ray, the real measurement is four, but I predicted zero. Clearly, there must be something in these two pixels. Their values should add to six along the first vertical ray. I do not know whether to give more to the first pixel or the second pixel, so to be fair, I evenly divide the error: six becomes three and three. I put the error back. After this redistribution, the two values add to six, so that vertical error is removed. Likewise, for the second vertical ray, four becomes two and two. After this, I am vertically consistent: along the first column, three plus three equals six, and along the second column, two plus two equals four, matching the measurements.\\n\\nNext, let’s double-check the horizontal integrals. Now the row sums are five and five. The measured horizontal sums are seven and three. Comparing again, the errors are plus two and minus two. A positive error means I still underestimate that row; a negative error means the true sum is less than my current estimate.\\nI redistribute the errors: the plus two is decomposed into one and one and added back to the two pixels in the first row; the minus two is decomposed into minus one and minus one and subtracted from the two pixels in the second row. In this case, we are lucky—after this second iteration, we obtain the correct result. Once we reach this state, the vertical and horizontal data are both perfectly explained. We are done—this illustrates the idea.\\n\\nIn real situations, it is never this simple. You need many iterations and many unknowns go back and forth, and a well-designed iterative algorithm will ensure that after many iterations the solution converges. Sometimes the iterative process gives an oscillating solution, and you need regularization. But again, for this undergraduate-level course, notice the basic idea.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<iterative algorithm>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<system of linear equations>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<iterative algorithm is used to solve a system of linear equations>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide15.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"\", \"parsed\": null}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide15.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"\", \"parsed\": null}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide15.json",
        "parsed": {
          "term": "basic idea",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T06:44:26.151615+00:00\", \"text_length\": 3837, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error. \\n\\nWhy explain an iterative algorithm? For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently. You may not have enough computer memory, and other issues may arise. So you use an iterative algorithm to solve the situation. Also, the iterative algorithm I’m about to explain lets you impose prior knowledge, like non-negativity or smoothness. These topics are beyond the scope of this lecture.\\n\\nLet me give you the basic idea—how you can do trial and error to solve a system of linear equations. As I told you, this is your underlying image. You have four measurements—two horizontal and two vertical—and you try to solve this system. The starting point: whenever you use an iterative algorithm, you need a starting point. Here, because I know nothing about the image, I choose a neutral guess and assume nothing in the field of view, so every pixel is zero. This is my starting point, or guess zero. It is a natural and unbiased starting point.\\n\\nFirst, if this guess were correct, then the vertical integrals must be zero and zero. Based on the assumption, I get these two estimated values: zero, zero. We call this a predicted or synthetic projection. It’s not that you must accept zero, zero just because I say so—you can challenge it. You can say, “If everything is zero, the vertical integrals must be zero, zero.” But the physical measurement says six and four. It is not zero, zero. How do we explain the contradiction?\\nWe compare the measurement with the prediction. We see errors six and four—here you measured six but predicted zero, so the error is six; there you measured four but predicted zero, so the error is four. This positive error indicates my initial guess underestimates the pixel values.\\n\\nAlong this ray, the real measurement is four, but I predicted zero. Clearly, there must be something in these two pixels. Their values should add to six along the first vertical ray. I do not know whether to give more to the first pixel or the second pixel, so to be fair, I evenly divide the error: six becomes three and three. I put the error back. After this redistribution, the two values add to six, so that vertical error is removed. Likewise, for the second vertical ray, four becomes two and two. After this, I am vertically consistent: along the first column, three plus three equals six, and along the second column, two plus two equals four, matching the measurements.\\n\\nNext, let’s double-check the horizontal integrals. Now the row sums are five and five. The measured horizontal sums are seven and three. Comparing again, the errors are plus two and minus two. A positive error means I still underestimate that row; a negative error means the true sum is less than my current estimate.\\nI redistribute the errors: the plus two is decomposed into one and one and added back to the two pixels in the first row; the minus two is decomposed into minus one and minus one and subtracted from the two pixels in the second row. In this case, we are lucky—after this second iteration, we obtain the correct result. Once we reach this state, the vertical and horizontal data are both perfectly explained. We are done—this illustrates the idea.\\n\\nIn real situations, it is never this simple. You need many iterations and many unknowns go back and forth, and a well-designed iterative algorithm will ensure that after many iterations the solution converges. Sometimes the iterative process gives an oscillating solution, and you need regularization. But again, for this undergraduate-level course, notice the basic idea.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"iterative algorithm\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"trial and error\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"linear system equations\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"pixel values\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"errors\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"measurement\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"synthetic projection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"non-negativity\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"smoothness\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"iterative process\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"convergence\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"regularization\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"undergraduate-level course\\\", \\\"category\\\": \\\"education\\\"},\\n    {\\\"term\\\": \\\"basic idea\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Here, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error.\\\",\\n    \\\"\", \"parsed\": {\"term\": \"basic idea\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide15.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T07:44:24.002499+00:00\", \"text_length\": 3837, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error. \\n\\nWhy explain an iterative algorithm? For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently. You may not have enough computer memory, and other issues may arise. So you use an iterative algorithm to solve the situation. Also, the iterative algorithm I’m about to explain lets you impose prior knowledge, like non-negativity or smoothness. These topics are beyond the scope of this lecture.\\n\\nLet me give you the basic idea—how you can do trial and error to solve a system of linear equations. As I told you, this is your underlying image. You have four measurements—two horizontal and two vertical—and you try to solve this system. The starting point: whenever you use an iterative algorithm, you need a starting point. Here, because I know nothing about the image, I choose a neutral guess and assume nothing in the field of view, so every pixel is zero. This is my starting point, or guess zero. It is a natural and unbiased starting point.\\n\\nFirst, if this guess were correct, then the vertical integrals must be zero and zero. Based on the assumption, I get these two estimated values: zero, zero. We call this a predicted or synthetic projection. It’s not that you must accept zero, zero just because I say so—you can challenge it. You can say, “If everything is zero, the vertical integrals must be zero, zero.” But the physical measurement says six and four. It is not zero, zero. How do we explain the contradiction?\\nWe compare the measurement with the prediction. We see errors six and four—here you measured six but predicted zero, so the error is six; there you measured four but predicted zero, so the error is four. This positive error indicates my initial guess underestimates the pixel values.\\n\\nAlong this ray, the real measurement is four, but I predicted zero. Clearly, there must be something in these two pixels. Their values should add to six along the first vertical ray. I do not know whether to give more to the first pixel or the second pixel, so to be fair, I evenly divide the error: six becomes three and three. I put the error back. After this redistribution, the two values add to six, so that vertical error is removed. Likewise, for the second vertical ray, four becomes two and two. After this, I am vertically consistent: along the first column, three plus three equals six, and along the second column, two plus two equals four, matching the measurements.\\n\\nNext, let’s double-check the horizontal integrals. Now the row sums are five and five. The measured horizontal sums are seven and three. Comparing again, the errors are plus two and minus two. A positive error means I still underestimate that row; a negative error means the true sum is less than my current estimate.\\nI redistribute the errors: the plus two is decomposed into one and one and added back to the two pixels in the first row; the minus two is decomposed into minus one and minus one and subtracted from the two pixels in the second row. In this case, we are lucky—after this second iteration, we obtain the correct result. Once we reach this state, the vertical and horizontal data are both perfectly explained. We are done—this illustrates the idea.\\n\\nIn real situations, it is never this simple. You need many iterations and many unknowns go back and forth, and a well-designed iterative algorithm will ensure that after many iterations the solution converges. Sometimes the iterative process gives an oscillating solution, and you need regularization. But again, for this undergraduate-level course, notice the basic idea.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide15.json",
        "parsed": {
          "term": "vertical integrals",
          "category": "physics"
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T11:38:49.005050+00:00\", \"text_length\": 3837, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error. \\n\\nWhy explain an iterative algorithm? For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently. You may not have enough computer memory, and other issues may arise. So you use an iterative algorithm to solve the situation. Also, the iterative algorithm I’m about to explain lets you impose prior knowledge, like non-negativity or smoothness. These topics are beyond the scope of this lecture.\\n\\nLet me give you the basic idea—how you can do trial and error to solve a system of linear equations. As I told you, this is your underlying image. You have four measurements—two horizontal and two vertical—and you try to solve this system. The starting point: whenever you use an iterative algorithm, you need a starting point. Here, because I know nothing about the image, I choose a neutral guess and assume nothing in the field of view, so every pixel is zero. This is my starting point, or guess zero. It is a natural and unbiased starting point.\\n\\nFirst, if this guess were correct, then the vertical integrals must be zero and zero. Based on the assumption, I get these two estimated values: zero, zero. We call this a predicted or synthetic projection. It’s not that you must accept zero, zero just because I say so—you can challenge it. You can say, “If everything is zero, the vertical integrals must be zero, zero.” But the physical measurement says six and four. It is not zero, zero. How do we explain the contradiction?\\nWe compare the measurement with the prediction. We see errors six and four—here you measured six but predicted zero, so the error is six; there you measured four but predicted zero, so the error is four. This positive error indicates my initial guess underestimates the pixel values.\\n\\nAlong this ray, the real measurement is four, but I predicted zero. Clearly, there must be something in these two pixels. Their values should add to six along the first vertical ray. I do not know whether to give more to the first pixel or the second pixel, so to be fair, I evenly divide the error: six becomes three and three. I put the error back. After this redistribution, the two values add to six, so that vertical error is removed. Likewise, for the second vertical ray, four becomes two and two. After this, I am vertically consistent: along the first column, three plus three equals six, and along the second column, two plus two equals four, matching the measurements.\\n\\nNext, let’s double-check the horizontal integrals. Now the row sums are five and five. The measured horizontal sums are seven and three. Comparing again, the errors are plus two and minus two. A positive error means I still underestimate that row; a negative error means the true sum is less than my current estimate.\\nI redistribute the errors: the plus two is decomposed into one and one and added back to the two pixels in the first row; the minus two is decomposed into minus one and minus one and subtracted from the two pixels in the second row. In this case, we are lucky—after this second iteration, we obtain the correct result. Once we reach this state, the vertical and horizontal data are both perfectly explained. We are done—this illustrates the idea.\\n\\nIn real situations, it is never this simple. You need many iterations and many unknowns go back and forth, and a well-designed iterative algorithm will ensure that after many iterations the solution converges. Sometimes the iterative process gives an oscillating solution, and you need regularization. But again, for this undergraduate-level course, notice the basic idea.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"trial & error\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"iterative algorithm\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"linear system equations\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"starting point\\\",\\n      \\\"category\\\": \\\"workflow\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"predicted or synthetic projection\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"error\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"redistribute the errors\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"converges\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"regularization\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"non-negativity\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"smoothness\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"vertical integrals\\\",\\n      \\\"category\\\": \\\"physics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"\", \"parsed\": {\"term\": \"vertical integrals\", \"category\": \"physics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide15.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide15\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T11:45:30.297530+00:00\", \"text_length\": 3837, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere, I’ll still use two horizontal rays and two vertical rays to show how we solve linear system equations using iterative algorithms through trial and error. \\n\\nWhy explain an iterative algorithm? For a simple case like this, you can solve it directly using an analytic method. But when the number of unknowns is huge—like millions or billions of equations—the direct method will not work efficiently. You may not have enough computer memory, and other issues may arise. So you use an iterative algorithm to solve the situation. Also, the iterative algorithm I’m about to explain lets you impose prior knowledge, like non-negativity or smoothness. These topics are beyond the scope of this lecture.\\n\\nLet me give you the basic idea—how you can do trial and error to solve a system of linear equations. As I told you, this is your underlying image. You have four measurements—two horizontal and two vertical—and you try to solve this system. The starting point: whenever you use an iterative algorithm, you need a starting point. Here, because I know nothing about the image, I choose a neutral guess and assume nothing in the field of view, so every pixel is zero. This is my starting point, or guess zero. It is a natural and unbiased starting point.\\n\\nFirst, if this guess were correct, then the vertical integrals must be zero and zero. Based on the assumption, I get these two estimated values: zero, zero. We call this a predicted or synthetic projection. It’s not that you must accept zero, zero just because I say so—you can challenge it. You can say, “If everything is zero, the vertical integrals must be zero, zero.” But the physical measurement says six and four. It is not zero, zero. How do we explain the contradiction?\\nWe compare the measurement with the prediction. We see errors six and four—here you measured six but predicted zero, so the error is six; there you measured four but predicted zero, so the error is four. This positive error indicates my initial guess underestimates the pixel values.\\n\\nAlong this ray, the real measurement is four, but I predicted zero. Clearly, there must be something in these two pixels. Their values should add to six along the first vertical ray. I do not know whether to give more to the first pixel or the second pixel, so to be fair, I evenly divide the error: six becomes three and three. I put the error back. After this redistribution, the two values add to six, so that vertical error is removed. Likewise, for the second vertical ray, four becomes two and two. After this, I am vertically consistent: along the first column, three plus three equals six, and along the second column, two plus two equals four, matching the measurements.\\n\\nNext, let’s double-check the horizontal integrals. Now the row sums are five and five. The measured horizontal sums are seven and three. Comparing again, the errors are plus two and minus two. A positive error means I still underestimate that row; a negative error means the true sum is less than my current estimate.\\nI redistribute the errors: the plus two is decomposed into one and one and added back to the two pixels in the first row; the minus two is decomposed into minus one and minus one and subtracted from the two pixels in the second row. In this case, we are lucky—after this second iteration, we obtain the correct result. Once we reach this state, the vertical and horizontal data are both perfectly explained. We are done—this illustrates the idea.\\n\\nIn real situations, it is never this simple. You need many iterations and many unknowns go back and forth, and a well-designed iterative algorithm will ensure that after many iterations the solution converges. Sometimes the iterative process gives an oscillating solution, and you need regularization. But again, for this undergraduate-level course, notice the basic idea.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}