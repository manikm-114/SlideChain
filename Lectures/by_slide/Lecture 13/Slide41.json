{
  "lecture": "Lecture 13",
  "slide_id": "Slide41",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Images\\Slide41.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Texts\\Slide41.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide41.json",
        "parsed": {
          "concepts": [
            {
              "term": "MATLAB",
              "category": "software"
            },
            {
              "term": "image",
              "category": "modality"
            },
            {
              "term": "angular increments",
              "category": "signal_processing"
            },
            {
              "term": "detector spacing",
              "category": "instrumentation"
            },
            {
              "term": "true image",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "Then you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image."
          ]
        },
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThen you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. \\n\\nThis is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"reconstruction\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"MATLAB\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"image\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"angular increments\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"detector spacing\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"true image\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Then you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"MATLAB\", \"category\": \"software\"}, {\"term\": \"image\", \"category\": \"modality\"}, {\"term\": \"angular increments\", \"category\": \"signal_processing\"}, {\"term\": \"detector spacing\", \"category\": \"instrumentation\"}, {\"term\": \"true image\", \"category\": \"quality_metric\"}], \"evidence\": [\"Then you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide41.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThen you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. \\n\\nThis is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<SLIDE_TEXT>\\\",\\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<SLIDE_TEXT>\\\",\\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<SLIDE_TEXT> Then you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. This is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide41.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"\", \"parsed\": null}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide41.json",
        "parsed": null,
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"\", \"parsed\": null}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide41.json",
        "parsed": {
          "term": "Try It Yourself",
          "category": "workflow"
        },
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T07:27:02.292325+00:00\", \"text_length\": 385, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThen you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. \\n\\nThis is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Filtered Backprojection\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"Sinogram\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Reconstructed Image\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"MATLAB\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"Homework\\\", \\\"category\\\": \\\"workflow\\\"},\\n    {\\\"term\\\": \\\"Numerical Example\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Angular Increments\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Detector Spacing\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"True Image\\\", \\\"category\\\": \\\"reconstruction\\\"},\\n    {\\\"term\\\": \\\"MATLAB Implementation\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"Try It Yourself\\\", \\\"category\\\": \\\"workflow\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Then you can recover the original image. This looks very close to the original.\\\",\\n    \\\"If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image.\\\",\\n    \\\"This is just a numerical example.\\\",\\n    \\\"The next few slides show a MATLAB implementation—also your\", \"parsed\": {\"term\": \"Try It Yourself\", \"category\": \"workflow\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide41.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T08:01:40.945906+00:00\", \"text_length\": 385, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThen you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. \\n\\nThis is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Filtered Sinogram\\\", \\\"p\\\":\\\"produces\\\", \\\"o\\\":\\\"Reconstructed Image\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Filtered Backprojection to Image\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide41.json",
        "parsed": {
          "term": "The next few slides show a MATLAB implementation-also your homework-so you can read through and try it yourself",
          "category": "software"
        },
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-08T11:42:56.070682+00:00\", \"text_length\": 385, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThen you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. \\n\\nThis is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Then you can recover the original image\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"This looks very close to the original\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"This is just a numerical example\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Then you can recover the original image\\\",\\n    \\\"This looks very close to the original\\\",\\n    \\\"If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image\\\",\\n    \\\"This is just a numerical example\\\",\\n    \\\"The next few slides show a MATLAB implementation—also your homework—so you can read\", \"parsed\": {\"term\": \"The next few slides show a MATLAB implementation-also your homework-so you can read through and try it yourself\", \"category\": \"software\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 13\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide41.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide41\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-08T11:48:14.620317+00:00\", \"text_length\": 385, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThen you can recover the original image. This looks very close to the original. If you have many angles, with very small angular increments, and the detector spacing is very small, the result becomes closer and closer to the true image. \\n\\nThis is just a numerical example. The next few slides show a MATLAB implementation—also your homework—so you can read through and try it yourself.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Filtered Sinogram\\\",\\n      \\\"p\\\": \\\"reconstructs_with\\\",\\n      \\\"o\\\": \\\"Reconstructed Image\\\",\\n      \\\"modalities\\\": [\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"Filtered Backprojection to Image\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}