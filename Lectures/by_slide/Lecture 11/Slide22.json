{
  "lecture": "Lecture 11",
  "slide_id": "Slide22",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide22.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide22.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide22.json",
        "parsed": {
          "concepts": [
            {
              "term": "changeover background",
              "category": "software"
            },
            {
              "term": "difference",
              "category": "mathematics"
            },
            {
              "term": "background level",
              "category": "mathematics"
            },
            {
              "term": "relative change",
              "category": "mathematics"
            },
            {
              "term": "contrast comparison",
              "category": "signal_processing"
            },
            {
              "term": "SSIM",
              "category": "signal_processing"
            },
            {
              "term": "absolute change",
              "category": "mathematics"
            },
            {
              "term": "background",
              "category": "mathematics"
            }
          ],
          "evidence": [
            "This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change - delta divided by the background.",
            "When we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see."
          ]
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a simple example of a changeover background.\\n\\nLook at the first column on the left. The top image has about 10 dots, while the bottom has about 20 dots. The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one.\\nNow look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference.\\n\\nWhy? Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110.\\nThis illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\n\\nSo, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"changeover background\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"difference\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"background level\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"relative change\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"human vision\\\", \\\"category\\\": \\\"psychophysics\\\"},\\n    {\\\"term\\\": \\\"absolute change\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"background\\\", \\\"category\\\": \\\"mathematics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\\", \\\"When we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"changeover background\", \"category\": \"software\"}, {\"term\": \"difference\", \"category\": \"mathematics\"}, {\"term\": \"background level\", \"category\": \"mathematics\"}, {\"term\": \"relative change\", \"category\": \"mathematics\"}, {\"term\": \"contrast comparison\", \"category\": \"signal_processing\"}, {\"term\": \"SSIM\", \"category\": \"signal_processing\"}, {\"term\": \"absolute change\", \"category\": \"mathematics\"}, {\"term\": \"background\", \"category\": \"mathematics\"}], \"evidence\": [\"This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change - delta divided by the background.\", \"When we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide22.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a simple example of a changeover background.\\n\\nLook at the first column on the left. The top image has about 10 dots, while the bottom has about 20 dots. The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one.\\nNow look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference.\\n\\nWhy? Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110.\\nThis illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\n\\nSo, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"changeover background\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"difference in number of dots\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one. Now look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference. Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110. This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background. So, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide22.json",
        "parsed": {
          "concepts": [
            {
              "term": "changeover background",
              "category": "signal_processing"
            },
            {
              "term": "visual system",
              "category": "signal_processing"
            },
            {
              "term": "relative change",
              "category": "signal_processing"
            },
            {
              "term": "delta divided by the background",
              "category": "signal_processing"
            },
            {
              "term": "similarity measure",
              "category": "algorithm"
            },
            {
              "term": "contrast comparison",
              "category": "algorithm"
            },
            {
              "term": "SSIM",
              "category": "algorithm"
            }
          ],
          "evidence": [
            "changeover background",
            "what our visual system detects is not the absolute change, but the relative change - delta divided by the background",
            "when we design a similarity measure",
            "contrast comparison in SSIM"
          ]
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"changeover background\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"visual system\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"relative change\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"delta divided by the background\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"similarity measure\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"changeover background\\\",\\n    \\\"what our visual system detects is not the absolute change, but the relative change — delta divided by the background\\\",\\n    \\\"when we design a similarity measure\\\",\\n    \\\"contrast comparison in SSIM\\\"\\n  ]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"changeover background\", \"category\": \"signal_processing\"}, {\"term\": \"visual system\", \"category\": \"signal_processing\"}, {\"term\": \"relative change\", \"category\": \"signal_processing\"}, {\"term\": \"delta divided by the background\", \"category\": \"signal_processing\"}, {\"term\": \"similarity measure\", \"category\": \"algorithm\"}, {\"term\": \"contrast comparison\", \"category\": \"algorithm\"}, {\"term\": \"SSIM\", \"category\": \"algorithm\"}], \"evidence\": [\"changeover background\", \"what our visual system detects is not the absolute change, but the relative change - delta divided by the background\", \"when we design a similarity measure\", \"contrast comparison in SSIM\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide22.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"contrast comparison in SSIM\\\",\\n      \\\"p\\\": \\\"behaves\\\",\\n      \\\"o\\\": \\\"consistent with how we see\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"It behaves in a way that is consistent with how we see.\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide22.json",
        "parsed": {
          "concepts": [
            {
              "term": "changeover background",
              "category": "signal_processing"
            },
            {
              "term": "relative change",
              "category": "signal_processing"
            },
            {
              "term": "delta",
              "category": "signal_processing"
            },
            {
              "term": "background level",
              "category": "signal_processing"
            },
            {
              "term": "contrast comparison",
              "category": "signal_processing"
            },
            {
              "term": "SSIM",
              "category": "signal_processing"
            },
            {
              "term": "similarity measure",
              "category": "signal_processing"
            }
          ],
          "evidence": [
            "what our visual system detects is not the absolute change, but the relative change - delta divided by the background.",
            "So, when we design a similarity measure, we want it to reflect this property of human vision. And that's exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see."
          ]
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:57:13.013042+00:00\", \"text_length\": 1053, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a simple example of a changeover background.\\n\\nLook at the first column on the left. The top image has about 10 dots, while the bottom has about 20 dots. The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one.\\nNow look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference.\\n\\nWhy? Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110.\\nThis illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\n\\nSo, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"changeover background\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"visual system\\\", \\\"category\\\": \\\"psychology\\\"},\\n    {\\\"term\\\": \\\"relative change\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"delta\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"background level\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"human vision\\\", \\\"category\\\": \\\"psychology\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"similarity measure\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"human perception\\\", \\\"category\\\": \\\"psychology\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\\",\\n    \\\"So, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"changeover background\", \"category\": \"signal_processing\"}, {\"term\": \"relative change\", \"category\": \"signal_processing\"}, {\"term\": \"delta\", \"category\": \"signal_processing\"}, {\"term\": \"background level\", \"category\": \"signal_processing\"}, {\"term\": \"contrast comparison\", \"category\": \"signal_processing\"}, {\"term\": \"SSIM\", \"category\": \"signal_processing\"}, {\"term\": \"similarity measure\", \"category\": \"signal_processing\"}], \"evidence\": [\"what our visual system detects is not the absolute change, but the relative change - delta divided by the background.\", \"So, when we design a similarity measure, we want it to reflect this property of human vision. And that's exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide22.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:32:56.599441+00:00\", \"text_length\": 1053, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a simple example of a changeover background.\\n\\nLook at the first column on the left. The top image has about 10 dots, while the bottom has about 20 dots. The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one.\\nNow look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference.\\n\\nWhy? Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110.\\nThis illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\n\\nSo, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide22.json",
        "parsed": {
          "concepts": [
            {
              "term": "changeover background",
              "category": "quality_metric"
            },
            {
              "term": "contrast comparison in SSIM",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change - delta divided by the background."
          ]
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:03:27.347635+00:00\", \"text_length\": 1053, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a simple example of a changeover background.\\n\\nLook at the first column on the left. The top image has about 10 dots, while the bottom has about 20 dots. The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one.\\nNow look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference.\\n\\nWhy? Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110.\\nThis illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\n\\nSo, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"changeover background\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"what our visual system detects is not the absolute change, but the relative change — delta divided by the background\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"contrast comparison in SSIM\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"changeover background\", \"category\": \"quality_metric\"}, {\"term\": \"contrast comparison in SSIM\", \"category\": \"quality_metric\"}], \"evidence\": [\"This illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change - delta divided by the background.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide22.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide22\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:12:56.575490+00:00\", \"text_length\": 1053, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a simple example of a changeover background.\\n\\nLook at the first column on the left. The top image has about 10 dots, while the bottom has about 20 dots. The difference is 10. When you compare them, it’s very obvious that the bottom one has more dots than the top one.\\nNow look at the second column. The top image has about 110 dots, and the bottom has about 120 dots. Again, the difference is 10. But this time, it’s much harder to notice the difference.\\n\\nWhy? Because the background level — the total number of dots — is so much higher. A change of 10 is a large fraction when the background is only 10, but it’s a tiny fraction when the background is already 110.\\nThis illustrates the principle we just discussed: what our visual system detects is not the absolute change, but the relative change — delta divided by the background.\\n\\nSo, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"the contrast comparison in SSIM\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"the relative change — delta divided by the background\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"So, when we design a similarity measure, we want it to reflect this property of human vision. And that’s exactly what the contrast comparison in SSIM does. It behaves in a way that is consistent with how we see.\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}