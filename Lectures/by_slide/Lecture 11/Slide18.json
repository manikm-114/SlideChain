{
  "lecture": "Lecture 11",
  "slide_id": "Slide18",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide18.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide18.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide18.json",
        "parsed": {
          "term": "dynamic range of pixel values",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo let’s begin with the first component of SSIM: the luminance comparison.\\n\\nRemember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\n\\nMathematically, the luminance comparison is written like this:\\nL of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\nHere, mu-X and mu-Y represent the average brightness of images X and Y. The constant C1 is added to make the formula stable — otherwise, if both means are very close to zero, the denominator becomes tiny and the ratio unstable.\\nTo choose C1, we take the square of K1 times L, where L is the dynamic range of pixel values. For an 8-bit grayscale image, L is 255. K1 is just a very small number, much less than one.\\n\\nNow, notice a few important properties:\\nIf the two means are equal, then the numerator and denominator are the same, so the luminance comparison equals 1, meaning perfect similarity.\\nIf the two means are very different, the numerator becomes small relative to the denominator, so the luminance comparison approaches 0, meaning poor similarity.\\n\\nThis simple formula ensures that luminance similarity satisfies the three postulates we discussed earlier: it is symmetric, bounded between 0 and 1, and it reaches the maximum value of 1 only when the two images have identical mean brightness.\\nSo luminance is the first step in measuring structural similarity. Next, we’ll look at contrast comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mean intensity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"dynamic range\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"pixel values\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"luminance comparison\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mu-X\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mu-Y\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"C1\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"K1\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"dynamic range of pixel values\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Remember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\\", \\\"Mathematically, the luminance comparison is written like this: L of X and Y equals two times mu-X times mu-Y, plus a constant C1\", \"parsed\": {\"term\": \"dynamic range of pixel values\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide18.json",
        "parsed": {
          "triples": [
            {
              "s": "luminance",
              "p": "measures",
              "o": "mean brightness",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 0.0,
              "evidence": "mu-X and mu-Y represent the average brightness of images X and Y."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo let’s begin with the first component of SSIM: the luminance comparison.\\n\\nRemember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\n\\nMathematically, the luminance comparison is written like this:\\nL of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\nHere, mu-X and mu-Y represent the average brightness of images X and Y. The constant C1 is added to make the formula stable — otherwise, if both means are very close to zero, the denominator becomes tiny and the ratio unstable.\\nTo choose C1, we take the square of K1 times L, where L is the dynamic range of pixel values. For an 8-bit grayscale image, L is 255. K1 is just a very small number, much less than one.\\n\\nNow, notice a few important properties:\\nIf the two means are equal, then the numerator and denominator are the same, so the luminance comparison equals 1, meaning perfect similarity.\\nIf the two means are very different, the numerator becomes small relative to the denominator, so the luminance comparison approaches 0, meaning poor similarity.\\n\\nThis simple formula ensures that luminance similarity satisfies the three postulates we discussed earlier: it is symmetric, bounded between 0 and 1, and it reaches the maximum value of 1 only when the two images have identical mean brightness.\\nSo luminance is the first step in measuring structural similarity. Next, we’ll look at contrast comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"luminance\\\", \\\"p\\\":\\\"measures\\\",\\n     \\\"o\\\":\\\"mean brightness\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"mu-X and mu-Y represent the average brightness of images X and Y.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"luminance\", \"p\": \"measures\", \"o\": \"mean brightness\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.0, \"evidence\": \"mu-X and mu-Y represent the average brightness of images X and Y.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide18.json",
        "parsed": {
          "term": "quality_metric",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"mean intensity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"dynamic range\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"symmetric\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"bounded between 0 and 1\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"maximum value of 1\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"quality_metric\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"luminance simply means the average brightness of an image\\\",\\n    \\\"If two images have the same mean intensity, they should score highly on luminance similarity\\\",\\n    \\\"L of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1\\\",\\n    \\\"the luminance comparison equals 1, meaning perfect similarity\\\",\", \"parsed\": {\"term\": \"quality_metric\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide18.json",
        "parsed": {
          "s": "luminance comparison",
          "p": "measures",
          "o": "average brightness",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "luminance simply means the average brightness of an image."
          ]
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"luminance comparison\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"constant C1\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"where the constant C1 is included to avoid instability when μx² + μy² is very close to zero.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"constant C1\\\",\\n      \\\"p\\\": \\\"is\\\",\\n      \\\"o\\\": \\\"(K1L)²\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"C1 = (K1L)²\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"luminance comparison\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"average brightness\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"luminance simply means the average brightness of an image.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"luminance comparison\\\",\\n      \\\"p\\\": \\\"depends_on\\\",\\n      \\\"o\\\": \\\"mean intensity\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.\", \"parsed\": {\"s\": \"luminance comparison\", \"p\": \"measures\", \"o\": \"average brightness\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"luminance simply means the average brightness of an image.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide18.json",
        "parsed": {
          "term": "contrast comparison",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:50:23.708419+00:00\", \"text_length\": 1644, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo let’s begin with the first component of SSIM: the luminance comparison.\\n\\nRemember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\n\\nMathematically, the luminance comparison is written like this:\\nL of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\nHere, mu-X and mu-Y represent the average brightness of images X and Y. The constant C1 is added to make the formula stable — otherwise, if both means are very close to zero, the denominator becomes tiny and the ratio unstable.\\nTo choose C1, we take the square of K1 times L, where L is the dynamic range of pixel values. For an 8-bit grayscale image, L is 255. K1 is just a very small number, much less than one.\\n\\nNow, notice a few important properties:\\nIf the two means are equal, then the numerator and denominator are the same, so the luminance comparison equals 1, meaning perfect similarity.\\nIf the two means are very different, the numerator becomes small relative to the denominator, so the luminance comparison approaches 0, meaning poor similarity.\\n\\nThis simple formula ensures that luminance similarity satisfies the three postulates we discussed earlier: it is symmetric, bounded between 0 and 1, and it reaches the maximum value of 1 only when the two images have identical mean brightness.\\nSo luminance is the first step in measuring structural similarity. Next, we’ll look at contrast comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"average brightness\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"mean intensity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"dynamic range\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pixel values\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"8-bit grayscale image\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"K1\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"C1\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"symmetric\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"bounded\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"maximum value\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"luminance simply means the average brightness of an image\\\",\\n    \\\"the constant C1 is added to make the formula stable\\\",\\n    \\\"the luminance comparison equals 1, meaning perfect similarity\\\",\\n    \\\"\", \"parsed\": {\"term\": \"contrast comparison\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide18.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:30:27.796259+00:00\", \"text_length\": 1644, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo let’s begin with the first component of SSIM: the luminance comparison.\\n\\nRemember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\n\\nMathematically, the luminance comparison is written like this:\\nL of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\nHere, mu-X and mu-Y represent the average brightness of images X and Y. The constant C1 is added to make the formula stable — otherwise, if both means are very close to zero, the denominator becomes tiny and the ratio unstable.\\nTo choose C1, we take the square of K1 times L, where L is the dynamic range of pixel values. For an 8-bit grayscale image, L is 255. K1 is just a very small number, much less than one.\\n\\nNow, notice a few important properties:\\nIf the two means are equal, then the numerator and denominator are the same, so the luminance comparison equals 1, meaning perfect similarity.\\nIf the two means are very different, the numerator becomes small relative to the denominator, so the luminance comparison approaches 0, meaning poor similarity.\\n\\nThis simple formula ensures that luminance similarity satisfies the three postulates we discussed earlier: it is symmetric, bounded between 0 and 1, and it reaches the maximum value of 1 only when the two images have identical mean brightness.\\nSo luminance is the first step in measuring structural similarity. Next, we’ll look at contrast comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"luminance comparison\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"average brightness of images X and Y\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"L of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide18.json",
        "parsed": {
          "term": "the luminance comparison approaches 0",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:02:50.808684+00:00\", \"text_length\": 1644, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nSo let’s begin with the first component of SSIM: the luminance comparison.\\n\\nRemember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\n\\nMathematically, the luminance comparison is written like this:\\nL of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\nHere, mu-X and mu-Y represent the average brightness of images X and Y. The constant C1 is added to make the formula stable — otherwise, if both means are very close to zero, the denominator becomes tiny and the ratio unstable.\\nTo choose C1, we take the square of K1 times L, where L is the dynamic range of pixel values. For an 8-bit grayscale image, L is 255. K1 is just a very small number, much less than one.\\n\\nNow, notice a few important properties:\\nIf the two means are equal, then the numerator and denominator are the same, so the luminance comparison equals 1, meaning perfect similarity.\\nIf the two means are very different, the numerator becomes small relative to the denominator, so the luminance comparison approaches 0, meaning poor similarity.\\n\\nThis simple formula ensures that luminance similarity satisfies the three postulates we discussed earlier: it is symmetric, bounded between 0 and 1, and it reaches the maximum value of 1 only when the two images have identical mean brightness.\\nSo luminance is the first step in measuring structural similarity. Next, we’ll look at contrast comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"luminance comparison\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"luminance\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mu-X and mu-Y represent the average brightness of images X and Y\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"C1 is added to make the formula stable\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"C1 = (K1 L)^2\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"L is the dynamic range of the pixel values\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"K1 << 1 is a small constant\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"the numerator and denominator are the same, so the luminance comparison equals 1\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"the luminance comparison approaches 0\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"\", \"parsed\": {\"term\": \"the luminance comparison approaches 0\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide18.json",
        "parsed": {
          "s": "luminance comparison",
          "p": "produces",
          "o": "value between 0 and 1",
          "modalities": [
            "text"
          ],
          "confidence": 0.95,
          "evidence": [
            "Equation (6) is easily seen to obey the three properties listed above."
          ]
        },
        "raw": "{\"slide_id\": \"Slide18\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:12:39.652469+00:00\", \"text_length\": 1644, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nSo let’s begin with the first component of SSIM: the luminance comparison.\\n\\nRemember, luminance simply means the average brightness of an image. If two images have the same mean intensity, they should score highly on luminance similarity. If one image is much brighter or darker than the other, the similarity should be lower.\\n\\nMathematically, the luminance comparison is written like this:\\nL of X and Y equals two times mu-X times mu-Y, plus a constant C1, all divided by mu-X squared plus mu-Y squared, plus that same constant C1.\\nHere, mu-X and mu-Y represent the average brightness of images X and Y. The constant C1 is added to make the formula stable — otherwise, if both means are very close to zero, the denominator becomes tiny and the ratio unstable.\\nTo choose C1, we take the square of K1 times L, where L is the dynamic range of pixel values. For an 8-bit grayscale image, L is 255. K1 is just a very small number, much less than one.\\n\\nNow, notice a few important properties:\\nIf the two means are equal, then the numerator and denominator are the same, so the luminance comparison equals 1, meaning perfect similarity.\\nIf the two means are very different, the numerator becomes small relative to the denominator, so the luminance comparison approaches 0, meaning poor similarity.\\n\\nThis simple formula ensures that luminance similarity satisfies the three postulates we discussed earlier: it is symmetric, bounded between 0 and 1, and it reaches the maximum value of 1 only when the two images have identical mean brightness.\\nSo luminance is the first step in measuring structural similarity. Next, we’ll look at contrast comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"luminance comparison\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"average brightness\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"luminance simply means the average brightness of an image.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"luminance comparison\\\",\\n      \\\"p\\\": \\\"produces\\\",\\n      \\\"o\\\": \\\"value between 0 and 1\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Equation (6) is easily seen to obey the three properties listed above.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"luminance comparison\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"mu-x and mu-y\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"l(x,y) = 2μxμy + C1 / μx² + μy² + C1, where μx and μy represent the average brightness of images X and Y.\\\"\", \"parsed\": {\"s\": \"luminance comparison\", \"p\": \"produces\", \"o\": \"value between 0 and 1\", \"modalities\": [\"text\"], \"confidence\": 0.95, \"evidence\": [\"Equation (6) is easily seen to obey the three properties listed above.\"]}}"
      }
    }
  }
}