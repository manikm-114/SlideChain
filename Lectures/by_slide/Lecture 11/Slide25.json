{
  "lecture": "Lecture 11",
  "slide_id": "Slide25",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide25.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide25.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide25.json",
        "parsed": {
          "term": "mean squared error",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd now, we can finally put everything together.\\n\\nWe’ve defined three components: luminance comparison, contrast comparison, and structural comparison. Each one captures a different aspect of how two images may look alike or differ. The Structural Similarity Index, or SSIM, is built by combining all three.\\nMathematically, the SSIM of X and Y is written as:\\nluminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma.\\n\\nThe parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components. In practice, we usually set all three equal to one, giving equal weight to luminance, contrast, and structure.\\nTo keep the formula stable, we also include constants — C1, C2, and C3. These prevent divisions by very small numbers, which could make the result unstable. For convenience, researchers often set C3 equal to half of C2. These are empirical design choices, not strict theory, but they work well in practice.\\nWith these simplifications, we arrive at the familiar form of SSIM that is widely used today. This measure is often referred to as the Universal Quality Index with stabilizing constants added.\\n\\nThe remarkable thing is how well SSIM works. Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\n\\nSo, this is the moment where SSIM is born — a simple but powerful measure that aligns closely with human perception and has stood the test of time.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"structure\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"alpha\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"beta\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"gamma\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"luminance term\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"contrast term\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"structure term\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"SSIM formula\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Universal Quality Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"stabilizing constants\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"And now, we can finally put everything together.\\\", \\n               \\\"We’ve defined three components: luminance comparison, contrast comparison\", \"parsed\": {\"term\": \"mean squared error\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide25.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd now, we can finally put everything together.\\n\\nWe’ve defined three components: luminance comparison, contrast comparison, and structural comparison. Each one captures a different aspect of how two images may look alike or differ. The Structural Similarity Index, or SSIM, is built by combining all three.\\nMathematically, the SSIM of X and Y is written as:\\nluminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma.\\n\\nThe parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components. In practice, we usually set all three equal to one, giving equal weight to luminance, contrast, and structure.\\nTo keep the formula stable, we also include constants — C1, C2, and C3. These prevent divisions by very small numbers, which could make the result unstable. For convenience, researchers often set C3 equal to half of C2. These are empirical design choices, not strict theory, but they work well in practice.\\nWith these simplifications, we arrive at the familiar form of SSIM that is widely used today. This measure is often referred to as the Universal Quality Index with stabilizing constants added.\\n\\nThe remarkable thing is how well SSIM works. Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\n\\nSo, this is the moment where SSIM is born — a simple but powerful measure that aligns closely with human perception and has stood the test of time.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Structural Similarity Index (SSIM)\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Image Quality\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"SSIM is built by combining luminance comparison, contrast comparison, and structural comparison. It has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide25.json",
        "parsed": {
          "term": "Universal Quality Index",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"luminance comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Structural Similarity Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"luminance term\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast term\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structure term\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"alpha\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"beta\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"gamma\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"constants\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C1\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C2\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C3\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Universal Quality Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"\", \"parsed\": {\"term\": \"Universal Quality Index\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide25.json",
        "parsed": {
          "triples": [
            {
              "s": "SSIM",
              "p": "uses",
              "o": "luminance comparison, contrast comparison, and structural comparison",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "We’ve defined three components: luminance comparison, contrast comparison, and structural comparison."
            },
            {
              "s": "SSIM",
              "p": "depends_on",
              "o": "parameters alpha, beta, and gamma",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "The parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"similarity between signals x and y\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The Structural Similarity Index, or SSIM, is built by combining all three.\\\"},\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"luminance comparison, contrast comparison, and structural comparison\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"We’ve defined three components: luminance comparison, contrast comparison, and structural comparison.\\\"},\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"depends_on\\\", \\\"o\\\":\\\"parameters alpha, beta, and gamma\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components.\\\"},\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"constants C1, C2, and C3\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"To keep the formula stable, we also include constants — C1, C2, and C3.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"SSIM\", \"p\": \"uses\", \"o\": \"luminance comparison, contrast comparison, and structural comparison\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"We’ve defined three components: luminance comparison, contrast comparison, and structural comparison.\"}, {\"s\": \"SSIM\", \"p\": \"depends_on\", \"o\": \"parameters alpha, beta, and gamma\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"The parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide25.json",
        "parsed": {
          "term": "human perception",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T04:02:35.612797+00:00\", \"text_length\": 1716, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd now, we can finally put everything together.\\n\\nWe’ve defined three components: luminance comparison, contrast comparison, and structural comparison. Each one captures a different aspect of how two images may look alike or differ. The Structural Similarity Index, or SSIM, is built by combining all three.\\nMathematically, the SSIM of X and Y is written as:\\nluminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma.\\n\\nThe parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components. In practice, we usually set all three equal to one, giving equal weight to luminance, contrast, and structure.\\nTo keep the formula stable, we also include constants — C1, C2, and C3. These prevent divisions by very small numbers, which could make the result unstable. For convenience, researchers often set C3 equal to half of C2. These are empirical design choices, not strict theory, but they work well in practice.\\nWith these simplifications, we arrive at the familiar form of SSIM that is widely used today. This measure is often referred to as the Universal Quality Index with stabilizing constants added.\\n\\nThe remarkable thing is how well SSIM works. Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\n\\nSo, this is the moment where SSIM is born — a simple but powerful measure that aligns closely with human perception and has stood the test of time.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"luminance comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"alpha\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"beta\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"gamma\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C1\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C2\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"C3\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Universal Quality Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"deep learning\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"advanced algorithms\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"image quality\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"human perception\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"standards\\\", \\\"category\", \"parsed\": {\"term\": \"human perception\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide25.json",
        "parsed": {
          "triples": [
            {
              "s": "SSIM",
              "p": "measures",
              "o": "image quality",
              "modalities": [
                "text",
                "image"
              ],
              "confidence": 1.0,
              "evidence": "Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:34:56.883906+00:00\", \"text_length\": 1716, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd now, we can finally put everything together.\\n\\nWe’ve defined three components: luminance comparison, contrast comparison, and structural comparison. Each one captures a different aspect of how two images may look alike or differ. The Structural Similarity Index, or SSIM, is built by combining all three.\\nMathematically, the SSIM of X and Y is written as:\\nluminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma.\\n\\nThe parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components. In practice, we usually set all three equal to one, giving equal weight to luminance, contrast, and structure.\\nTo keep the formula stable, we also include constants — C1, C2, and C3. These prevent divisions by very small numbers, which could make the result unstable. For convenience, researchers often set C3 equal to half of C2. These are empirical design choices, not strict theory, but they work well in practice.\\nWith these simplifications, we arrive at the familiar form of SSIM that is widely used today. This measure is often referred to as the Universal Quality Index with stabilizing constants added.\\n\\nThe remarkable thing is how well SSIM works. Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\n\\nSo, this is the moment where SSIM is born — a simple but powerful measure that aligns closely with human perception and has stood the test of time.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"image quality\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"SSIM\", \"p\": \"measures\", \"o\": \"image quality\", \"modalities\": [\"text\", \"image\"], \"confidence\": 1.0, \"evidence\": \"Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide25.json",
        "parsed": {
          "term": "stabilizing constants",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:03:58.505393+00:00\", \"text_length\": 1716, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd now, we can finally put everything together.\\n\\nWe’ve defined three components: luminance comparison, contrast comparison, and structural comparison. Each one captures a different aspect of how two images may look alike or differ. The Structural Similarity Index, or SSIM, is built by combining all three.\\nMathematically, the SSIM of X and Y is written as:\\nluminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma.\\n\\nThe parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components. In practice, we usually set all three equal to one, giving equal weight to luminance, contrast, and structure.\\nTo keep the formula stable, we also include constants — C1, C2, and C3. These prevent divisions by very small numbers, which could make the result unstable. For convenience, researchers often set C3 equal to half of C2. These are empirical design choices, not strict theory, but they work well in practice.\\nWith these simplifications, we arrive at the familiar form of SSIM that is widely used today. This measure is often referred to as the Universal Quality Index with stabilizing constants added.\\n\\nThe remarkable thing is how well SSIM works. Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\n\\nSo, this is the moment where SSIM is born — a simple but powerful measure that aligns closely with human perception and has stood the test of time.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"structural similarity index\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"luminance comparison\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"contrast comparison\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"structural comparison\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"luminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"parameters alpha, beta, and gamma\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"constants — C1, C2, and C3\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"universal quality index\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"stabilizing constants\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mean squared error\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\", \"parsed\": {\"term\": \"stabilizing constants\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide25.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide25\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:13:08.189942+00:00\", \"text_length\": 1716, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAnd now, we can finally put everything together.\\n\\nWe’ve defined three components: luminance comparison, contrast comparison, and structural comparison. Each one captures a different aspect of how two images may look alike or differ. The Structural Similarity Index, or SSIM, is built by combining all three.\\nMathematically, the SSIM of X and Y is written as:\\nluminance term raised to the power alpha, multiplied by the contrast term raised to the power beta, multiplied by the structure term raised to the power gamma.\\n\\nThe parameters alpha, beta, and gamma simply allow us to adjust the relative importance of the three components. In practice, we usually set all three equal to one, giving equal weight to luminance, contrast, and structure.\\nTo keep the formula stable, we also include constants — C1, C2, and C3. These prevent divisions by very small numbers, which could make the result unstable. For convenience, researchers often set C3 equal to half of C2. These are empirical design choices, not strict theory, but they work well in practice.\\nWith these simplifications, we arrive at the familiar form of SSIM that is widely used today. This measure is often referred to as the Universal Quality Index with stabilizing constants added.\\n\\nThe remarkable thing is how well SSIM works. Despite its simplicity, it has become one of the most widely used metrics for image quality, both in research and in industry. Even today, when we use deep learning and advanced algorithms for image processing, SSIM and mean squared error remain the standard reference metrics.\\n\\nSo, this is the moment where SSIM is born — a simple but powerful measure that aligns closely with human perception and has stood the test of time.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}