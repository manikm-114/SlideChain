{
  "lecture": "Lecture 11",
  "slide_id": "Slide39",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide39.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide39.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide39.json",
        "parsed": {
          "term": "screening program",
          "category": "workflow"
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a concrete example using tuberculosis screening with chest X-ray. In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\n\\nLet’s break this down.\\nAmong the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\nAmong the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\n\\nNow, from this table, we can calculate the standard measures:\\nSensitivity: 22 out of 30 true TB cases were detected → about 73%. This means the system caught almost three-quarters of real cases.\\nSpecificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%. This shows the system rarely gave false alarms.\\nPositive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%. This is much lower, meaning that when the system flagged a case as positive, it was wrong more often than it was right.\\nNegative Predictive Value (NPV): 1,739 out of 1,747 reported negatives were truly healthy → nearly 99.5%. This means a negative result was highly reliable.\\nDiagnostic Accuracy: The proportion of all correct results, positive and negative, was about 97%.\\nPrevalence: Only 30 out of 1,820 people had TB → around 1.6%.\\n\\nNotice something important here: although accuracy and NPV are very high, the PPV is quite low. That’s because the disease is rare in this population — when prevalence is low, even a small number of false positives can outweigh the true positives.\\n\\nThis example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world conditions.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"positive predictive value (PPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"negative predictive value (NPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"prevalence\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"accuracy\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"disease\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"screening program\\\", \\\"category\\\": \\\"workflow\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Among the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\\", \\\"Among the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\\", \\\"This example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world\", \"parsed\": {\"term\": \"screening program\", \"category\": \"workflow\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide39.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a concrete example using tuberculosis screening with chest X-ray. In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\n\\nLet’s break this down.\\nAmong the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\nAmong the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\n\\nNow, from this table, we can calculate the standard measures:\\nSensitivity: 22 out of 30 true TB cases were detected → about 73%. This means the system caught almost three-quarters of real cases.\\nSpecificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%. This shows the system rarely gave false alarms.\\nPositive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%. This is much lower, meaning that when the system flagged a case as positive, it was wrong more often than it was right.\\nNegative Predictive Value (NPV): 1,739 out of 1,747 reported negatives were truly healthy → nearly 99.5%. This means a negative result was highly reliable.\\nDiagnostic Accuracy: The proportion of all correct results, positive and negative, was about 97%.\\nPrevalence: Only 30 out of 1,820 people had TB → around 1.6%.\\n\\nNotice something important here: although accuracy and NPV are very high, the PPV is quite low. That’s because the disease is rare in this population — when prevalence is low, even a small number of false positives can outweigh the true positives.\\n\\nThis example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world conditions.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<2,000 people were tested>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<nearly 30 actually had tuberculosis>\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide39.json",
        "parsed": {
          "term": "tuberculosis",
          "category": "anatomy"
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Positive Predictive Value (PPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Negative Predictive Value (NPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Diagnostic Accuracy\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Prevalence\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"chest X-ray\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"tuberculosis\\\", \\\"category\\\": \\\"anatomy\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Sensitivity: 22 out of 30 true TB cases were detected → about 73%\\\",\\n    \\\"Specificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%\\\",\\n    \\\"Positive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%\\\",\\n    \\\"Negative Predictive Value (NPV): 1,739 out of 1,747\", \"parsed\": {\"term\": \"tuberculosis\", \"category\": \"anatomy\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide39.json",
        "parsed": {
          "s": "the system",
          "p": "measures",
          "o": "positive predictive value (PPV)",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "Positive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%."
          ]
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"chest X-ray\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"tuberculosis\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Here’s a concrete example using tuberculosis screening with chest X-ray.\\\"},\\n    {\\\"s\\\":\\\"the system\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"sensitivity\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Sensitivity: 22 out of 30 true TB cases were detected → about 73%.\\\"},\\n    {\\\"s\\\":\\\"the system\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"specificity\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Specificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%.\\\"},\\n    {\\\"s\\\":\\\"the system\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"positive predictive value (PPV)\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Positive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%.\\\"},\\n    {\\\"s\\\":\\\"the\", \"parsed\": {\"s\": \"the system\", \"p\": \"measures\", \"o\": \"positive predictive value (PPV)\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"Positive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide39.json",
        "parsed": {
          "term": "Positive Predictive Value (PPV)",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T04:28:08.010452+00:00\", \"text_length\": 1791, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a concrete example using tuberculosis screening with chest X-ray. In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\n\\nLet’s break this down.\\nAmong the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\nAmong the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\n\\nNow, from this table, we can calculate the standard measures:\\nSensitivity: 22 out of 30 true TB cases were detected → about 73%. This means the system caught almost three-quarters of real cases.\\nSpecificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%. This shows the system rarely gave false alarms.\\nPositive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%. This is much lower, meaning that when the system flagged a case as positive, it was wrong more often than it was right.\\nNegative Predictive Value (NPV): 1,739 out of 1,747 reported negatives were truly healthy → nearly 99.5%. This means a negative result was highly reliable.\\nDiagnostic Accuracy: The proportion of all correct results, positive and negative, was about 97%.\\nPrevalence: Only 30 out of 1,820 people had TB → around 1.6%.\\n\\nNotice something important here: although accuracy and NPV are very high, the PPV is quite low. That’s because the disease is rare in this population — when prevalence is low, even a small number of false positives can outweigh the true positives.\\n\\nThis example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world conditions.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Positive Predictive Value (PPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Negative Predictive Value (NPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Diagnostic Accuracy (DA)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Prevalence (PR)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Tuberculosis\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"X-Ray\\\", \\\"category\\\": \\\"modality\\\"},\\n    {\\\"term\\\": \\\"True Positive\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"True Negative\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"False Positive\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"False Negative\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Accuracy\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Positive Predictive Value (PPV)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Negative Predictive Value (NPV)\\\", \\\"category\\\": \\\"quality_metric\", \"parsed\": {\"term\": \"Positive Predictive Value (PPV)\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide39.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:45:10.221947+00:00\", \"text_length\": 1791, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a concrete example using tuberculosis screening with chest X-ray. In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\n\\nLet’s break this down.\\nAmong the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\nAmong the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\n\\nNow, from this table, we can calculate the standard measures:\\nSensitivity: 22 out of 30 true TB cases were detected → about 73%. This means the system caught almost three-quarters of real cases.\\nSpecificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%. This shows the system rarely gave false alarms.\\nPositive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%. This is much lower, meaning that when the system flagged a case as positive, it was wrong more often than it was right.\\nNegative Predictive Value (NPV): 1,739 out of 1,747 reported negatives were truly healthy → nearly 99.5%. This means a negative result was highly reliable.\\nDiagnostic Accuracy: The proportion of all correct results, positive and negative, was about 97%.\\nPrevalence: Only 30 out of 1,820 people had TB → around 1.6%.\\n\\nNotice something important here: although accuracy and NPV are very high, the PPV is quite low. That’s because the disease is rare in this population — when prevalence is low, even a small number of false positives can outweigh the true positives.\\n\\nThis example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world conditions.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim sensitivity>\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"<verbatim 73.3%>\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Sensitivity = 22 / 30 = 73.3%\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide39.json",
        "parsed": {
          "term": "chest X-ray",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:06:22.746130+00:00\", \"text_length\": 1791, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a concrete example using tuberculosis screening with chest X-ray. In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\n\\nLet’s break this down.\\nAmong the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\nAmong the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\n\\nNow, from this table, we can calculate the standard measures:\\nSensitivity: 22 out of 30 true TB cases were detected → about 73%. This means the system caught almost three-quarters of real cases.\\nSpecificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%. This shows the system rarely gave false alarms.\\nPositive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%. This is much lower, meaning that when the system flagged a case as positive, it was wrong more often than it was right.\\nNegative Predictive Value (NPV): 1,739 out of 1,747 reported negatives were truly healthy → nearly 99.5%. This means a negative result was highly reliable.\\nDiagnostic Accuracy: The proportion of all correct results, positive and negative, was about 97%.\\nPrevalence: Only 30 out of 1,820 people had TB → around 1.6%.\\n\\nNotice something important here: although accuracy and NPV are very high, the PPV is quite low. That’s because the disease is rare in this population — when prevalence is low, even a small number of false positives can outweigh the true positives.\\n\\nThis example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world conditions.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Sensitivity\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Specificity\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Positive Predictive Value (PPV)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Negative Predictive Value (NPV)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Diagnostic Accuracy (DA)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Prevalence (PR)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"chest X-ray\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Sensitivity: 22 out of 30 true TB cases were detected → about 73%.\\\",\\n    \\\"Specificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%.\\\",\\n    \\\"Positive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30\", \"parsed\": {\"term\": \"chest X-ray\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide39.json",
        "parsed": {
          "s": "Specificity",
          "p": "measures",
          "o": "1,739 out of 1,790 healthy cases were correctly identified",
          "modalities": [
            "text"
          ],
          "confidence": 0.95,
          "evidence": [
            "Among the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority - 1,739 - were correctly classified as negative."
          ]
        },
        "raw": "{\"slide_id\": \"Slide39\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:15:09.331302+00:00\", \"text_length\": 1791, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s a concrete example using tuberculosis screening with chest X-ray. In this study, nearly 2,000 people were tested, but only 30 actually had tuberculosis.\\n\\nLet’s break this down.\\nAmong the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\nAmong the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\n\\nNow, from this table, we can calculate the standard measures:\\nSensitivity: 22 out of 30 true TB cases were detected → about 73%. This means the system caught almost three-quarters of real cases.\\nSpecificity: 1,739 out of 1,790 healthy cases were correctly identified → about 97%. This shows the system rarely gave false alarms.\\nPositive Predictive Value (PPV): 22 out of 73 reported positives were real TB cases → only 30%. This is much lower, meaning that when the system flagged a case as positive, it was wrong more often than it was right.\\nNegative Predictive Value (NPV): 1,739 out of 1,747 reported negatives were truly healthy → nearly 99.5%. This means a negative result was highly reliable.\\nDiagnostic Accuracy: The proportion of all correct results, positive and negative, was about 97%.\\nPrevalence: Only 30 out of 1,820 people had TB → around 1.6%.\\n\\nNotice something important here: although accuracy and NPV are very high, the PPV is quite low. That’s because the disease is rare in this population — when prevalence is low, even a small number of false positives can outweigh the true positives.\\n\\nThis example shows why we need to interpret these metrics carefully, especially in screening programs. Sensitivity, specificity, PPV, NPV, and prevalence all interact, and each tells us something different about how the test performs in real-world conditions.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Sensitivity\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"22 out of 30 true TB cases were detected\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Among the 30 true TB patients, 22 were correctly reported as positive, while 8 were missed.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Specificity\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"1,739 out of 1,790 healthy cases were correctly identified\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Among the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority — 1,739 — were correctly classified as negative.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Positive Predictive Value (PPV)\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"22 out of 73 reported positives were real TB cases\\\",\\n      \\\"modalities\\\": [\\n        \\\"\", \"parsed\": {\"s\": \"Specificity\", \"p\": \"measures\", \"o\": \"1,739 out of 1,790 healthy cases were correctly identified\", \"modalities\": [\"text\"], \"confidence\": 0.95, \"evidence\": [\"Among the 1,790 healthy individuals, 51 were incorrectly reported as positive, but the majority - 1,739 - were correctly classified as negative.\"]}}"
      }
    }
  }
}