{
  "lecture": "Lecture 11",
  "slide_id": "Slide43",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide43.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide43.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide43.json",
        "parsed": {
          "concepts": [
            {
              "term": "threshold",
              "category": "signal_processing"
            },
            {
              "term": "ROC curve",
              "category": "signal_processing"
            },
            {
              "term": "false negatives",
              "category": "quality_metric"
            },
            {
              "term": "false positives",
              "category": "quality_metric"
            },
            {
              "term": "decision threshold",
              "category": "signal_processing"
            },
            {
              "term": "trade-off",
              "category": "signal_processing"
            },
            {
              "term": "sensitivity",
              "category": "quality_metric"
            },
            {
              "term": "specificity",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "In reality, things are rarely so clear-cut.",
            "Most of the time, the distributions of healthy and diseased patients overlap.",
            "So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.",
            "This overlap is exactly what forces us to think carefully about where to place the decision threshold.",
            "And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds."
          ]
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nIn reality, things are rarely so clear-cut.\\n\\nMost of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\nFor example, suppose we run a blood test or measure a tumor-related biomarker. Healthy patients tend to cluster around one range, while diseased patients cluster around another. But because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\n\\nSo when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors. Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives. Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\n\\nThis overlap is exactly what forces us to think carefully about where to place the decision threshold. And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"threshold\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"ROC curve\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"false negatives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"false positives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"decision threshold\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"trade-off\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"specificity\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"In reality, things are rarely so clear-cut.\\\", \\\"Most of the time, the distributions of healthy and diseased patients overlap.\\\", \\\"So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.\\\", \\\"This overlap is exactly what forces us to think carefully about where to place the decision threshold.\\\", \\\"And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"threshold\", \"category\": \"signal_processing\"}, {\"term\": \"ROC curve\", \"category\": \"signal_processing\"}, {\"term\": \"false negatives\", \"category\": \"quality_metric\"}, {\"term\": \"false positives\", \"category\": \"quality_metric\"}, {\"term\": \"decision threshold\", \"category\": \"signal_processing\"}, {\"term\": \"trade-off\", \"category\": \"signal_processing\"}, {\"term\": \"sensitivity\", \"category\": \"quality_metric\"}, {\"term\": \"specificity\", \"category\": \"quality_metric\"}], \"evidence\": [\"In reality, things are rarely so clear-cut.\", \"Most of the time, the distributions of healthy and diseased patients overlap.\", \"So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.\", \"This overlap is exactly what forces us to think carefully about where to place the decision threshold.\", \"And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide43.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nIn reality, things are rarely so clear-cut.\\n\\nMost of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\nFor example, suppose we run a blood test or measure a tumor-related biomarker. Healthy patients tend to cluster around one range, while diseased patients cluster around another. But because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\n\\nSo when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors. Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives. Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\n\\nThis overlap is exactly what forces us to think carefully about where to place the decision threshold. And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"disease diagnosis\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"threshold\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"In reality, things are rarely so clear-cut. Most of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide43.json",
        "parsed": {
          "concepts": [
            {
              "term": "distributions",
              "category": "mathematics"
            },
            {
              "term": "overlap",
              "category": "mathematics"
            },
            {
              "term": "threshold",
              "category": "algorithm"
            },
            {
              "term": "false negatives",
              "category": "quality_metric"
            },
            {
              "term": "false positives",
              "category": "quality_metric"
            },
            {
              "term": "decision threshold",
              "category": "algorithm"
            },
            {
              "term": "ROC curve",
              "category": "algorithm"
            },
            {
              "term": "sensitivity",
              "category": "quality_metric"
            },
            {
              "term": "specificity",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "Most of the time, the distributions of healthy and diseased patients overlap.",
            "a threshold placed in the middle will inevitably create two types of errors.",
            "So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.",
            "And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds."
          ]
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"distributions\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"overlap\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"threshold\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"false negatives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"false positives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"decision threshold\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"ROC curve\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"specificity\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Most of the time, the distributions of healthy and diseased patients overlap.\\\",\\n    \\\"a threshold placed in the middle will inevitably create two types of errors.\\\",\\n    \\\"So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.\\\",\\n    \\\"And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"distributions\", \"category\": \"mathematics\"}, {\"term\": \"overlap\", \"category\": \"mathematics\"}, {\"term\": \"threshold\", \"category\": \"algorithm\"}, {\"term\": \"false negatives\", \"category\": \"quality_metric\"}, {\"term\": \"false positives\", \"category\": \"quality_metric\"}, {\"term\": \"decision threshold\", \"category\": \"algorithm\"}, {\"term\": \"ROC curve\", \"category\": \"algorithm\"}, {\"term\": \"sensitivity\", \"category\": \"quality_metric\"}, {\"term\": \"specificity\", \"category\": \"quality_metric\"}], \"evidence\": [\"Most of the time, the distributions of healthy and diseased patients overlap.\", \"a threshold placed in the middle will inevitably create two types of errors.\", \"So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.\", \"And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide43.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"More Realistic Case\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"overlap of healthy and diseased patient distributions\\\",\\n      \\\"modalities\\\": [\\\"image\\\", \\\"text\\\"],\\n      \\\"confidence\\\": 0.9,\\n      \\\"evidence\\\": \\\"Most of the time, the distributions of healthy and diseased patients overlap.\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide43.json",
        "parsed": {
          "term": "trade-off",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T04:36:02.768318+00:00\", \"text_length\": 1142, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nIn reality, things are rarely so clear-cut.\\n\\nMost of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\nFor example, suppose we run a blood test or measure a tumor-related biomarker. Healthy patients tend to cluster around one range, while diseased patients cluster around another. But because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\n\\nSo when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors. Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives. Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\n\\nThis overlap is exactly what forces us to think carefully about where to place the decision threshold. And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"threshold\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"false negatives\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"false positives\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"ROC curve\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"sensitivity\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"specificity\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"biological variation\\\", \\\"category\\\": \\\"biomedical\\\"},\\n    {\\\"term\\\": \\\"measurement noise\\\", \\\"category\\\": \\\"biomedical\\\"},\\n    {\\\"term\\\": \\\"overlapping physiology\\\", \\\"category\\\": \\\"biomedical\\\"},\\n    {\\\"term\\\": \\\"decision threshold\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"trade-off\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"In reality, things are rarely so clear-cut.\\\",\\n    \\\"Most of the time, the distributions of healthy and diseased patients overlap.\\\",\\n    \\\"So when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors.\\\",\\n    \\\"This overlap is exactly what forces us to think carefully about where to place the decision threshold.\\\",\\n    \\\"And it’s what makes tools like the ROC\", \"parsed\": {\"term\": \"trade-off\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide43.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:47:40.455027+00:00\", \"text_length\": 1142, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nIn reality, things are rarely so clear-cut.\\n\\nMost of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\nFor example, suppose we run a blood test or measure a tumor-related biomarker. Healthy patients tend to cluster around one range, while diseased patients cluster around another. But because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\n\\nSo when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors. Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives. Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\n\\nThis overlap is exactly what forces us to think carefully about where to place the decision threshold. And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide43.json",
        "parsed": {
          "term": "Some healthy patients will fall above the threshold and be misclassified as diseased - these are false positives.",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:07:03.889935+00:00\", \"text_length\": 1142, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nIn reality, things are rarely so clear-cut.\\n\\nMost of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\nFor example, suppose we run a blood test or measure a tumor-related biomarker. Healthy patients tend to cluster around one range, while diseased patients cluster around another. But because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\n\\nSo when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors. Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives. Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\n\\nThis overlap is exactly what forces us to think carefully about where to place the decision threshold. And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"In reality, things are rarely so clear-cut.\\\",\\n      \\\"category\\\": \\\"ai_ml\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Most of the time, the distributions of healthy and diseased patients overlap.\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"That means the same measured value could belong either to a healthy individual or to someone with a disease.\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Healthy patients tend to cluster around one range, while diseased patients cluster around another.\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives.\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"This\", \"parsed\": {\"term\": \"Some healthy patients will fall above the threshold and be misclassified as diseased - these are false positives.\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide43.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide43\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:15:41.086680+00:00\", \"text_length\": 1142, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nIn reality, things are rarely so clear-cut.\\n\\nMost of the time, the distributions of healthy and diseased patients overlap. That means the same measured value could belong either to a healthy individual or to someone with a disease.\\nFor example, suppose we run a blood test or measure a tumor-related biomarker. Healthy patients tend to cluster around one range, while diseased patients cluster around another. But because of biological variation, measurement noise, and overlapping physiology, there is no perfect separation.\\n\\nSo when the two distributions overlap, a threshold placed in the middle will inevitably create two types of errors. Some diseased patients will fall below the threshold and be misclassified as healthy — these are false negatives. Some healthy patients will fall above the threshold and be misclassified as diseased — these are false positives.\\n\\nThis overlap is exactly what forces us to think carefully about where to place the decision threshold. And it’s what makes tools like the ROC curve so valuable, because they let us analyze the trade-off between sensitivity and specificity across all possible thresholds.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}