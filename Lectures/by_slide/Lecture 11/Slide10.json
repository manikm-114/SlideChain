{
  "lecture": "Lecture 11",
  "slide_id": "Slide10",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide10.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide10.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide10.json",
        "parsed": {
          "term": "tools",
          "category": "software"
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nMutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\n\\nSo, what is entropy in this context? Think of it as a measure of uncertainty. If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\nOn the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\n\\nSo entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\nNow, mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X. In other words, it measures how much uncertainty about Y is reduced when you know X. That’s exactly what we mean by “how much does X tell us about Y.”\\nAgain, you don’t need to get bogged down in the formulas here. The key point is: entropy captures uncertainty, and mutual information measures how two variables share or reduce that uncertainty.\\n\\nFor our purposes, I just want you to know that these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful, but they are more advanced than what we need right now. Think of them as tools in the background, which complement the simpler measures like mean squared error.\\n\\nAnd with that, we will soon return to the more practical measures that are directly used in image quality assessment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"entropy\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mutual information\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"KL divergence\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"uncertainty\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"random variable\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"reducing uncertainty\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"information-theoretic measures\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"tools\\\", \\\"category\\\": \\\"software\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"So, what is entropy in this context? Think of it as a measure of uncertainty.\\\", \\n               \\\"If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\\", \\n               \\\"On the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\\", \\n               \\\"Mutual information can be written as the difference\", \"parsed\": {\"term\": \"tools\", \"category\": \"software\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide10.json",
        "parsed": {
          "triples": [
            {
              "s": "entropy",
              "p": "measures",
              "o": "uncertainty",
              "modalities": [
                "text"
              ],
              "confidence": 0.9,
              "evidence": "Entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nMutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\n\\nSo, what is entropy in this context? Think of it as a measure of uncertainty. If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\nOn the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\n\\nSo entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\nNow, mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X. In other words, it measures how much uncertainty about Y is reduced when you know X. That’s exactly what we mean by “how much does X tell us about Y.”\\nAgain, you don’t need to get bogged down in the formulas here. The key point is: entropy captures uncertainty, and mutual information measures how two variables share or reduce that uncertainty.\\n\\nFor our purposes, I just want you to know that these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful, but they are more advanced than what we need right now. Think of them as tools in the background, which complement the simpler measures like mean squared error.\\n\\nAnd with that, we will soon return to the more practical measures that are directly used in image quality assessment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"entropy\\\", \\\"p\\\":\\\"measures\\\",\\n     \\\"o\\\":\\\"uncertainty\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.9, \\\"evidence\\\":\\\"Entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"entropy\", \"p\": \"measures\", \"o\": \"uncertainty\", \"modalities\": [\"text\"], \"confidence\": 0.9, \"evidence\": \"Entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide10.json",
        "parsed": {
          "concepts": [
            {
              "term": "entropy",
              "category": "mathematics"
            },
            {
              "term": "mutual information",
              "category": "mathematics"
            },
            {
              "term": "KL divergence",
              "category": "mathematics"
            },
            {
              "term": "mean squared error",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "entropy tells us how much information, or how much unpredictability, is contained in a random variable.",
            "mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X.",
            "these information-theoretic measures - KL divergence, mutual information, and entropy - are very powerful",
            "simpler measures like mean squared error"
          ]
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"entropy\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mutual information\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"KL divergence\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"entropy tells us how much information, or how much unpredictability, is contained in a random variable.\\\",\\n    \\\"mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X.\\\",\\n    \\\"these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful\\\",\\n    \\\"simpler measures like mean squared error\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"entropy\", \"category\": \"mathematics\"}, {\"term\": \"mutual information\", \"category\": \"mathematics\"}, {\"term\": \"KL divergence\", \"category\": \"mathematics\"}, {\"term\": \"mean squared error\", \"category\": \"quality_metric\"}], \"evidence\": [\"entropy tells us how much information, or how much unpredictability, is contained in a random variable.\", \"mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X.\", \"these information-theoretic measures - KL divergence, mutual information, and entropy - are very powerful\", \"simpler measures like mean squared error\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide10.json",
        "parsed": {
          "triples": [
            {
              "s": "entropy",
              "p": "measures",
              "o": "uncertainty",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "entropy tells us how much information, or how much unpredictability, is contained in a random variable."
            },
            {
              "s": "mutual information",
              "p": "measures",
              "o": "how much uncertainty about Y is reduced when you know X",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"entropy\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"uncertainty\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"entropy tells us how much information, or how much unpredictability, is contained in a random variable.\\\"},\\n    {\\\"s\\\":\\\"mutual information\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"how much uncertainty about Y is reduced when you know X\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"entropy\", \"p\": \"measures\", \"o\": \"uncertainty\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"entropy tells us how much information, or how much unpredictability, is contained in a random variable.\"}, {\"s\": \"mutual information\", \"p\": \"measures\", \"o\": \"how much uncertainty about Y is reduced when you know X\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide10.json",
        "parsed": {
          "concepts": [
            {
              "term": "entropy",
              "category": "mathematics"
            },
            {
              "term": "mutual information",
              "category": "mathematics"
            },
            {
              "term": "uncertainty",
              "category": "mathematics"
            },
            {
              "term": "information theory",
              "category": "mathematics"
            },
            {
              "term": "KL divergence",
              "category": "mathematics"
            },
            {
              "term": "mean squared error",
              "category": "mathematics"
            },
            {
              "term": "image quality assessment",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "entropy is a measure of uncertainty",
            "mutual information measures how two variables share or reduce that uncertainty",
            "entropy captures uncertainty",
            "mutual information is the difference between two entropies",
            "these information-theoretic measures are powerful tools",
            "we will soon return to the more practical measures"
          ]
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:37:46.416891+00:00\", \"text_length\": 1730, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nMutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\n\\nSo, what is entropy in this context? Think of it as a measure of uncertainty. If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\nOn the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\n\\nSo entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\nNow, mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X. In other words, it measures how much uncertainty about Y is reduced when you know X. That’s exactly what we mean by “how much does X tell us about Y.”\\nAgain, you don’t need to get bogged down in the formulas here. The key point is: entropy captures uncertainty, and mutual information measures how two variables share or reduce that uncertainty.\\n\\nFor our purposes, I just want you to know that these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful, but they are more advanced than what we need right now. Think of them as tools in the background, which complement the simpler measures like mean squared error.\\n\\nAnd with that, we will soon return to the more practical measures that are directly used in image quality assessment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"entropy\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mutual information\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"uncertainty\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"information theory\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"KL divergence\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"image quality assessment\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"entropy is a measure of uncertainty\\\",\\n    \\\"mutual information measures how two variables share or reduce that uncertainty\\\",\\n    \\\"entropy captures uncertainty\\\",\\n    \\\"mutual information is the difference between two entropies\\\",\\n    \\\"these information-theoretic measures are powerful tools\\\",\\n    \\\"we will soon return to the more practical measures\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"entropy\", \"category\": \"mathematics\"}, {\"term\": \"mutual information\", \"category\": \"mathematics\"}, {\"term\": \"uncertainty\", \"category\": \"mathematics\"}, {\"term\": \"information theory\", \"category\": \"mathematics\"}, {\"term\": \"KL divergence\", \"category\": \"mathematics\"}, {\"term\": \"mean squared error\", \"category\": \"mathematics\"}, {\"term\": \"image quality assessment\", \"category\": \"quality_metric\"}], \"evidence\": [\"entropy is a measure of uncertainty\", \"mutual information measures how two variables share or reduce that uncertainty\", \"entropy captures uncertainty\", \"mutual information is the difference between two entropies\", \"these information-theoretic measures are powerful tools\", \"we will soon return to the more practical measures\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide10.json",
        "parsed": {
          "triples": [
            {
              "s": "Entropy",
              "p": "measures",
              "o": "Uncertainty",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "Entropy tells us how much information, or how much unpredictability, is contained in a random variable."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:23:51.080928+00:00\", \"text_length\": 1730, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nMutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\n\\nSo, what is entropy in this context? Think of it as a measure of uncertainty. If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\nOn the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\n\\nSo entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\nNow, mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X. In other words, it measures how much uncertainty about Y is reduced when you know X. That’s exactly what we mean by “how much does X tell us about Y.”\\nAgain, you don’t need to get bogged down in the formulas here. The key point is: entropy captures uncertainty, and mutual information measures how two variables share or reduce that uncertainty.\\n\\nFor our purposes, I just want you to know that these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful, but they are more advanced than what we need right now. Think of them as tools in the background, which complement the simpler measures like mean squared error.\\n\\nAnd with that, we will soon return to the more practical measures that are directly used in image quality assessment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Entropy\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"Uncertainty\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Entropy tells us how much information, or how much unpredictability, is contained in a random variable.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"Entropy\", \"p\": \"measures\", \"o\": \"Uncertainty\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"Entropy tells us how much information, or how much unpredictability, is contained in a random variable.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide10.json",
        "parsed": {
          "term": "KL divergence, mutual information, and entropy are very powerful, but they are more advanced than what we need right now",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:01:33.402291+00:00\", \"text_length\": 1730, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nMutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\n\\nSo, what is entropy in this context? Think of it as a measure of uncertainty. If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\nOn the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\n\\nSo entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\nNow, mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X. In other words, it measures how much uncertainty about Y is reduced when you know X. That’s exactly what we mean by “how much does X tell us about Y.”\\nAgain, you don’t need to get bogged down in the formulas here. The key point is: entropy captures uncertainty, and mutual information measures how two variables share or reduce that uncertainty.\\n\\nFor our purposes, I just want you to know that these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful, but they are more advanced than what we need right now. Think of them as tools in the background, which complement the simpler measures like mean squared error.\\n\\nAnd with that, we will soon return to the more practical measures that are directly used in image quality assessment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"entropy\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mutual information\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"entropy is a measure of uncertainty\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"entropy tells us how much information, or how much unpredictability, is contained in a random variable\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"it measures how much uncertainty about Y is reduced when you know X\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"information itself is really about reducing uncertainty\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"KL divergence, mutual information, and entropy are very powerful, but they are more advanced than what we need right now\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"\", \"parsed\": {\"term\": \"KL divergence, mutual information, and entropy are very powerful, but they are more advanced than what we need right now\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide10.json",
        "parsed": {
          "s": "mutual information",
          "p": "measures",
          "o": "how much uncertainty about Y is reduced when you know X",
          "modalities": [
            "text"
          ],
          "confidence": 0.95,
          "evidence": [
            "mutual information measures how much uncertainty about Y is reduced when you know X."
          ]
        },
        "raw": "{\"slide_id\": \"Slide10\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:11:37.455539+00:00\", \"text_length\": 1730, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nMutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\n\\nSo, what is entropy in this context? Think of it as a measure of uncertainty. If you have a probability distribution that is very spread out and uniform, then you have a lot of uncertainty — you don’t really know what the outcome will be. That means the entropy is high.\\nOn the other hand, if the distribution is sharply peaked — like a delta function, where one outcome is guaranteed — then there is no uncertainty. In that case, the entropy is very low, even zero.\\n\\nSo entropy tells us how much information, or how much unpredictability, is contained in a random variable. In information theory, this is a central concept because information itself is really about reducing uncertainty.\\nNow, mutual information can be written as the difference between two entropies: the entropy of Y by itself, minus the entropy of Y given X. In other words, it measures how much uncertainty about Y is reduced when you know X. That’s exactly what we mean by “how much does X tell us about Y.”\\nAgain, you don’t need to get bogged down in the formulas here. The key point is: entropy captures uncertainty, and mutual information measures how two variables share or reduce that uncertainty.\\n\\nFor our purposes, I just want you to know that these information-theoretic measures — KL divergence, mutual information, and entropy — are very powerful, but they are more advanced than what we need right now. Think of them as tools in the background, which complement the simpler measures like mean squared error.\\n\\nAnd with that, we will soon return to the more practical measures that are directly used in image quality assessment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"mutual information\\\",\\n      \\\"p\\\": \\\"depends_on\\\",\\n      \\\"o\\\": \\\"entropy\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Mutual information, which we just discussed, is actually defined in terms of another very fundamental concept: entropy.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"entropy\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"uncertainty\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"entropy tells us how much information, or how much unpredictability, is contained in a random variable.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"mutual information\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"how much uncertainty about Y is reduced when you know X\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"mutual information measures how much uncertainty about Y is reduced when you know X.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"mutual information\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"H(Y\", \"parsed\": {\"s\": \"mutual information\", \"p\": \"measures\", \"o\": \"how much uncertainty about Y is reduced when you know X\", \"modalities\": [\"text\"], \"confidence\": 0.95, \"evidence\": [\"mutual information measures how much uncertainty about Y is reduced when you know X.\"]}}"
      }
    }
  }
}