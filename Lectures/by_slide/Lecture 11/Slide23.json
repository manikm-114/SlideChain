{
  "lecture": "Lecture 11",
  "slide_id": "Slide23",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide23.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide23.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide23.json",
        "parsed": {
          "term": "similarity",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe third and final component of SSIM is the structural comparison.\\n\\nHere’s the idea. Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\nMathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\n\\nAnother way to think about this is in terms of vectors in high-dimensional space. Imagine each image as a vector, with each pixel value being one coordinate. The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths. Geometrically, this is just the cosine of the angle between the two vectors.\\n\\nIf the two vectors point in exactly the same direction — meaning the images are identical up to scaling — the angle is zero, and the similarity is maximized.\\nIf they are completely uncorrelated, the inner product is small, and the similarity is low.\\nThis is the same intuition we used when studying Fourier analysis: a Fourier coefficient is computed by projecting a signal onto a basis function. Here, we are projecting one image onto another and measuring how well they align.\\n\\nSo, structural comparison boils down to asking: once brightness and contrast are accounted for, do the fine details and patterns of the two images still match?\\nThat completes the three pillars of SSIM: luminance, contrast, and structure. Next, we’ll see how they combine into the full similarity measure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"structure\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"cross-correlation\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"cross-correlation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier analysis\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Fourier coefficient\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"inner product\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"cosine of the angle\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"high-dimensional space\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"vectors\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"alignment\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"similarity\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"The third and final component of SSIM is the structural comparison.\\\", \\n               \\\"Once we normalize each image —\", \"parsed\": {\"term\": \"similarity\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide23.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe third and final component of SSIM is the structural comparison.\\n\\nHere’s the idea. Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\nMathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\n\\nAnother way to think about this is in terms of vectors in high-dimensional space. Imagine each image as a vector, with each pixel value being one coordinate. The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths. Geometrically, this is just the cosine of the angle between the two vectors.\\n\\nIf the two vectors point in exactly the same direction — meaning the images are identical up to scaling — the angle is zero, and the similarity is maximized.\\nIf they are completely uncorrelated, the inner product is small, and the similarity is low.\\nThis is the same intuition we used when studying Fourier analysis: a Fourier coefficient is computed by projecting a signal onto a basis function. Here, we are projecting one image onto another and measuring how well they align.\\n\\nSo, structural comparison boils down to asking: once brightness and contrast are accounted for, do the fine details and patterns of the two images still match?\\nThat completes the three pillars of SSIM: luminance, contrast, and structure. Next, we’ll see how they combine into the full similarity measure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"structural comparison\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align? Mathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide23.json",
        "parsed": {
          "term": "vectors",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"structural comparison\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"cross-correlation\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"inner product\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"cosine of the angle\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier analysis\\\", \\\"category\\\": \\\"frequency_domain\\\"},\\n    {\\\"term\\\": \\\"projection\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"similarity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"vectors\\\", \\\"category\\\": \\\"mathematics\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"the structural similarity is then like taking the inner product of these two vectors\\\",\\n    \\\"Mathematically, this is captured using the cross-correlation between the two images\\\",\\n    \\\"This is the same intuition we used when studying Fourier analysis\\\",\\n    \\\"structural comparison boils down to asking: once brightness and contrast are accounted for\\\",\\n    \\\"That completes\", \"parsed\": {\"term\": \"vectors\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide23.json",
        "parsed": {
          "triples": [
            {
              "s": "structural comparison",
              "p": "uses",
              "o": "cross-correlation",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "Mathematically, this is captured using the cross-correlation between the two images."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"structural comparison\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"cross-correlation\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Mathematically, this is captured using the cross-correlation between the two images.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"structural similarity\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"inner product of two vectors\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"structural comparison\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"alignment of patterns, textures, and shapes\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"do the patterns, textures, and shapes in the two images align?\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"structural comparison\", \"p\": \"uses\", \"o\": \"cross-correlation\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"Mathematically, this is captured using the cross-correlation between the two images.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide23.json",
        "parsed": {
          "term": "full similarity measure",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:59:08.287815+00:00\", \"text_length\": 1735, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe third and final component of SSIM is the structural comparison.\\n\\nHere’s the idea. Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\nMathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\n\\nAnother way to think about this is in terms of vectors in high-dimensional space. Imagine each image as a vector, with each pixel value being one coordinate. The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths. Geometrically, this is just the cosine of the angle between the two vectors.\\n\\nIf the two vectors point in exactly the same direction — meaning the images are identical up to scaling — the angle is zero, and the similarity is maximized.\\nIf they are completely uncorrelated, the inner product is small, and the similarity is low.\\nThis is the same intuition we used when studying Fourier analysis: a Fourier coefficient is computed by projecting a signal onto a basis function. Here, we are projecting one image onto another and measuring how well they align.\\n\\nSo, structural comparison boils down to asking: once brightness and contrast are accounted for, do the fine details and patterns of the two images still match?\\nThat completes the three pillars of SSIM: luminance, contrast, and structure. Next, we’ll see how they combine into the full similarity measure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"structural comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"cross-correlation\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"sigma-X-Y\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"inner product\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"cosine of the angle\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"vectors in high-dimensional space\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Fourier analysis\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"alignment\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Fourier coefficient\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"basis function\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"alignment\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"full similarity measure\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Once we normalize each\", \"parsed\": {\"term\": \"full similarity measure\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide23.json",
        "parsed": {
          "triples": [
            {
              "s": "sigma-X-Y",
              "p": "measures",
              "o": "structural similarity",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "The cross-correlation between the two images, which measures how the variations in image X line up with the variations in image Y."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:33:34.716605+00:00\", \"text_length\": 1735, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe third and final component of SSIM is the structural comparison.\\n\\nHere’s the idea. Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\nMathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\n\\nAnother way to think about this is in terms of vectors in high-dimensional space. Imagine each image as a vector, with each pixel value being one coordinate. The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths. Geometrically, this is just the cosine of the angle between the two vectors.\\n\\nIf the two vectors point in exactly the same direction — meaning the images are identical up to scaling — the angle is zero, and the similarity is maximized.\\nIf they are completely uncorrelated, the inner product is small, and the similarity is low.\\nThis is the same intuition we used when studying Fourier analysis: a Fourier coefficient is computed by projecting a signal onto a basis function. Here, we are projecting one image onto another and measuring how well they align.\\n\\nSo, structural comparison boils down to asking: once brightness and contrast are accounted for, do the fine details and patterns of the two images still match?\\nThat completes the three pillars of SSIM: luminance, contrast, and structure. Next, we’ll see how they combine into the full similarity measure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"sigma-X-Y\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"structural similarity\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The cross-correlation between the two images, which measures how the variations in image X line up with the variations in image Y.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"sigma-X-Y\", \"p\": \"measures\", \"o\": \"structural similarity\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"The cross-correlation between the two images, which measures how the variations in image X line up with the variations in image Y.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide23.json",
        "parsed": {
          "term": "luminance, contrast, and structure",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:03:37.751675+00:00\", \"text_length\": 1735, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe third and final component of SSIM is the structural comparison.\\n\\nHere’s the idea. Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\nMathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\n\\nAnother way to think about this is in terms of vectors in high-dimensional space. Imagine each image as a vector, with each pixel value being one coordinate. The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths. Geometrically, this is just the cosine of the angle between the two vectors.\\n\\nIf the two vectors point in exactly the same direction — meaning the images are identical up to scaling — the angle is zero, and the similarity is maximized.\\nIf they are completely uncorrelated, the inner product is small, and the similarity is low.\\nThis is the same intuition we used when studying Fourier analysis: a Fourier coefficient is computed by projecting a signal onto a basis function. Here, we are projecting one image onto another and measuring how well they align.\\n\\nSo, structural comparison boils down to asking: once brightness and contrast are accounted for, do the fine details and patterns of the two images still match?\\nThat completes the three pillars of SSIM: luminance, contrast, and structure. Next, we’ll see how they combine into the full similarity measure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"structural comparison\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"luminance subtraction\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"variance normalization\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"cross-correlation\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"sigma-x-y\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"inner product\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"cosine of the angle between the two vectors\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"projecting one image onto another\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Fourier analysis\\\",\\n      \\\"category\\\": \\\"frequency_domain\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"SSIM\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"luminance, contrast, and structure\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    }\\n  ],\\n  \\\"evidence\", \"parsed\": {\"term\": \"luminance, contrast, and structure\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide23.json",
        "parsed": {
          "s": "structural comparison",
          "p": "uses",
          "o": "cross-correlation between the two images",
          "modalities": [
            "text"
          ],
          "confidence": 0.95,
          "evidence": [
            "Mathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y."
          ]
        },
        "raw": "{\"slide_id\": \"Slide23\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:13:06.914839+00:00\", \"text_length\": 1735, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe third and final component of SSIM is the structural comparison.\\n\\nHere’s the idea. Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\nMathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y. To make the measure stable, we again introduce a constant, just like we did with luminance and contrast.\\n\\nAnother way to think about this is in terms of vectors in high-dimensional space. Imagine each image as a vector, with each pixel value being one coordinate. The structural similarity is then like taking the inner product of these two vectors, normalized by their lengths. Geometrically, this is just the cosine of the angle between the two vectors.\\n\\nIf the two vectors point in exactly the same direction — meaning the images are identical up to scaling — the angle is zero, and the similarity is maximized.\\nIf they are completely uncorrelated, the inner product is small, and the similarity is low.\\nThis is the same intuition we used when studying Fourier analysis: a Fourier coefficient is computed by projecting a signal onto a basis function. Here, we are projecting one image onto another and measuring how well they align.\\n\\nSo, structural comparison boils down to asking: once brightness and contrast are accounted for, do the fine details and patterns of the two images still match?\\nThat completes the three pillars of SSIM: luminance, contrast, and structure. Next, we’ll see how they combine into the full similarity measure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"structural comparison\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"alignment of patterns, textures, and shapes\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Once we normalize each image — removing its mean brightness and adjusting its contrast — what’s left is essentially its structure. This is where we ask: do the patterns, textures, and shapes in the two images align?\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"structural comparison\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"cross-correlation between the two images\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Mathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"structural comparison\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"inner product of two unit vectors\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\", \"parsed\": {\"s\": \"structural comparison\", \"p\": \"uses\", \"o\": \"cross-correlation between the two images\", \"modalities\": [\"text\"], \"confidence\": 0.95, \"evidence\": [\"Mathematically, this is captured using the cross-correlation between the two images. We call it sigma-X-Y, which measures how the variations in image X line up with the variations in image Y.\"]}}"
      }
    }
  }
}