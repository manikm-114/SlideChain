{
  "lecture": "Lecture 11",
  "slide_id": "Slide16",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide16.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide16.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide16.json",
        "parsed": {
          "concepts": [
            {
              "term": "mean",
              "category": "mathematics"
            },
            {
              "term": "standard deviation",
              "category": "mathematics"
            },
            {
              "term": "normalization",
              "category": "signal_processing"
            },
            {
              "term": "Structural Similarity Index",
              "category": "quality_metric"
            },
            {
              "term": "luminance",
              "category": "signal_processing"
            },
            {
              "term": "contrast",
              "category": "signal_processing"
            },
            {
              "term": "structure",
              "category": "signal_processing"
            }
          ],
          "evidence": [
            "As I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure - or L, C, and S for short.",
            "Once we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics - it gives us an unbiased estimate of the standard deviation."
          ]
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAs I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\n\\nLet’s start with luminance. Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\nNext, we remove the mean by subtracting the mean of X from every pixel. This is the first step of normalization — it centers the image so that the average brightness is zero.\\n\\nOnce we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\nFinally, we can normalize the image even further by dividing each pixel by the standard deviation. After this second step of normalization, the transformed image will have a mean of zero and a standard deviation of one. In other words, it has been rescaled so that brightness and contrast are standardized.\\nWe repeat this process for both images, X and Y. Only then do we compare them — first in terms of luminance, then contrast, and finally their structural relationship.\\n\\nSo, these are the basic operations behind SSIM. They are simple statistical tools, but together they allow us to capture how similar two images are in terms of brightness, contrast, and structure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"mean\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"normalization\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Structural Similarity Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structure\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"As I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\\", \\\"Once we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"mean\", \"category\": \"mathematics\"}, {\"term\": \"standard deviation\", \"category\": \"mathematics\"}, {\"term\": \"normalization\", \"category\": \"signal_processing\"}, {\"term\": \"Structural Similarity Index\", \"category\": \"quality_metric\"}, {\"term\": \"luminance\", \"category\": \"signal_processing\"}, {\"term\": \"contrast\", \"category\": \"signal_processing\"}, {\"term\": \"structure\", \"category\": \"signal_processing\"}], \"evidence\": [\"As I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure - or L, C, and S for short.\", \"Once we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics - it gives us an unbiased estimate of the standard deviation.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide16.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAs I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\n\\nLet’s start with luminance. Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\nNext, we remove the mean by subtracting the mean of X from every pixel. This is the first step of normalization — it centers the image so that the average brightness is zero.\\n\\nOnce we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\nFinally, we can normalize the image even further by dividing each pixel by the standard deviation. After this second step of normalization, the transformed image will have a mean of zero and a standard deviation of one. In other words, it has been rescaled so that brightness and contrast are standardized.\\nWe repeat this process for both images, X and Y. Only then do we compare them — first in terms of luminance, then contrast, and finally their structural relationship.\\n\\nSo, these are the basic operations behind SSIM. They are simple statistical tools, but together they allow us to capture how similar two images are in terms of brightness, contrast, and structure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Structural Similarity Index\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"image\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"built on three components: luminance, contrast, and structure — or L, C, and S for short.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide16.json",
        "parsed": {
          "term": "structural relationship",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structure\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"mean\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"normalization\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"Structural Similarity Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"average brightness\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pixel values\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"brightness\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural relationship\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"built on three components: luminance, contrast, and structure\\\",\\n    \\\"average brightness, or mean\\\",\\n    \\\"standard deviation\\\",\\n    \\\"normalization\\\",\\n    \\\"Structural Similarity Index\\\",\\n    \\\"average brightness\\\",\\n    \\\"pixel values\\\",\\n    \\\"brightness\\\",\\n    \\\"contrast\\\",\\n    \\\"structural\", \"parsed\": {\"term\": \"structural relationship\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide16.json",
        "parsed": {
          "s": "mean value",
          "p": "measures",
          "o": "average brightness",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value"
          ]
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Structural Similarity Index\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"luminance\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"the Structural Similarity Index is built on three components: luminance, contrast, and structure\\\"},\\n    {\\\"s\\\":\\\"Structural Similarity Index\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"contrast\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"the Structural Similarity Index is built on three components: luminance, contrast, and structure\\\"},\\n    {\\\"s\\\":\\\"Structural Similarity Index\\\", \\\"p\\\":\\\"uses\\\", \\\"o\\\":\\\"structure\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"the Structural Similarity Index is built on three components: luminance, contrast, and structure\\\"},\\n    {\\\"s\\\":\\\"mean value\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"average brightness\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value\\\"},\\n    {\\\"s\\\":\\\"standard deviation\\\", \\\"p\\\":\\\"measures\\\", \\\"\", \"parsed\": {\"s\": \"mean value\", \"p\": \"measures\", \"o\": \"average brightness\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide16.json",
        "parsed": {
          "term": "structural relationship",
          "category": "signal_processing"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:47:27.219632+00:00\", \"text_length\": 1503, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAs I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\n\\nLet’s start with luminance. Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\nNext, we remove the mean by subtracting the mean of X from every pixel. This is the first step of normalization — it centers the image so that the average brightness is zero.\\n\\nOnce we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\nFinally, we can normalize the image even further by dividing each pixel by the standard deviation. After this second step of normalization, the transformed image will have a mean of zero and a standard deviation of one. In other words, it has been rescaled so that brightness and contrast are standardized.\\nWe repeat this process for both images, X and Y. Only then do we compare them — first in terms of luminance, then contrast, and finally their structural relationship.\\n\\nSo, these are the basic operations behind SSIM. They are simple statistical tools, but together they allow us to capture how similar two images are in terms of brightness, contrast, and structure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Structural Similarity Index\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structure\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"mean\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"normalization\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"statistics\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"brightness\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural relationship\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"The Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\\",\\n    \\\"To find its average brightness, or mean, we simply add up all the pixel values and divide by N.\\\",\\n    \\\"This gives us the mean value, which we call mu of X.\\\",\\n    \\\"We remove the mean by\", \"parsed\": {\"term\": \"structural relationship\", \"category\": \"signal_processing\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide16.json",
        "parsed": {
          "triples": [
            {
              "s": "mean of X",
              "p": "measures",
              "o": "average brightness",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:29:08.767178+00:00\", \"text_length\": 1503, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAs I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\n\\nLet’s start with luminance. Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\nNext, we remove the mean by subtracting the mean of X from every pixel. This is the first step of normalization — it centers the image so that the average brightness is zero.\\n\\nOnce we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\nFinally, we can normalize the image even further by dividing each pixel by the standard deviation. After this second step of normalization, the transformed image will have a mean of zero and a standard deviation of one. In other words, it has been rescaled so that brightness and contrast are standardized.\\nWe repeat this process for both images, X and Y. Only then do we compare them — first in terms of luminance, then contrast, and finally their structural relationship.\\n\\nSo, these are the basic operations behind SSIM. They are simple statistical tools, but together they allow us to capture how similar two images are in terms of brightness, contrast, and structure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"mean of X\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"average brightness\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"mean of X\", \"p\": \"measures\", \"o\": \"average brightness\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide16.json",
        "parsed": {
          "term": "unbiased estimate",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:02:33.177530+00:00\", \"text_length\": 1503, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nAs I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\n\\nLet’s start with luminance. Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\nNext, we remove the mean by subtracting the mean of X from every pixel. This is the first step of normalization — it centers the image so that the average brightness is zero.\\n\\nOnce we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\nFinally, we can normalize the image even further by dividing each pixel by the standard deviation. After this second step of normalization, the transformed image will have a mean of zero and a standard deviation of one. In other words, it has been rescaled so that brightness and contrast are standardized.\\nWe repeat this process for both images, X and Y. Only then do we compare them — first in terms of luminance, then contrast, and finally their structural relationship.\\n\\nSo, these are the basic operations behind SSIM. They are simple statistical tools, but together they allow us to capture how similar two images are in terms of brightness, contrast, and structure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"structural similarity index\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"luminance\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"contrast\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"structure\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"mean\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"standard deviation\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"normalize\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"rescale\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"pixel values\\\",\\n      \\\"category\\\": \\\"data_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"unbiased estimate\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"As I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\\",\\n    \\\"To find its average brightness\", \"parsed\": {\"term\": \"unbiased estimate\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide16.json",
        "parsed": {
          "s": "σₓ",
          "p": "measures",
          "o": "standard deviation of X",
          "modalities": [
            "text"
          ],
          "confidence": 0.95,
          "evidence": [
            "σₓ = (1/(N-1) Σ (xᵢ - μₓ)²)^(1/2)"
          ]
        },
        "raw": "{\"slide_id\": \"Slide16\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:12:18.910622+00:00\", \"text_length\": 1503, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nAs I mentioned, the Structural Similarity Index is built on three components: luminance, contrast, and structure — or L, C, and S for short.\\n\\nLet’s start with luminance. Suppose we have an image X with N pixels. To find its average brightness, or mean, we simply add up all the pixel values and divide by N. This gives us the mean value, which we call mu of X.\\nNext, we remove the mean by subtracting the mean of X from every pixel. This is the first step of normalization — it centers the image so that the average brightness is zero.\\n\\nOnce we have the mean, we can also compute the standard deviation. This measures how much the pixel values vary around the mean. Notice that the formula here uses 1 divided by N minus 1, not just N. That detail comes from statistics — it gives us an unbiased estimate of the standard deviation.\\nFinally, we can normalize the image even further by dividing each pixel by the standard deviation. After this second step of normalization, the transformed image will have a mean of zero and a standard deviation of one. In other words, it has been rescaled so that brightness and contrast are standardized.\\nWe repeat this process for both images, X and Y. Only then do we compare them — first in terms of luminance, then contrast, and finally their structural relationship.\\n\\nSo, these are the basic operations behind SSIM. They are simple statistical tools, but together they allow us to capture how similar two images are in terms of brightness, contrast, and structure.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"S(x, y)\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"f(l(x, y), c(x, y), s(x, y))\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"S(x, y) = f(l(x, y), c(x, y), s(x, y))\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"μₓ\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"mean of X\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"μₓ = 1/N Σ xᵢ\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"σₓ\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"standard deviation of X\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"σₓ = (1/(N-1) Σ (xᵢ - μₓ)²)^(1/2)\\\"\\n    },\", \"parsed\": {\"s\": \"σₓ\", \"p\": \"measures\", \"o\": \"standard deviation of X\", \"modalities\": [\"text\"], \"confidence\": 0.95, \"evidence\": [\"σₓ = (1/(N-1) Σ (xᵢ - μₓ)²)^(1/2)\"]}}"
      }
    }
  }
}