{
  "lecture": "Lecture 11",
  "slide_id": "Slide13",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide13.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide13.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide13.json",
        "parsed": {
          "concepts": [
            {
              "term": "image quality assessment",
              "category": "quality_metric"
            },
            {
              "term": "structural similarity",
              "category": "quality_metric"
            },
            {
              "term": "perceptual image quality",
              "category": "quality_metric"
            },
            {
              "term": "mean squared error",
              "category": "signal_processing"
            },
            {
              "term": "pixel by pixel",
              "category": "signal_processing"
            },
            {
              "term": "image processing research",
              "category": "software"
            },
            {
              "term": "video compression",
              "category": "software"
            },
            {
              "term": "image restoration",
              "category": "software"
            },
            {
              "term": "medical imaging",
              "category": "modality"
            }
          ],
          "evidence": [
            "This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.",
            "The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging."
          ]
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere we arrive at what I like to call an instant classic. This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\n\\nBefore this work, most image quality measures focused on error visibility — essentially counting differences pixel by pixel, the way mean squared error does. What this paper introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity.\\nThe idea is built on the assumption that the human visual system is highly tuned to extract structural information from images. So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\n\\nThis shift in thinking turned out to be incredibly powerful. The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\nSo, from this point forward, when we talk about perceptual image quality, we are really building on the foundation laid by this work.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"image quality assessment\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"perceptual image quality\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"pixel by pixel\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"image processing research\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"video compression\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"image restoration\\\", \\\"category\\\": \\\"software\\\"},\\n    {\\\"term\\\": \\\"medical imaging\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\\", \\\"The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"image quality assessment\", \"category\": \"quality_metric\"}, {\"term\": \"structural similarity\", \"category\": \"quality_metric\"}, {\"term\": \"perceptual image quality\", \"category\": \"quality_metric\"}, {\"term\": \"mean squared error\", \"category\": \"signal_processing\"}, {\"term\": \"pixel by pixel\", \"category\": \"signal_processing\"}, {\"term\": \"image processing research\", \"category\": \"software\"}, {\"term\": \"video compression\", \"category\": \"software\"}, {\"term\": \"image restoration\", \"category\": \"software\"}, {\"term\": \"medical imaging\", \"category\": \"modality\"}], \"evidence\": [\"This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\", \"The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide13.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere we arrive at what I like to call an instant classic. This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\n\\nBefore this work, most image quality measures focused on error visibility — essentially counting differences pixel by pixel, the way mean squared error does. What this paper introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity.\\nThe idea is built on the assumption that the human visual system is highly tuned to extract structural information from images. So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\n\\nThis shift in thinking turned out to be incredibly powerful. The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\nSo, from this point forward, when we talk about perceptual image quality, we are really building on the foundation laid by this work.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Image Quality Assessment\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"Structural Similarity\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide13.json",
        "parsed": {
          "term": "medical imaging",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"error visibility\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"human visual system\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"SSIM framework\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"image quality measures\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"image processing research\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"video compression\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"image restoration\\\", \\\"category\\\": \\\"data_processing\\\"},\\n    {\\\"term\\\": \\\"medical imaging\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"most image quality measures focused on error visibility\\\",\\n    \\\"introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity\\\",\\n    \\\"built on the assumption that the human visual system is highly tuned to extract structural information from images\\\",\\n    \\\"SSIM framework\\\",\\n    \\\"image quality measures\\\",\\n    \\\"mean squared error\\\",\\n    \\\"image processing research\\\",\\n    \\\"practical applications like video compression\", \"parsed\": {\"term\": \"medical imaging\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide13.json",
        "parsed": {
          "triples": [
            {
              "s": "Image Quality Assessment: From Error Visibility to Structural Similarity",
              "p": "measures",
              "o": "structural similarity",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Image Quality Assessment: From Error Visibility to Structural Similarity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"structural similarity\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity.\\\"},\\n    {\\\"s\\\":\\\"SSIM framework\\\", \\\"p\\\":\\\"asks\\\", \\\"o\\\":\\\"How well is the structure of the image preserved?\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\\"},\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"became\\\", \\\"o\\\":\\\"standard tool\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"Image Quality Assessment: From Error Visibility to Structural Similarity\", \"p\": \"measures\", \"o\": \"structural similarity\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity.\"}]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide13.json",
        "parsed": {
          "concepts": [
            {
              "term": "Image Quality Assessment",
              "category": "quality_metric"
            },
            {
              "term": "Human Visual System",
              "category": "signal_processing"
            },
            {
              "term": "Mean Squared Error",
              "category": "signal_processing"
            },
            {
              "term": "Video Compression",
              "category": "communication"
            },
            {
              "term": "Image Restoration",
              "category": "signal_processing"
            },
            {
              "term": "Medical Imaging",
              "category": "modality"
            }
          ],
          "evidence": [
            "This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity.",
            "The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging."
          ]
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:41:46.284943+00:00\", \"text_length\": 1212, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere we arrive at what I like to call an instant classic. This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\n\\nBefore this work, most image quality measures focused on error visibility — essentially counting differences pixel by pixel, the way mean squared error does. What this paper introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity.\\nThe idea is built on the assumption that the human visual system is highly tuned to extract structural information from images. So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\n\\nThis shift in thinking turned out to be incredibly powerful. The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\nSo, from this point forward, when we talk about perceptual image quality, we are really building on the foundation laid by this work.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Image Quality Assessment\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Structural Similarity Index (SSIM)\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Human Visual System\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Mean Squared Error\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Video Compression\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"Image Restoration\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Medical Imaging\\\", \\\"category\\\": \\\"modality\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity.\\\",\\n    \\\"The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"Image Quality Assessment\", \"category\": \"quality_metric\"}, {\"term\": \"Human Visual System\", \"category\": \"signal_processing\"}, {\"term\": \"Mean Squared Error\", \"category\": \"signal_processing\"}, {\"term\": \"Video Compression\", \"category\": \"communication\"}, {\"term\": \"Image Restoration\", \"category\": \"signal_processing\"}, {\"term\": \"Medical Imaging\", \"category\": \"modality\"}], \"evidence\": [\"This paper introduced a completely different perspective: instead of measuring errors, we should measure structural similarity.\", \"The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide13.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:25:49.406291+00:00\", \"text_length\": 1212, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere we arrive at what I like to call an instant classic. This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\n\\nBefore this work, most image quality measures focused on error visibility — essentially counting differences pixel by pixel, the way mean squared error does. What this paper introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity.\\nThe idea is built on the assumption that the human visual system is highly tuned to extract structural information from images. So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\n\\nThis shift in thinking turned out to be incredibly powerful. The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\nSo, from this point forward, when we talk about perceptual image quality, we are really building on the foundation laid by this work.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide13.json",
        "parsed": {
          "term": "medical imaging",
          "category": "modality"
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:02:02.230131+00:00\", \"text_length\": 1212, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere we arrive at what I like to call an instant classic. This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\n\\nBefore this work, most image quality measures focused on error visibility — essentially counting differences pixel by pixel, the way mean squared error does. What this paper introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity.\\nThe idea is built on the assumption that the human visual system is highly tuned to extract structural information from images. So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\n\\nThis shift in thinking turned out to be incredibly powerful. The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\nSo, from this point forward, when we talk about perceptual image quality, we are really building on the foundation laid by this work.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"instant classic\\\",\\n      \\\"category\\\": \\\"software\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Image Quality Assessment: From Error Visibility to Structural Similarity\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"error visibility\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"structural similarity\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"human visual system\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"structural information\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"SSIM framework\\\",\\n      \\\"category\\\": \\\"algorithm\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"perceptual image quality\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"video compression\\\",\\n      \\\"category\\\": \\\"communication\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"image restoration\\\",\\n      \\\"category\\\": \\\"reconstruction\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"medical imaging\\\",\\n      \\\"category\\\": \\\"modality\\\"\\n    }\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"This is the landmark 200\", \"parsed\": {\"term\": \"medical imaging\", \"category\": \"modality\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide13.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide13\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:11:47.781153+00:00\", \"text_length\": 1212, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere we arrive at what I like to call an instant classic. This is the landmark 2004 paper by Zhou Wang, Alan Bovik, Hamid Sheikh, and Eero Simoncelli, titled Image Quality Assessment: From Error Visibility to Structural Similarity.\\n\\nBefore this work, most image quality measures focused on error visibility — essentially counting differences pixel by pixel, the way mean squared error does. What this paper introduced was a completely different perspective: instead of measuring errors, we should measure structural similarity.\\nThe idea is built on the assumption that the human visual system is highly tuned to extract structural information from images. So rather than asking, “How many errors can we see?”, the SSIM framework asks, “How well is the structure of the image preserved?”\\n\\nThis shift in thinking turned out to be incredibly powerful. The paper has been cited tens of thousands of times, and SSIM quickly became a standard tool not only in image processing research but also in practical applications like video compression, image restoration, and medical imaging.\\nSo, from this point forward, when we talk about perceptual image quality, we are really building on the foundation laid by this work.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": []\\n}\", \"parsed\": {\"triples\": []}}"
      }
    }
  }
}