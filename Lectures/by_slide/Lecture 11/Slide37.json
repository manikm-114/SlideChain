{
  "lecture": "Lecture 11",
  "slide_id": "Slide37",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide37.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide37.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide37.json",
        "parsed": {
          "concepts": [
            {
              "term": "sensitivity",
              "category": "quality_metric"
            },
            {
              "term": "specificity",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN.",
            "Specificity is the proportion of true negatives among all actual negative cases. The formula is: Specificity equals TN over TN plus FP."
          ]
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow that we’ve defined the four possible outcomes — true positives, true negatives, false positives, and false negatives — we can formally define sensitivity and specificity.\\n\\nSensitivity is the proportion of true positives among all actual positive cases. In formula form, it is:\\nSensitivity equals TP over TP plus FN.\\n\\nIn other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\nFor example, suppose 100 patients truly have lung cancer. If our system correctly detects 50 of them, but misses the other 50, then the sensitivity is 50%. Sensitivity is essentially a measure of how confident we are when we say “Yes, disease is present.”\\nNow let’s move to specificity.\\nSpecificity is the proportion of true negatives among all actual negative cases. The formula is:\\nSpecificity equals TN over TN plus FP.\\n\\nThis answers the question: “If the patient really does not have the disease, how likely are we to correctly say no?”\\nFor example, if 100 healthy people are scanned, and 95 are correctly reported as negative while 5 are mistakenly labeled as positive, the specificity is 95%. Specificity is essentially a measure of how confident we are when we say “No, there is no disease.”\\n\\nSo, in summary:\\nSensitivity tells us how good we are at catching disease cases.\\nSpecificity tells us how good we are at avoiding false alarms.\\n\\nBoth are critical in clinical imaging. High sensitivity ensures we don’t miss disease, while high specificity ensures we don’t overwhelm patients with unnecessary worry or treatment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"TP\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"FN\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"TN\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"FP\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"disease\\\", \\\"category\\\": \\\"anatomy\\\"},\\n    {\\\"term\\\": \\\"patient\\\", \\\"category\\\": \\\"anatomy\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN.\\\", \\\"Specificity is the proportion of true negatives among all actual negative cases. The formula is: Specificity equals TN over TN plus FP.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"sensitivity\", \"category\": \"quality_metric\"}, {\"term\": \"specificity\", \"category\": \"quality_metric\"}], \"evidence\": [\"Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN.\", \"Specificity is the proportion of true negatives among all actual negative cases. The formula is: Specificity equals TN over TN plus FP.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide37.json",
        "parsed": {
          "triples": [
            {
              "s": "sensitivity",
              "p": "measures",
              "o": "TP over TP plus FN",
              "modalities": [
                "text"
              ],
              "confidence": 0.0,
              "evidence": "Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN. In other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”"
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow that we’ve defined the four possible outcomes — true positives, true negatives, false positives, and false negatives — we can formally define sensitivity and specificity.\\n\\nSensitivity is the proportion of true positives among all actual positive cases. In formula form, it is:\\nSensitivity equals TP over TP plus FN.\\n\\nIn other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\nFor example, suppose 100 patients truly have lung cancer. If our system correctly detects 50 of them, but misses the other 50, then the sensitivity is 50%. Sensitivity is essentially a measure of how confident we are when we say “Yes, disease is present.”\\nNow let’s move to specificity.\\nSpecificity is the proportion of true negatives among all actual negative cases. The formula is:\\nSpecificity equals TN over TN plus FP.\\n\\nThis answers the question: “If the patient really does not have the disease, how likely are we to correctly say no?”\\nFor example, if 100 healthy people are scanned, and 95 are correctly reported as negative while 5 are mistakenly labeled as positive, the specificity is 95%. Specificity is essentially a measure of how confident we are when we say “No, there is no disease.”\\n\\nSo, in summary:\\nSensitivity tells us how good we are at catching disease cases.\\nSpecificity tells us how good we are at avoiding false alarms.\\n\\nBoth are critical in clinical imaging. High sensitivity ensures we don’t miss disease, while high specificity ensures we don’t overwhelm patients with unnecessary worry or treatment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"sensitivity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"TP over TP plus FN\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN. In other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"sensitivity\", \"p\": \"measures\", \"o\": \"TP over TP plus FN\", \"modalities\": [\"text\"], \"confidence\": 0.0, \"evidence\": \"Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN. In other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide37.json",
        "parsed": {
          "concepts": [
            {
              "term": "Sensitivity",
              "category": "quality_metric"
            },
            {
              "term": "Specificity",
              "category": "quality_metric"
            },
            {
              "term": "true positives",
              "category": "quality_metric"
            },
            {
              "term": "true negatives",
              "category": "quality_metric"
            },
            {
              "term": "false positives",
              "category": "quality_metric"
            },
            {
              "term": "false negatives",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "Sensitivity is the proportion of true positives among all actual positive cases.",
            "Specificity is the proportion of true negatives among all actual negative cases.",
            "Sensitivity equals TP over TP plus FN.",
            "Specificity equals TN over TN plus FP.",
            "Sensitivity tells us how good we are at catching disease cases.",
            "Specificity tells us how good we are at avoiding false alarms."
          ]
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"true positives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"true negatives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"false positives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"false negatives\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"TP\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"FN\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"TN\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"FP\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Sensitivity is the proportion of true positives among all actual positive cases.\\\",\\n    \\\"Specificity is the proportion of true negatives among all actual negative cases.\\\",\\n    \\\"Sensitivity equals TP over TP plus FN.\\\",\\n    \\\"Specificity equals TN over TN plus FP.\\\",\\n    \\\"Sensitivity tells us how good we are at catching disease cases.\\\",\\n    \\\"Specificity tells us how good we are at avoiding false alarms.\\\"\\n  ]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"Sensitivity\", \"category\": \"quality_metric\"}, {\"term\": \"Specificity\", \"category\": \"quality_metric\"}, {\"term\": \"true positives\", \"category\": \"quality_metric\"}, {\"term\": \"true negatives\", \"category\": \"quality_metric\"}, {\"term\": \"false positives\", \"category\": \"quality_metric\"}, {\"term\": \"false negatives\", \"category\": \"quality_metric\"}], \"evidence\": [\"Sensitivity is the proportion of true positives among all actual positive cases.\", \"Specificity is the proportion of true negatives among all actual negative cases.\", \"Sensitivity equals TP over TP plus FN.\", \"Specificity equals TN over TN plus FP.\", \"Sensitivity tells us how good we are at catching disease cases.\", \"Specificity tells us how good we are at avoiding false alarms.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide37.json",
        "parsed": {
          "s": "Specificity",
          "p": "measures",
          "o": "likelihood of a negative case",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "Specificity is the proportion of true negatives among all actual negative cases."
          ]
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Sensitivity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"likelihood of a positive case\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Sensitivity is the proportion of true positives among all actual positive cases.\\\"},\\n    {\\\"s\\\":\\\"Sensitivity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"% of edges we find\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Sensitivity equals TP over TP plus FN.\\\"},\\n    {\\\"s\\\":\\\"Sensitivity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"how sure we say YES\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Sensitivity is essentially a measure of how confident we are when we say 'Yes, disease is present.'\\\"},\\n    {\\\"s\\\":\\\"Specificity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"likelihood of a negative case\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Specificity is the proportion of true negatives among all actual negative cases.\\\"},\\n    {\\\"s\\\":\\\"Specificity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"% of non-edges we find\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1\", \"parsed\": {\"s\": \"Specificity\", \"p\": \"measures\", \"o\": \"likelihood of a negative case\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"Specificity is the proportion of true negatives among all actual negative cases.\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide37.json",
        "parsed": {
          "term": "High specificity ensures we don't overwhelm patients with unnecessary worry or treatment",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T04:24:13.591402+00:00\", \"text_length\": 1570, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow that we’ve defined the four possible outcomes — true positives, true negatives, false positives, and false negatives — we can formally define sensitivity and specificity.\\n\\nSensitivity is the proportion of true positives among all actual positive cases. In formula form, it is:\\nSensitivity equals TP over TP plus FN.\\n\\nIn other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\nFor example, suppose 100 patients truly have lung cancer. If our system correctly detects 50 of them, but misses the other 50, then the sensitivity is 50%. Sensitivity is essentially a measure of how confident we are when we say “Yes, disease is present.”\\nNow let’s move to specificity.\\nSpecificity is the proportion of true negatives among all actual negative cases. The formula is:\\nSpecificity equals TN over TN plus FP.\\n\\nThis answers the question: “If the patient really does not have the disease, how likely are we to correctly say no?”\\nFor example, if 100 healthy people are scanned, and 95 are correctly reported as negative while 5 are mistakenly labeled as positive, the specificity is 95%. Specificity is essentially a measure of how confident we are when we say “No, there is no disease.”\\n\\nSo, in summary:\\nSensitivity tells us how good we are at catching disease cases.\\nSpecificity tells us how good we are at avoiding false alarms.\\n\\nBoth are critical in clinical imaging. High sensitivity ensures we don’t miss disease, while high specificity ensures we don’t overwhelm patients with unnecessary worry or treatment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"True Positives (TP)\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"False Negatives (FN)\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"True Negatives (TN)\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"False Positives (FP)\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Likelihood of a positive case\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Likelihood of a negative case\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"How sure we say YES\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"How sure we say NOPE\\\", \\\"category\\\": \\\"communication\\\"},\\n    {\\\"term\\\": \\\"High sensitivity ensures we don’t miss disease\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"High specificity ensures we don’t overwhelm patients with unnecessary worry or treatment\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Sensitivity is the proportion of true positives among all actual positive cases.\\\",\\n    \\\"Specificity is\", \"parsed\": {\"term\": \"High specificity ensures we don't overwhelm patients with unnecessary worry or treatment\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide37.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:44:01.093674+00:00\", \"text_length\": 1570, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow that we’ve defined the four possible outcomes — true positives, true negatives, false positives, and false negatives — we can formally define sensitivity and specificity.\\n\\nSensitivity is the proportion of true positives among all actual positive cases. In formula form, it is:\\nSensitivity equals TP over TP plus FN.\\n\\nIn other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\nFor example, suppose 100 patients truly have lung cancer. If our system correctly detects 50 of them, but misses the other 50, then the sensitivity is 50%. Sensitivity is essentially a measure of how confident we are when we say “Yes, disease is present.”\\nNow let’s move to specificity.\\nSpecificity is the proportion of true negatives among all actual negative cases. The formula is:\\nSpecificity equals TN over TN plus FP.\\n\\nThis answers the question: “If the patient really does not have the disease, how likely are we to correctly say no?”\\nFor example, if 100 healthy people are scanned, and 95 are correctly reported as negative while 5 are mistakenly labeled as positive, the specificity is 95%. Specificity is essentially a measure of how confident we are when we say “No, there is no disease.”\\n\\nSo, in summary:\\nSensitivity tells us how good we are at catching disease cases.\\nSpecificity tells us how good we are at avoiding false alarms.\\n\\nBoth are critical in clinical imaging. High sensitivity ensures we don’t miss disease, while high specificity ensures we don’t overwhelm patients with unnecessary worry or treatment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Sensitivity\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"TP/(TP+FN)\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Sensitivity is the proportion of true positives among all actual positive cases. In formula form, it is: Sensitivity equals TP over TP plus FN.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide37.json",
        "parsed": {
          "term": "Sensitivity tells us how good we are at catching disease cases",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:06:03.498588+00:00\", \"text_length\": 1570, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nNow that we’ve defined the four possible outcomes — true positives, true negatives, false positives, and false negatives — we can formally define sensitivity and specificity.\\n\\nSensitivity is the proportion of true positives among all actual positive cases. In formula form, it is:\\nSensitivity equals TP over TP plus FN.\\n\\nIn other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\nFor example, suppose 100 patients truly have lung cancer. If our system correctly detects 50 of them, but misses the other 50, then the sensitivity is 50%. Sensitivity is essentially a measure of how confident we are when we say “Yes, disease is present.”\\nNow let’s move to specificity.\\nSpecificity is the proportion of true negatives among all actual negative cases. The formula is:\\nSpecificity equals TN over TN plus FP.\\n\\nThis answers the question: “If the patient really does not have the disease, how likely are we to correctly say no?”\\nFor example, if 100 healthy people are scanned, and 95 are correctly reported as negative while 5 are mistakenly labeled as positive, the specificity is 95%. Specificity is essentially a measure of how confident we are when we say “No, there is no disease.”\\n\\nSo, in summary:\\nSensitivity tells us how good we are at catching disease cases.\\nSpecificity tells us how good we are at avoiding false alarms.\\n\\nBoth are critical in clinical imaging. High sensitivity ensures we don’t miss disease, while high specificity ensures we don’t overwhelm patients with unnecessary worry or treatment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"Sensitivity=TP/(TP+FN)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Sensitivity is the proportion of true positives among all actual positive cases\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Sensitivity answers the question: \\\\\\\"If the patient really has the disease, how likely are we to detect it?\\\\\\\"\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Specificity =TN/(TN+FP)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Specificity is the proportion of true negatives among all actual negative cases\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Specificity answers the question: \\\\\\\"If the patient really does not have the disease, how likely are we to correctly say no?\\\\\\\"\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Sensitivity tells us how good we are at catching disease cases\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Specificity tells us how good we are at avoiding false alarms\\\",\", \"parsed\": {\"term\": \"Sensitivity tells us how good we are at catching disease cases\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide37.json",
        "parsed": {
          "s": "Specificity =TN/(TN+FP)",
          "p": "measures",
          "o": "likelihood of a negative case",
          "modalities": [
            "text",
            "image"
          ],
          "confidence": 0.95,
          "evidence": [
            "Specificity =TN/(TN+FP) Likelihood of a negative case"
          ]
        },
        "raw": "{\"slide_id\": \"Slide37\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:14:50.985739+00:00\", \"text_length\": 1570, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nNow that we’ve defined the four possible outcomes — true positives, true negatives, false positives, and false negatives — we can formally define sensitivity and specificity.\\n\\nSensitivity is the proportion of true positives among all actual positive cases. In formula form, it is:\\nSensitivity equals TP over TP plus FN.\\n\\nIn other words, sensitivity answers the question: “If the patient really has the disease, how likely are we to detect it?”\\nFor example, suppose 100 patients truly have lung cancer. If our system correctly detects 50 of them, but misses the other 50, then the sensitivity is 50%. Sensitivity is essentially a measure of how confident we are when we say “Yes, disease is present.”\\nNow let’s move to specificity.\\nSpecificity is the proportion of true negatives among all actual negative cases. The formula is:\\nSpecificity equals TN over TN plus FP.\\n\\nThis answers the question: “If the patient really does not have the disease, how likely are we to correctly say no?”\\nFor example, if 100 healthy people are scanned, and 95 are correctly reported as negative while 5 are mistakenly labeled as positive, the specificity is 95%. Specificity is essentially a measure of how confident we are when we say “No, there is no disease.”\\n\\nSo, in summary:\\nSensitivity tells us how good we are at catching disease cases.\\nSpecificity tells us how good we are at avoiding false alarms.\\n\\nBoth are critical in clinical imaging. High sensitivity ensures we don’t miss disease, while high specificity ensures we don’t overwhelm patients with unnecessary worry or treatment.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"Sensitivity=TP/(TP+FN)\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"likelihood of a positive case\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Sensitivity=TP/(TP+FN) Likelihood of a positive case\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Specificity =TN/(TN+FP)\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"likelihood of a negative case\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Specificity =TN/(TN+FP) Likelihood of a negative case\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"Sensitivity=TP/(TP+FN)\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"how sure we say YES\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\",\\n        \\\"image\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"Sensitivity=TP/(TP+FN) How sure we\", \"parsed\": {\"s\": \"Specificity =TN/(TN+FP)\", \"p\": \"measures\", \"o\": \"likelihood of a negative case\", \"modalities\": [\"text\", \"image\"], \"confidence\": 0.95, \"evidence\": [\"Specificity =TN/(TN+FP) Likelihood of a negative case\"]}}"
      }
    }
  }
}