{
  "lecture": "Lecture 11",
  "slide_id": "Slide4",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide4.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide4.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide4.json",
        "parsed": {
          "term": "MRI scanner",
          "category": "instrumentation"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\\n\\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\n\\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\\n\\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\\n\\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\\n\\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"Euclidean distance\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"mean squared error\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"Kullback–Leibler divergence\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"noise\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"resolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"artifacts\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"spatial resolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast resolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"temporal resolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"spectral resolution\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"imaging system\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"X-ray detector\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"ultrasound probe\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"MRI scanner\\\", \\\"category\\\": \\\"instrumentation\\\"},\\n    {\\\"term\\\": \\\"bone fracture\\\", \\\"\", \"parsed\": {\"term\": \"MRI scanner\", \"category\": \"instrumentation\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide4.json",
        "parsed": {
          "triples": [
            {
              "s": "Euclidean distance",
              "p": "measures",
              "o": "MSE",
              "modalities": [
                "text"
              ],
              "confidence": 0.0,
              "evidence": "The Euclidean distance leads directly to the mean squared error, or MSE."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\\n\\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\n\\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\\n\\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\\n\\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\\n\\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"Euclidean distance\\\", \\\"p\\\":\\\"measures\\\",\\n     \\\"o\\\":\\\"MSE\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The Euclidean distance leads directly to the mean squared error, or MSE.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"Euclidean distance\", \"p\": \"measures\", \"o\": \"MSE\", \"modalities\": [\"text\"], \"confidence\": 0.0, \"evidence\": \"The Euclidean distance leads directly to the mean squared error, or MSE.\"}]}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide4.json",
        "parsed": {
          "term": "AUC",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"MSE\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"KL Distance\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Noise\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"SNR\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"CNR\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Resolution\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Spatial\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Contrast\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Temporal\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Spectral\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Artifacts\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"ROC\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"AUC\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Human Observer\\\", \\\"category\\\":\", \"parsed\": {\"term\": \"AUC\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide4.json",
        "parsed": {
          "s": "System Specific",
          "p": "measures",
          "o": "Resolution (Spatial, Contrast, Temporal, Spectral)",
          "modalities": [
            "text"
          ],
          "confidence": 1.0,
          "evidence": [
            "Resolution (Spatial, Contrast, Temporal, Spectral)"
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"```json\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"General Measures\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"MSE\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"MSE\\\"},\\n    {\\\"s\\\":\\\"General Measures\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"KL Distance\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"KL Distance\\\"},\\n    {\\\"s\\\":\\\"General Measures\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"SSIM\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"SSIM\\\"},\\n    {\\\"s\\\":\\\"System Specific\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"Noise, SNR & CNR\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Noise, SNR & CNR\\\"},\\n    {\\\"s\\\":\\\"System Specific\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"Resolution (Spatial, Contrast, Temporal, Spectral)\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"Resolution (Spatial, Contrast, Temporal, Spectral)\\\"},\\n    {\\\"s\\\":\\\"System Specific\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"Artifacts\\\", \\\"modalities\\\":[\\\"\", \"parsed\": {\"s\": \"System Specific\", \"p\": \"measures\", \"o\": \"Resolution (Spatial, Contrast, Temporal, Spectral)\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": [\"Resolution (Spatial, Contrast, Temporal, Spectral)\"]}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide4.json",
        "parsed": {
          "term": "Neural Network/Radiomics",
          "category": "algorithm"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:27:18.497948+00:00\", \"text_length\": 2705, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\\n\\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\n\\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\\n\\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\\n\\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\\n\\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"MSE\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"KL Distance\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"SSIM\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Noise\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"SNR\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"CNR\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Resolution (Spatial, Contrast, Temporal, Spectral)\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Artifacts\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"Sensitivity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Specificity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"ROC\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"AUC\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"Human Observer\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Hotelling Observer\\\", \\\"category\\\": \\\"algorithm\\\"},\\n    {\\\"term\\\": \\\"Neural Network/Radiomics\\\", \\\"category\\\": \\\"algorithm\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"Imagine you have an image\", \"parsed\": {\"term\": \"Neural Network/Radiomics\", \"category\": \"algorithm\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide4.json",
        "parsed": {
          "triples": [
            {
              "s": "MSE",
              "p": "measures",
              "o": "general measures",
              "modalities": [
                "text"
              ],
              "confidence": 1.0,
              "evidence": "The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE."
            }
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:19:04.589979+00:00\", \"text_length\": 2705, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\\n\\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\n\\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\\n\\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\\n\\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\\n\\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"MSE\\\", \\\"p\\\":\\\"measures\\\", \\\"o\\\":\\\"general measures\\\", \\\"modalities\\\":[\\\"text\\\"], \\\"confidence\\\":1.0, \\\"evidence\\\":\\\"The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": [{\"s\": \"MSE\", \"p\": \"measures\", \"o\": \"general measures\", \"modalities\": [\"text\"], \"confidence\": 1.0, \"evidence\": \"The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\"}]}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide4.json",
        "parsed": {
          "term": "Sensitivity & Specificity",
          "category": "quality_metric"
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:00:31.725726+00:00\", \"text_length\": 2705, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\\n\\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\n\\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\\n\\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\\n\\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\\n\\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"General Measures\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"MSE\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"KL Distance\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"SSIM\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"System Specific\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Noise\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"SNR & CNR\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Resolution (Spatial, Contrast, Temporal, Spectral)\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Artifacts\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Task Specific\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"Sensitivity & Specificity\\\",\\n      \\\"category\\\": \\\"quality_metric\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"ROC & AUC\\\",\\n      \\\"category\", \"parsed\": {\"term\": \"Sensitivity & Specificity\", \"category\": \"quality_metric\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide4.json",
        "parsed": {
          "s": "General Measures",
          "p": "measures",
          "o": "KL Distance",
          "modalities": [
            "text"
          ],
          "confidence": 0.85,
          "evidence": [
            "One example I'll briefly mention is the Kullback-Leibler divergence, or KL distance."
          ]
        },
        "raw": "{\"slide_id\": \"Slide4\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:10:57.383795+00:00\", \"text_length\": 2705, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\\n\\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\n\\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\\n\\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\\n\\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\\n\\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"General Measures\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"MSE\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"General Measures\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"KL Distance\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.85,\\n      \\\"evidence\\\": \\\"One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"General Measures\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"SSIM\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"And then there is a very\", \"parsed\": {\"s\": \"General Measures\", \"p\": \"measures\", \"o\": \"KL Distance\", \"modalities\": [\"text\"], \"confidence\": 0.85, \"evidence\": [\"One example I'll briefly mention is the Kullback-Leibler divergence, or KL distance.\"]}}"
      }
    }
  }
}