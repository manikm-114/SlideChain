{
  "lecture": "Lecture 11",
  "slide_id": "Slide20",
  "paths": {
    "image": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Images\\Slide20.JPG",
    "text": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Texts\\Slide20.txt"
  },
  "models": {
    "llava-hf__llava-onevision-qwen2-7b-ov-hf": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\concepts\\Slide20.json",
        "parsed": {
          "concepts": [
            {
              "term": "contrast",
              "category": "signal_processing"
            },
            {
              "term": "standard deviation",
              "category": "mathematics"
            },
            {
              "term": "luminance",
              "category": "signal_processing"
            },
            {
              "term": "dynamic range",
              "category": "signal_processing"
            },
            {
              "term": "contrast comparison",
              "category": "signal_processing"
            },
            {
              "term": "structural similarity",
              "category": "quality_metric"
            },
            {
              "term": "structural comparison",
              "category": "quality_metric"
            }
          ],
          "evidence": [
            "The second component of SSIM is the contrast comparison.",
            "Even if two images have the same average brightness, they may still look very different if their contrast is not the same.",
            "The formula for contrast comparison looks very similar to the one we used for luminance.",
            "The formula reflects this effect, sometimes called contrast masking."
          ]
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"concepts\", \"raw_output\": \"user \\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe second component of SSIM is the contrast comparison.\\nEven if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\n\\nThe formula for contrast comparison looks very similar to the one we used for luminance. It is written as:\\nC of X and Y equals two times sigma-X times sigma-Y, plus a constant C2, divided by sigma-X squared plus sigma-Y squared, plus that same constant C2.\\n\\nHere again, the constant is added to prevent instability when values are close to zero. C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\nNow, notice how this works:\\nIf the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\nIf one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\nThis design is also consistent with how the human visual system works. For example, in a very dark room, small changes in brightness can be quite noticeable. But in a very bright, high-contrast scene, the same small changes are much harder to see. The formula reflects this effect, sometimes called contrast masking.\\n\\nSo contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\nNext, we’ll look at the third pillar: the structural comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Category guidance:\\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\\n  * physics → energy, radiation, waves, gradients, attenuation\\n  * instrumentation → scanners, detectors, coils, transducers, gantry\\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\\n  * communication → network or data transfer\\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\\n  * algorithm → analytical/iterative computational methods\\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\nassistant\\n```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"contrast\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"luminance\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"dynamic range\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"quality_metric\\\"},\\n    {\\\"term\\\": \\\"structural comparison\\\", \\\"category\\\": \\\"quality_metric\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"The second component of SSIM is the contrast comparison.\\\", \\\"Even if two images have the same average brightness, they may still look very different if their contrast is not the same.\\\", \\\"The formula for contrast comparison looks very similar to the one we used for luminance.\\\", \\\"The formula reflects this effect, sometimes called contrast masking.\\\"]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"contrast\", \"category\": \"signal_processing\"}, {\"term\": \"standard deviation\", \"category\": \"mathematics\"}, {\"term\": \"luminance\", \"category\": \"signal_processing\"}, {\"term\": \"dynamic range\", \"category\": \"signal_processing\"}, {\"term\": \"contrast comparison\", \"category\": \"signal_processing\"}, {\"term\": \"structural similarity\", \"category\": \"quality_metric\"}, {\"term\": \"structural comparison\", \"category\": \"quality_metric\"}], \"evidence\": [\"The second component of SSIM is the contrast comparison.\", \"Even if two images have the same average brightness, they may still look very different if their contrast is not the same.\", \"The formula for contrast comparison looks very similar to the one we used for luminance.\", \"The formula reflects this effect, sometimes called contrast masking.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\llava-hf__llava-onevision-qwen2-7b-ov-hf\\triples\\Slide20.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"llava-hf/llava-onevision-qwen2-7b-ov-hf\", \"prompt\": \"triples\", \"raw_output\": \"user \\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe second component of SSIM is the contrast comparison.\\nEven if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\n\\nThe formula for contrast comparison looks very similar to the one we used for luminance. It is written as:\\nC of X and Y equals two times sigma-X times sigma-Y, plus a constant C2, divided by sigma-X squared plus sigma-Y squared, plus that same constant C2.\\n\\nHere again, the constant is added to prevent instability when values are close to zero. C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\nNow, notice how this works:\\nIf the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\nIf one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\nThis design is also consistent with how the human visual system works. For example, in a very dark room, small changes in brightness can be quite noticeable. But in a very bright, high-contrast scene, the same small changes are much harder to see. The formula reflects this effect, sometimes called contrast masking.\\n\\nSo contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\nNext, we’ll look at the third pillar: the structural comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if the relation is clearly visible without the text.\\n- confidence in [0,1]. Do not invent entities or relations.\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\nassistant\\n```json\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"SSIM\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"contrast comparison\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"The second component of SSIM is the contrast comparison. Even if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\\"}\\n  ]\\n}\\n```\", \"parsed\": {\"triples\": []}}"
      }
    },
    "OpenGVLab__InternVL3-14B": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\concepts\\Slide20.json",
        "parsed": {
          "concepts": [
            {
              "term": "contrast comparison",
              "category": "signal_processing"
            },
            {
              "term": "standard deviation",
              "category": "mathematics"
            },
            {
              "term": "dynamic range",
              "category": "signal_processing"
            },
            {
              "term": "contrast masking",
              "category": "signal_processing"
            },
            {
              "term": "structural similarity",
              "category": "signal_processing"
            }
          ],
          "evidence": [
            "The second component of SSIM is the contrast comparison.",
            "We use the standard deviation of pixel values - sigma-X for image X and sigma-Y for image Y.",
            "C2 is defined as K2 times L squared, where L is the dynamic range of the image.",
            "The formula reflects this effect, sometimes called contrast masking.",
            "So contrast is the second pillar of structural similarity - it ensures that two images not only have the same average brightness but also the same level of variation around that average.",
            "This is consistent with the contrast-masking feature of the HVS."
          ]
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"concepts\", \"raw_output\": \"```json\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"dynamic range\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast masking\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"human visual system\\\", \\\"category\\\": \\\"biology\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"The second component of SSIM is the contrast comparison.\\\",\\n    \\\"We use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\\",\\n    \\\"C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\\",\\n    \\\"The formula reflects this effect, sometimes called contrast masking.\\\",\\n    \\\"So contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\\",\\n    \\\"This is consistent with the contrast-masking feature of the HVS.\\\"\\n  ]\\n}\\n```\", \"parsed\": {\"concepts\": [{\"term\": \"contrast comparison\", \"category\": \"signal_processing\"}, {\"term\": \"standard deviation\", \"category\": \"mathematics\"}, {\"term\": \"dynamic range\", \"category\": \"signal_processing\"}, {\"term\": \"contrast masking\", \"category\": \"signal_processing\"}, {\"term\": \"structural similarity\", \"category\": \"signal_processing\"}], \"evidence\": [\"The second component of SSIM is the contrast comparison.\", \"We use the standard deviation of pixel values - sigma-X for image X and sigma-Y for image Y.\", \"C2 is defined as K2 times L squared, where L is the dynamic range of the image.\", \"The formula reflects this effect, sometimes called contrast masking.\", \"So contrast is the second pillar of structural similarity - it ensures that two images not only have the same average brightness but also the same level of variation around that average.\", \"This is consistent with the contrast-masking feature of the HVS.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\OpenGVLab__InternVL3-14B\\triples\\Slide20.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"OpenGVLab/InternVL3-14B\", \"prompt\": \"triples\", \"raw_output\": \"{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"contrast comparison function\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"standard deviation of pixel values\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"contrast comparison function\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"contrast\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"Even if two images have the same average brightness, they may still look very different if their contrast is not the same.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"contrast comparison function\\\",\\n      \\\"p\\\": \\\"represents\\\",\\n      \\\"o\\\": \\\"human visual system\\\",\\n      \\\"modalities\\\": [\\\"text\\\"],\\n      \\\"confidence\\\": 1.0,\\n      \\\"evidence\\\": \\\"This design is also consistent with how the human visual system works.\\\"\\n    }\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen2-VL-7B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\concepts\\Slide20.json",
        "parsed": {
          "concepts": [
            {
              "term": "contrast comparison",
              "category": "signal_processing"
            },
            {
              "term": "standard deviation",
              "category": "mathematics"
            },
            {
              "term": "sigma-X",
              "category": "signal_processing"
            },
            {
              "term": "sigma-Y",
              "category": "signal_processing"
            },
            {
              "term": "dynamic range",
              "category": "signal_processing"
            },
            {
              "term": "contrast masking",
              "category": "signal_processing"
            },
            {
              "term": "structural similarity",
              "category": "signal_processing"
            },
            {
              "term": "human visual system",
              "category": "signal_processing"
            }
          ],
          "evidence": [
            "The formula for contrast comparison looks very similar to the one we used for luminance.",
            "This design is also consistent with how the human visual system works.",
            "The formula reflects this effect, sometimes called contrast masking."
          ]
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:53:37.224005+00:00\", \"text_length\": 1679, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe second component of SSIM is the contrast comparison.\\nEven if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\n\\nThe formula for contrast comparison looks very similar to the one we used for luminance. It is written as:\\nC of X and Y equals two times sigma-X times sigma-Y, plus a constant C2, divided by sigma-X squared plus sigma-Y squared, plus that same constant C2.\\n\\nHere again, the constant is added to prevent instability when values are close to zero. C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\nNow, notice how this works:\\nIf the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\nIf one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\nThis design is also consistent with how the human visual system works. For example, in a very dark room, small changes in brightness can be quite noticeable. But in a very bright, high-contrast scene, the same small changes are much harder to see. The formula reflects this effect, sometimes called contrast masking.\\n\\nSo contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\nNext, we’ll look at the third pillar: the structural comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"contrast comparison\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"standard deviation\\\", \\\"category\\\": \\\"mathematics\\\"},\\n    {\\\"term\\\": \\\"sigma-X\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"sigma-Y\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"C2\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"K2\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"L\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"dynamic range\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"contrast masking\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"structural similarity\\\", \\\"category\\\": \\\"signal_processing\\\"},\\n    {\\\"term\\\": \\\"human visual system\\\", \\\"category\\\": \\\"signal_processing\\\"}\\n  ],\\n  \\\"evidence\\\": [\\n    \\\"The formula for contrast comparison looks very similar to the one we used for luminance.\\\",\\n    \\\"This design is also consistent with how the human visual system works.\\\",\\n    \\\"The formula reflects this effect, sometimes called contrast masking.\\\"\\n  ]\\n}\", \"parsed\": {\"concepts\": [{\"term\": \"contrast comparison\", \"category\": \"signal_processing\"}, {\"term\": \"standard deviation\", \"category\": \"mathematics\"}, {\"term\": \"sigma-X\", \"category\": \"signal_processing\"}, {\"term\": \"sigma-Y\", \"category\": \"signal_processing\"}, {\"term\": \"dynamic range\", \"category\": \"signal_processing\"}, {\"term\": \"contrast masking\", \"category\": \"signal_processing\"}, {\"term\": \"structural similarity\", \"category\": \"signal_processing\"}, {\"term\": \"human visual system\", \"category\": \"signal_processing\"}], \"evidence\": [\"The formula for contrast comparison looks very similar to the one we used for luminance.\", \"This design is also consistent with how the human visual system works.\", \"The formula reflects this effect, sometimes called contrast masking.\"]}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen2-VL-7B-Instruct\\triples\\Slide20.json",
        "parsed": {
          "triples": []
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"Qwen/Qwen2-VL-7B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T05:31:41.925821+00:00\", \"text_length\": 1679, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe second component of SSIM is the contrast comparison.\\nEven if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\n\\nThe formula for contrast comparison looks very similar to the one we used for luminance. It is written as:\\nC of X and Y equals two times sigma-X times sigma-Y, plus a constant C2, divided by sigma-X squared plus sigma-Y squared, plus that same constant C2.\\n\\nHere again, the constant is added to prevent instability when values are close to zero. C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\nNow, notice how this works:\\nIf the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\nIf one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\nThis design is also consistent with how the human visual system works. For example, in a very dark room, small changes in brightness can be quite noticeable. But in a very bright, high-contrast scene, the same small changes are much harder to see. The formula reflects this effect, sometimes called contrast masking.\\n\\nSo contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\nNext, we’ll look at the third pillar: the structural comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\", \"parsed\": {\"triples\": []}}"
      }
    },
    "Qwen__Qwen3-VL-4B-Instruct": {
      "concepts": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\concepts\\Slide20.json",
        "parsed": {
          "term": "If the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.",
          "category": "mathematics"
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"concepts\", \"timestamp_utc\": \"2025-11-09T03:03:11.427948+00:00\", \"text_length\": 1679, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are an expert educator in medical imaging. From the following slide text,\\nextract the key technical or scientific concepts that are essential for understanding the topic.\\n\\nUser:\\nSLIDE_TEXT:\\nThe second component of SSIM is the contrast comparison.\\nEven if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\n\\nThe formula for contrast comparison looks very similar to the one we used for luminance. It is written as:\\nC of X and Y equals two times sigma-X times sigma-Y, plus a constant C2, divided by sigma-X squared plus sigma-Y squared, plus that same constant C2.\\n\\nHere again, the constant is added to prevent instability when values are close to zero. C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\nNow, notice how this works:\\nIf the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\nIf one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\nThis design is also consistent with how the human visual system works. For example, in a very dark room, small changes in brightness can be quite noticeable. But in a very bright, high-contrast scene, the same small changes are much harder to see. The formula reflects this effect, sometimes called contrast masking.\\n\\nSo contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\nNext, we’ll look at the third pillar: the structural comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return pure JSON only. No prose, no markdown, no code fences.\\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\\n- Assign exactly one category from:\\n  software | workflow | mathematics | signal_processing | frequency_domain |\\n  physics | instrumentation | data_processing | reconstruction |\\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\\n- Reject filler or administrative text.\\n- Output format:\\n{\\n  \\\"concepts\\\": [\\n    {\\\"term\\\": \\\"<exact term from slide>\\\", \\\"category\\\": \\\"<category>\\\"}\\n  ],\\n  \\\"evidence\\\": [\\\"<short supporting phrase from SLIDE_TEXT>\\\"]\\n}\\n\\nassistant\\n{\\n  \\\"concepts\\\": [\\n    {\\n      \\\"term\\\": \\\"the contrast comparison function takes a similar form\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"c(x, y) = (2σ_xσ_y + C_2) / (σ_x^2 + σ_y^2 + C_2)\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"C_2 = (K_2L)^2\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"K_2 ≪ 1\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y\\\",\\n      \\\"category\\\": \\\"signal_processing\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"If the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\\",\\n      \\\"category\\\": \\\"mathematics\\\"\\n    },\\n    {\\n      \\\"term\\\": \\\"If one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\\",\\n      \\\"category\\\":\", \"parsed\": {\"term\": \"If the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\", \"category\": \"mathematics\"}}"
      },
      "triples": {
        "source": "G:\\My Drive\\1. Studies\\RPI\\Thesis\\1. Prof Ge Wang\\1. Avatar Project\\Future Directions\\Comparing Models\\Lectures\\Retrieved Data\\Further Work\\MILU23\\Lecture 11\\Outputs\\Qwen__Qwen3-VL-4B-Instruct\\triples\\Slide20.json",
        "parsed": {
          "s": "contrast comparison function",
          "p": "uses",
          "o": "standard deviation of pixel values",
          "modalities": [
            "text"
          ],
          "confidence": 0.95,
          "evidence": [
            "The contrast comparison function takes a similar form ... where C2 = (K2L)², and K2 << 1. This definition again satisfies the three properties listed above. An important feature of this function is that with the same amount of contrast change Δσ = σy − σx, this measure is less sensitive to the case of high base contrast σx than low base contrast. This is consistent with the contrast-masking feature of the HVS."
          ]
        },
        "raw": "{\"slide_id\": \"Slide20\", \"model\": \"Qwen/Qwen3-VL-4B-Instruct\", \"prompt\": \"triples\", \"timestamp_utc\": \"2025-11-09T03:12:50.630328+00:00\", \"text_length\": 1679, \"raw_output\": \"system\\nYou are a helpful AI for medical imaging.\\nuser\\nSystem:\\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\\n\\nUser:\\nSLIDE_TEXT:\\nThe second component of SSIM is the contrast comparison.\\nEven if two images have the same average brightness, they may still look very different if their contrast is not the same. One might look sharp and vivid, while the other looks flat or washed out. To capture this, we use the standard deviation of pixel values — sigma-X for image X and sigma-Y for image Y.\\n\\nThe formula for contrast comparison looks very similar to the one we used for luminance. It is written as:\\nC of X and Y equals two times sigma-X times sigma-Y, plus a constant C2, divided by sigma-X squared plus sigma-Y squared, plus that same constant C2.\\n\\nHere again, the constant is added to prevent instability when values are close to zero. C2 is defined as K2 times L squared, where L is the dynamic range of the image.\\nNow, notice how this works:\\nIf the two images have the same standard deviation, meaning their contrasts are the same, then the numerator and denominator match, and the contrast comparison equals 1.\\nIf one image has much higher or lower contrast than the other, then the ratio becomes smaller, and the similarity drops.\\nThis design is also consistent with how the human visual system works. For example, in a very dark room, small changes in brightness can be quite noticeable. But in a very bright, high-contrast scene, the same small changes are much harder to see. The formula reflects this effect, sometimes called contrast masking.\\n\\nSo contrast is the second pillar of structural similarity — it ensures that two images not only have the same average brightness but also the same level of variation around that average.\\nNext, we’ll look at the third pillar: the structural comparison.\\n\\nSTRICT INSTRUCTIONS:\\n- Return JSON only. No prose, no markdown, no code fences.\\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\\n- Add modalities [\\\"text\\\"] by default; add \\\"image\\\" only if clearly visible without the text.\\n- Confidence in [0,1].\\n\\nOUTPUT:\\n{\\n  \\\"triples\\\": [\\n    {\\\"s\\\":\\\"<verbatim subject>\\\", \\\"p\\\":\\\"uses|via|represents|depends_on|measures|produces|reconstructs_with\\\",\\n     \\\"o\\\":\\\"<verbatim object>\\\", \\\"modalities\\\":[\\\"text\\\",\\\"image\\\"], \\\"confidence\\\":0.0, \\\"evidence\\\":\\\"<short quote from SLIDE_TEXT>\\\"}\\n  ]\\n}\\n\\nassistant\\n{\\n  \\\"triples\\\": [\\n    {\\n      \\\"s\\\": \\\"contrast comparison function\\\",\\n      \\\"p\\\": \\\"uses\\\",\\n      \\\"o\\\": \\\"standard deviation of pixel values\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"The contrast comparison function takes a similar form ... where C2 = (K2L)², and K2 << 1. This definition again satisfies the three properties listed above. An important feature of this function is that with the same amount of contrast change Δσ = σy − σx, this measure is less sensitive to the case of high base contrast σx than low base contrast. This is consistent with the contrast-masking feature of the HVS.\\\"\\n    },\\n    {\\n      \\\"s\\\": \\\"contrast comparison function\\\",\\n      \\\"p\\\": \\\"measures\\\",\\n      \\\"o\\\": \\\"contrast\\\",\\n      \\\"modalities\\\": [\\n        \\\"text\\\"\\n      ],\\n      \\\"confidence\\\": 0.95,\\n      \\\"evidence\\\": \\\"The second component of SSIM is the contrast comparison. Even if two images have the same average brightness, they may still look very different if their contrast is not the same. To capture this, we use the\", \"parsed\": {\"s\": \"contrast comparison function\", \"p\": \"uses\", \"o\": \"standard deviation of pixel values\", \"modalities\": [\"text\"], \"confidence\": 0.95, \"evidence\": [\"The contrast comparison function takes a similar form ... where C2 = (K2L)², and K2 << 1. This definition again satisfies the three properties listed above. An important feature of this function is that with the same amount of contrast change Δσ = σy − σx, this measure is less sensitive to the case of high base contrast σx than low base contrast. This is consistent with the contrast-masking feature of the HVS.\"]}}"
      }
    }
  }
}