{
  "slide_id": "Slide41",
  "model": "llava-hf/llava-onevision-qwen2-7b-ov-hf",
  "prompt": "concepts",
  "raw_output": "user \nSystem:\nYou are an expert educator in medical imaging. From the following slide text,\nextract the key technical or scientific concepts that are essential for understanding the topic.\n\nUser:\nSLIDE_TEXT:\nThere are multiple high-order effects in PET imaging, and this is what I’m showing here with these figures. Ideally, you want to detect coincidences—by definition, in a given time window, you should only have two gamma-ray photons captured. If your time window is short enough, you get a well-controlled count rate, typically up to 100,000 per second, which is the principle behind coincidence detection. However, sometimes within a short time interval, you might have three gamma-ray photons reported simultaneously. How does this happen? For example, the first annihilation event is detected near detector two, so its gamma photon reaches that detector and is recorded. \n\nWithin that same time window, another event occurs closer to detector thirteen, and its sister photon travels a longer path. Before the photon from the second event reaches detector five, the third photon from the first event might reach detector ten. So, within the same interval, three photons can be detected as coincidences.\nWhenever you get triple coincidences—three detected photons in the same resolving window—they introduce confusion, and you simply discard that data. The system is designed to expect only pairs of coincident photons. If you see this higher-order event, you just throw it away, focusing only on true doubles.\n\nBut confusing situations remain: it’s hard to know which events should be assigned to which lines of response. That's where the correction factor formula comes in. For every true coincidence measurement, you also need to account for the data lost due to triple or higher-order coincidences. The formula shown here calculates the correction factor—combining both the estimated loss from discarded high-order events and the true measurement—to help restore your measured data to the real level. Sometimes, higher-order events may be very rare, but if your time window is wide enough, you might encounter even more photons simultaneously, which complicates things further. In practice, these cases are always discarded, and the formula allows you to estimate the amount of lost data. You then use this correction factor to scale your results back to the true count, improving accuracy in quantitative PET measurements.\n\nSTRICT INSTRUCTIONS:\n- Return pure JSON only. No prose, no markdown, no code fences.\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\n- Assign exactly one category from:\n  software | workflow | mathematics | signal_processing | frequency_domain |\n  physics | instrumentation | data_processing | reconstruction |\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\n- Category guidance:\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\n  * physics → energy, radiation, waves, gradients, attenuation\n  * instrumentation → scanners, detectors, coils, transducers, gantry\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\n  * communication → network or data transfer\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\n  * algorithm → analytical/iterative computational methods\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\n- Output format:\n{\n  \"concepts\": [\n    {\"term\": \"<exact term from slide>\", \"category\": \"<category>\"}\n  ],\n  \"evidence\": [\"<short supporting phrase from SLIDE_TEXT>\"]\n}\nassistant\n```json\n{\n  \"concepts\": [\n    {\"term\": \"coincidence detection\", \"category\": \"physics\"},\n    {\"term\": \"gamma-ray photons\", \"category\": \"physics\"},\n    {\"term\": \"time window\", \"category\": \"signal_processing\"},\n    {\"term\": \"count rate\", \"category\": \"signal_processing\"},\n    {\"term\": \"discarded data\", \"category\": \"data_processing\"},\n    {\"term\": \"correction factor\", \"category\": \"mathematics\"},\n    {\"term\": \"estimated loss\", \"category\": \"data_processing\"},\n    {\"term\": \"true measurement\", \"category\": \"data_processing\"},\n    {\"term\": \"higher-order events\", \"category\": \"physics\"},\n    {\"term\": \"rare events\", \"category\": \"physics\"},\n    {\"term\": \"wide enough\", \"category\": \"signal_processing\"}\n  ],\n  \"evidence\": [\"...you want to detect coincidences—by definition, in a given time window, you should only have two gamma-ray photons captured.\", \n               \"...if your time window is short enough, you get a well-controlled count rate, typically up to 100,000 per second, which is the principle behind coincidence detection.\",",
  "parsed": {
    "term": "wide enough",
    "category": "signal_processing"
  }
}