{
  "slide_id": "Slide6",
  "model": "llava-hf/llava-onevision-qwen2-7b-ov-hf",
  "prompt": "concepts",
  "raw_output": "user \nSystem:\nYou are an expert educator in medical imaging. From the following slide text,\nextract the key technical or scientific concepts that are essential for understanding the topic.\n\nUser:\nSLIDE_TEXT:\nStatistical distributions are very important, especially for understanding noise and random variables over different intervals. The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely. That’s one simple kind of distribution.\n\nNext, we have the Gaussian distribution, and after that, the Poisson distribution. The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma. If mu is zero and sigma is one, that’s the standard normal distribution. Mathematically, you see a scaling factor and an exponential factor involving mu and sigma. This type of distribution is used everywhere in engineering, noise measurement, estimation, and more.\nIf you have lots of independent random variables, each contributing a bit—maybe some are uniform, maybe some are not—when you put them all together, the outcome will tend to look like a Gaussian curve. This is a fundamental result from statistics, and it’s why you see the bell-shaped curve over and over in reality—lots of independent factors add up to give something that looks Gaussian.\n\nThe Poisson distribution is related to the Gaussian, but looks very different, especially with small means. The Poisson describes random variables that give you counts—like one, two, three, and so on—with different probabilities for each count. It’s controlled by the mean, which we call lambda. If that mean is small, you get a very asymmetric distribution. But as lambda grows larger, the curve starts to look more and more like a Gaussian—eventually, if lambda is really big, the Poisson distribution and the Gaussian distribution look nearly the same.\n\nFor the Gaussian, you have mean and variance, with variance noted as sigma squared. For Poisson, both mean and variance are just lambda. You can actually derive the Gaussian by combining lots of individual random distributions—through convolution—and prove it’s a bell-shaped curve.\nSo, in summary, we’re going to see both Gaussian and Poisson noise often in imaging, and understanding how they behave is key to handling measurement and image reconstruction accurately.\n\nSTRICT INSTRUCTIONS:\n- Return pure JSON only. No prose, no markdown, no code fences.\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\n- Assign exactly one category from:\n  software | workflow | mathematics | signal_processing | frequency_domain |\n  physics | instrumentation | data_processing | reconstruction |\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\n- Category guidance:\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\n  * physics → energy, radiation, waves, gradients, attenuation\n  * instrumentation → scanners, detectors, coils, transducers, gantry\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\n  * communication → network or data transfer\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\n  * algorithm → analytical/iterative computational methods\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\n- Output format:\n{\n  \"concepts\": [\n    {\"term\": \"<exact term from slide>\", \"category\": \"<category>\"}\n  ],\n  \"evidence\": [\"<short supporting phrase from SLIDE_TEXT>\"]\n}\nassistant\n```json\n{\n  \"concepts\": [\n    {\"term\": \"uniform distribution\", \"category\": \"mathematics\"},\n    {\"term\": \"Gaussian distribution\", \"category\": \"mathematics\"},\n    {\"term\": \"Poisson distribution\", \"category\": \"mathematics\"},\n    {\"term\": \"mean\", \"category\": \"mathematics\"},\n    {\"term\": \"standard deviation\", \"category\": \"mathematics\"},\n    {\"term\": \"independent random variables\", \"category\": \"mathematics\"},\n    {\"term\": \"Gaussian curve\", \"category\": \"mathematics\"},\n    {\"term\": \"Poisson distribution\", \"category\": \"mathematics\"},\n    {\"term\": \"lambda\", \"category\": \"mathematics\"}\n  ],\n  \"evidence\": [\"The simplest case is the uniform distribution. With a uniform distribution, every point in the interval, like zero to one or zero to five, has the same chance of being picked. Every number in that range is equally likely.\", \n             \"The Gaussian distribution, also called the normal distribution, is your classic bell-shaped curve. You usually describe it with a mean—called mu—and a standard deviation, sigma.\", \n             \"If you have lots of independent random variables, each contributing a",
  "parsed": {
    "term": "lambda",
    "category": "mathematics"
  }
}