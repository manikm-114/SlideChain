nohup: ignoring input
/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:119: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✅ Device: cuda
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 59074.70it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.19it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.53it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  2.22it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.84it/s]
✅ Successfully loaded: llava-hf/llava-onevision-qwen2-7b-ov-hf

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=concepts on 55 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/55 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   2%|▏         | 1/55 [00:09<08:53,  9.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   4%|▎         | 2/55 [00:18<07:55,  8.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   5%|▌         | 3/55 [00:26<07:33,  8.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   7%|▋         | 4/55 [00:32<06:31,  7.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   9%|▉         | 5/55 [00:41<06:37,  7.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  11%|█         | 6/55 [00:49<06:36,  8.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  13%|█▎        | 7/55 [00:58<06:34,  8.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  15%|█▍        | 8/55 [01:06<06:29,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  16%|█▋        | 9/55 [01:13<06:09,  8.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  18%|█▊        | 10/55 [01:22<06:08,  8.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  20%|██        | 11/55 [01:30<06:03,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  22%|██▏       | 12/55 [01:38<05:43,  7.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  24%|██▎       | 13/55 [01:41<04:40,  6.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  25%|██▌       | 14/55 [01:50<04:55,  7.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  27%|██▋       | 15/55 [01:58<05:03,  7.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  29%|██▉       | 16/55 [02:03<04:24,  6.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  31%|███       | 17/55 [02:12<04:36,  7.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  33%|███▎      | 18/55 [02:20<04:42,  7.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  35%|███▍      | 19/55 [02:29<04:43,  7.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  36%|███▋      | 20/55 [02:36<04:26,  7.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  38%|███▊      | 21/55 [02:44<04:28,  7.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  40%|████      | 22/55 [02:53<04:25,  8.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  42%|████▏     | 23/55 [02:57<03:47,  7.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  44%|████▎     | 24/55 [03:04<03:39,  7.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  45%|████▌     | 25/55 [03:11<03:26,  6.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  47%|████▋     | 26/55 [03:19<03:33,  7.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  49%|████▉     | 27/55 [03:28<03:35,  7.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  51%|█████     | 28/55 [03:36<03:33,  7.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  53%|█████▎    | 29/55 [03:45<03:29,  8.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  55%|█████▍    | 30/55 [03:53<03:24,  8.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  56%|█████▋    | 31/55 [04:02<03:18,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  58%|█████▊    | 32/55 [04:08<02:58,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  60%|██████    | 33/55 [04:17<02:55,  7.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  62%|██████▏   | 34/55 [04:25<02:50,  8.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  64%|██████▎   | 35/55 [04:34<02:44,  8.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  65%|██████▌   | 36/55 [04:42<02:37,  8.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  67%|██████▋   | 37/55 [04:51<02:30,  8.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  69%|██████▉   | 38/55 [04:59<02:22,  8.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  71%|███████   | 39/55 [05:08<02:14,  8.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  73%|███████▎  | 40/55 [05:14<01:57,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  75%|███████▍  | 41/55 [05:22<01:52,  8.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  76%|███████▋  | 42/55 [05:31<01:46,  8.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  78%|███████▊  | 43/55 [05:36<01:27,  7.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  80%|████████  | 44/55 [05:45<01:24,  7.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  82%|████████▏ | 45/55 [05:53<01:18,  7.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  84%|████████▎ | 46/55 [06:02<01:12,  8.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  85%|████████▌ | 47/55 [06:10<01:05,  8.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  87%|████████▋ | 48/55 [06:19<00:58,  8.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  89%|████████▉ | 49/55 [06:27<00:50,  8.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  91%|█████████ | 50/55 [06:36<00:41,  8.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  93%|█████████▎| 51/55 [06:44<00:33,  8.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  95%|█████████▍| 52/55 [06:53<00:25,  8.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  96%|█████████▋| 53/55 [07:01<00:16,  8.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  98%|█████████▊| 54/55 [07:10<00:08,  8.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 55/55 [07:18<00:00,  8.44s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 55/55 [07:18<00:00,  7.97s/it]
✅ Completed 55/55 slides

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=triples on 55 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   0%|          | 0/55 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   2%|▏         | 1/55 [00:03<03:10,  3.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   4%|▎         | 2/55 [00:06<03:05,  3.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   5%|▌         | 3/55 [00:11<03:13,  3.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   7%|▋         | 4/55 [00:15<03:19,  3.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   9%|▉         | 5/55 [00:19<03:18,  3.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  11%|█         | 6/55 [00:23<03:15,  3.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  13%|█▎        | 7/55 [00:31<04:21,  5.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  15%|█▍        | 8/55 [00:34<03:41,  4.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  16%|█▋        | 9/55 [00:38<03:23,  4.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  18%|█▊        | 10/55 [00:47<04:15,  5.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  20%|██        | 11/55 [00:55<04:46,  6.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  22%|██▏       | 12/55 [00:59<04:03,  5.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  24%|██▎       | 13/55 [01:02<03:28,  4.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  25%|██▌       | 14/55 [01:06<03:10,  4.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  27%|██▋       | 15/55 [01:09<02:45,  4.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  29%|██▉       | 16/55 [01:17<03:30,  5.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  31%|███       | 17/55 [01:21<03:02,  4.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  33%|███▎      | 18/55 [01:24<02:37,  4.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  35%|███▍      | 19/55 [01:28<02:28,  4.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  36%|███▋      | 20/55 [01:31<02:19,  3.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  38%|███▊      | 21/55 [01:36<02:22,  4.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  40%|████      | 22/55 [01:39<02:11,  3.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  42%|████▏     | 23/55 [01:48<02:49,  5.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  44%|████▎     | 24/55 [01:51<02:29,  4.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  45%|████▌     | 25/55 [01:54<02:07,  4.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  47%|████▋     | 26/55 [02:00<02:15,  4.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  49%|████▉     | 27/55 [02:04<02:04,  4.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  51%|█████     | 28/55 [02:08<01:56,  4.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  53%|█████▎    | 29/55 [02:13<01:59,  4.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  55%|█████▍    | 30/55 [02:17<01:50,  4.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  56%|█████▋    | 31/55 [02:26<02:14,  5.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  58%|█████▊    | 32/55 [02:29<01:50,  4.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  60%|██████    | 33/55 [02:33<01:42,  4.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  62%|██████▏   | 34/55 [02:37<01:32,  4.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  64%|██████▎   | 35/55 [02:41<01:28,  4.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  65%|██████▌   | 36/55 [02:45<01:22,  4.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  67%|██████▋   | 37/55 [02:54<01:40,  5.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  69%|██████▉   | 38/55 [02:58<01:25,  5.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  71%|███████   | 39/55 [03:01<01:12,  4.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  73%|███████▎  | 40/55 [03:04<01:00,  4.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  75%|███████▍  | 41/55 [03:12<01:14,  5.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  76%|███████▋  | 42/55 [03:16<01:04,  4.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  78%|███████▊  | 43/55 [03:21<00:58,  4.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  80%|████████  | 44/55 [03:24<00:48,  4.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  82%|████████▏ | 45/55 [03:29<00:44,  4.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  84%|████████▎ | 46/55 [03:32<00:36,  4.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  85%|████████▌ | 47/55 [03:35<00:30,  3.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  87%|████████▋ | 48/55 [03:39<00:26,  3.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  89%|████████▉ | 49/55 [03:43<00:22,  3.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  91%|█████████ | 50/55 [03:46<00:18,  3.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  93%|█████████▎| 51/55 [03:49<00:13,  3.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  95%|█████████▍| 52/55 [03:57<00:14,  4.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  96%|█████████▋| 53/55 [04:01<00:09,  4.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  98%|█████████▊| 54/55 [04:05<00:04,  4.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 55/55 [04:09<00:00,  4.19s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 55/55 [04:09<00:00,  4.53s/it]
✅ Completed 55/55 slides
