Now, once you put that single-crystal transducer inside a handheld housing, you get what we commonly call a probe — or a transducer head.
You simply place this probe on top of the area you want to examine — it could be the chest, the abdomen, the breast, an arm, or any other part of the body — depending on what you are imaging. These probes are used for a variety of diagnostic and therapeutic purposes.

On this slide, you can see several examples of commercial ultrasound probes. Each one is designed for a different purpose — some are curved for abdominal imaging, some are linear for vascular or musculoskeletal scans, and others are very small for intracavitary or ophthalmic use.

Now, I’d like to share a more forward-looking idea — something I’ve been thinking about for quite a while. I believe that in the future, our everyday devices — maybe even the iPhone — could incorporate this kind of piezoelectric technology directly into the screen.

Just imagine that the phone’s surface could act as a two-dimensional acoustic transducer array. Each tiny pixel on the screen could both generate and receive ultrasound signals. That means you could, in principle, perform a quick body scan right at home — maybe before going to bed.
You could place the phone on your skin, and the device would automatically send out ultrasound waves, collect the echoes, and the AI software inside would analyze the data for you. It might tell you, “Everything looks fine,” or “You may want to check this area further.” It could even show you which parts of the body were already scanned and which ones weren’t.

By combining piezoelectric technology, machine learning, and digital signal processing, we could one day make personal, professional-level imaging accessible to everyone — right from their own phone.

This might sound futuristic, but remember — all great innovations start as ideas. And this one could truly revolutionize preventive healthcare by bringing ultrasound diagnostics into the hands of ordinary people.