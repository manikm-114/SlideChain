Now, I know DARPA has funded huge research programs in this new frontier of ultrasound technology. It’s important to remember that ultrasound is not an electromagnetic wave. This makes it fundamentally different from X-ray, CT, nuclear imaging, or MRI.

MRI, for example, uses radio-frequency (RF) signals, which are simply alternating magnetic fields — still part of the electromagnetic spectrum. X-ray and nuclear imaging use high-energy photons — X-rays and gamma rays — which can behave like both waves and particles. All of those imaging types relate to Maxwell’s equations if we describe them as waves, or to Boltzmann’s equations if we describe them as particles.
But ultrasound is different — it’s a mechanical wave, not electromagnetic. It physically vibrates particles in a medium — air, water, or biological tissue. That’s why it needs a medium to travel; it can’t move through a vacuum.

As you can see in this frequency chart, the audible range for humans is roughly from 20 hertz to 20 kilohertz — that’s what you and I can hear, like my speaking voice or birds singing. Ultrasound goes far beyond that, starting from around 20 kilohertz and reaching into the megahertz range.

In medical imaging, typical frequencies are between 2 MHz and 20 MHz, depending on the application. Lower frequencies penetrate deeper but give lower resolution; higher frequencies provide sharper images but can’t go as deep. Industrial and destructive-testing ultrasounds can reach up to hundreds of megahertz.
So, unlike the sound waves we can hear, these ultrasound waves are way too high-frequency for our ears. And with very high-power, focused ultrasound, we can actually go beyond imaging — we can cut or heat tissue, like a kind of ultrasound knife. It’s used in certain treatments to destroy tumors or cauterize tissue.

But in this lecture, our focus remains on diagnostic ultrasound imaging — understanding how these mechanical waves are formed, transmitted, and received to create medical images.