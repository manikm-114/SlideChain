{
  "slide_id": "Slide39",
  "model": "Qwen/Qwen2-VL-7B-Instruct",
  "prompt": "triples",
  "timestamp_utc": "2025-11-09T18:54:39.999221+00:00",
  "text_length": 5597,
  "raw_output": "system\nYou are a helpful AI for medical imaging.\nuser\nSystem:\nYou are extracting factual relations from a medical imaging lecture. Use only information grounded in the input SLIDE_TEXT.\n\nUser:\nSLIDE_TEXT:\nNow, this next imaging modality is what we call bioluminescence tomography. It’s one of the most fascinating — but also one of the most challenging — tomography problems we can deal with.\nLet me explain why.\nIn fluorescence tomography, you can send in a laser beam — you control where it goes, you can illuminate the tissue from different directions, and that makes it what we call an active imaging modality. You actively excite the fluorescent molecules, and they emit light back, which you can detect and reconstruct into an image.\n\nBut bioluminescence tomography is totally different. Here, the light comes from inside the animal itself — not from any external laser. You don’t get to shine a laser and choose where to excite. The light is produced biologically, inside the tissue, by a chemical reaction, typically involving something like luciferase, the same enzyme that makes a firefly glow.\nSo, imagine you genetically modify an animal — usually a mouse — to express this bioluminescent probe inside its cells. The animal literally becomes like a little living firefly. When the probe reacts inside its body, it emits light that escapes through the tissue, and you can capture that light on the surface.\n\nThat’s beautiful to watch — I still remember when we did this experiment back at the University of Iowa. We worked in a completely dark room, and when the mice began to glow faintly, you could actually see the light coming through their skin. It was really amazing.\nBut scientifically, this is very challenging, because you can’t control the direction of illumination — there is no external laser input. All you can do is measure the light that escapes to the surface. That makes it a purely passive imaging problem, and therefore much harder than fluorescence tomography.\nSo, the question is: can we reconstruct where the bioluminescent light is coming from inside the animal, based only on what we observe on the surface? That’s the big challenge of bioluminescence tomography.\n\nWhen I was at Iowa, we actually got a multi-million-dollar NIH grant to tackle exactly this problem. My idea was to use a multi-modality approach — to combine optical imaging with micro-CT or micro-MRI so we could obtain both the anatomical structure and the optical measurements together.\nHere’s how it works. First, we perform a micro-CT or micro-MRI scan of the animal. That gives us very detailed anatomical information — we can segment the bones, the organs, the tissue layers. We then take that structure and build a finite element mesh, so now we have a 3D computational model of the animal’s anatomy.\n\nNext, we perform optical measurements — diffuse optical tomography — to estimate the optical properties of the tissues, like how much they scatter and absorb light. Once we have both the anatomical map and the optical map, we put them together. Now we have a very detailed, voxel-by-voxel model — a so-called prior model — of the animal’s body.\nWith that model, we can perform Monte Carlo simulations. This is similar to the photon simulation I showed you earlier. You put a light source at a certain location inside the model, and then you let thousands — or even millions — of photons propagate randomly in all directions. Each photon scatters, reflects, refracts, or gets absorbed, following the physical laws of light propagation in tissue. Eventually, some photons reach the surface, where they are detected.\n\nThis process tells us, for any assumed source position, what the light distribution on the surface would look like. We call that the forward problem — going from a known source to the expected surface measurement.\nThen, we flip the problem around. This is the inverse problem — we already know the surface light pattern (that’s what we measured), and we want to find the internal source distribution that could have produced it.\nSo we try different possible source locations — say, one in the middle of the body, one near the liver, one near the kidneys — and simulate each case. We compare the simulated surface pattern with the measured one. If they don’t match, we adjust the model, move the source slightly, and try again.\nAfter many iterations, when the simulated pattern matches the measured pattern well, we can say with confidence that the actual bioluminescent source is located in that region inside the animal.\n\nI remember one particular case — we found two bioluminescent spots, one near the upper right and one near the left kidney. When we later sacrificed the mouse and examined it, we indeed found two small tumor nodules exactly in those locations. It was like magic — a scientific magic trick!\nWe even published that work in Optics Express, showing this successful reconstruction. It was a very satisfying result.\n\nHowever, as with all research, the story isn’t all perfect. The reconstruction is extremely sensitive to errors in the model. If your optical properties are slightly off, or your anatomical registration isn’t perfect, the reconstructed source location can be wrong. That’s why, although it’s feasible, it’s not as robust or as straightforward as, say, X-ray CT.\nSo, to summarize — bioluminescence tomography is feasible, it works, but it’s still very much a research topic, not yet a clinical tool. It’s beautiful, it’s challenging, and it’s fun to work on. And along the way, we also contributed several new ideas to this field — such as combing tomography, helical scanning, interior tomography, and other concepts that pushed the boundaries of imaging research.\nSo yes — this was, and still is, a very enjoyable area of scientific discovery.\n\nSTRICT INSTRUCTIONS:\n- Return JSON only. No prose, no markdown, no code fences.\n- Output a triple only if both subject and object appear verbatim in SLIDE_TEXT (case-insensitive).\n- Predicates must be one of: uses | via | represents | depends_on | measures | produces | reconstructs_with.\n- Add modalities [\"text\"] by default; add \"image\" only if clearly visible without the text.\n- Confidence in [0,1].\n\nOUTPUT:\n{\n  \"triples\": [\n    {\"s\":\"<verbatim subject>\", \"p\":\"uses|via|represents|depends_on|measures|produces|reconstructs_with\",\n     \"o\":\"<verbatim object>\", \"modalities\":[\"text\",\"image\"], \"confidence\":0.0, \"evidence\":\"<short quote from SLIDE_TEXT>\"}\n  ]\n}\n\nassistant\n{\n  \"triples\": [\n    {\"s\":\"bioluminescence tomography\", \"p\":\"uses|via|represents|depends_on|measures|produces|reconstructs_with\",\n     \"o\":\"fluorescence tomography\", \"modalities\":[\"text\",\"image\"], \"confidence\":0.0, \"evidence\":\"In fluorescence tomography, you can send in a laser beam — you control where it goes, you can illuminate the tissue from different directions, and that makes it what we call an active imaging modality. You actively excite the fluorescent molecules, and they emit light back, which you can detect and reconstruct into an image.\"}\n  ]\n}",
  "parsed": {
    "triples": []
  }
}