{
  "slide_id": "Slide6",
  "model": "llava-hf/llava-onevision-qwen2-7b-ov-hf",
  "prompt": "concepts",
  "raw_output": "user \nSystem:\nYou are an expert educator in medical imaging. From the following slide text,\nextract the key technical or scientific concepts that are essential for understanding the topic.\n\nUser:\nSLIDE_TEXT:\nLet me explain a little further. Take an arbitrary picture—say, a portrait of our former president. You can decompose the picture into many, many small elements. For each element, it’s very simple: just a homogeneous pixel, a small square. Add these together. \n\nThe trick is really the amplitude: you need to make sure all these amplitudes are modulated nicely. Then, when you put them together, you have the perception of a picture or a natural scene, whatever. This is one way to represent a picture.\n\nSTRICT INSTRUCTIONS:\n- Return pure JSON only. No prose, no markdown, no code fences.\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\n- Assign exactly one category from:\n  software | workflow | mathematics | signal_processing | frequency_domain |\n  physics | instrumentation | data_processing | reconstruction |\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\n- Category guidance:\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\n  * physics → energy, radiation, waves, gradients, attenuation\n  * instrumentation → scanners, detectors, coils, transducers, gantry\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\n  * communication → network or data transfer\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\n  * algorithm → analytical/iterative computational methods\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\n- Output format:\n{\n  \"concepts\": [\n    {\"term\": \"<exact term from slide>\", \"category\": \"<category>\"}\n  ],\n  \"evidence\": [\"<short supporting phrase from SLIDE_TEXT>\"]\n}\nassistant\n```json\n{\n  \"concepts\": [\n    {\"term\": \"decomposition\", \"category\": \"signal_processing\"},\n    {\"term\": \"amplitude\", \"category\": \"signal_processing\"},\n    {\"term\": \"picture representation\", \"category\": \"image_processing\"},\n    {\"term\": \"modulation\", \"category\": \"signal_processing\"},\n    {\"term\": \"perception\", \"category\": \"psychophysics\"}\n  ],\n  \"evidence\": [\"Take an arbitrary picture—say, a portrait of our former president. You can decompose the picture into many, many small elements. For each element, it’s very simple: just a homogeneous pixel, a small square. Add these together. The trick is really the amplitude: you need to make sure all these amplitudes are modulated nicely. Then, when you put them together, you have the perception of a picture or a natural scene, whatever. This is one way to represent a picture.\"]\n}\n```",
  "parsed": {
    "concepts": [
      {
        "term": "amplitude",
        "category": "signal_processing"
      }
    ],
    "evidence": [
      "Take an arbitrary picture-say, a portrait of our former president. You can decompose the picture into many, many small elements. For each element, it’s very simple: just a homogeneous pixel, a small square. Add these together. The trick is really the amplitude: you need to make sure all these amplitudes are modulated nicely. Then, when you put them together, you have the perception of a picture or a natural scene, whatever. This is one way to represent a picture."
    ]
  }
}