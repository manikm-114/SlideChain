nohup: ignoring input
/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:119: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✅ Device: cuda
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 6895.69it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.83it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  6.80it/s]
/scratch/manikm/myenv/lib/python3.10/site-packages/accelerate/utils/modeling.py:1598: UserWarning: The following device_map keys do not match any submodules in the model: ['model.image_newline']
  warnings.warn(
Some parameters are on the meta device because they were offloaded to the cpu.
✅ Successfully loaded: llava-hf/llava-onevision-qwen2-7b-ov-hf

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=concepts on 42 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/42 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/42 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/scratch/manikm/Lecture 6/llava_code_to_compare_models.py", line 362, in <module>
    run()
  File "/scratch/manikm/Lecture 6/llava_code_to_compare_models.py", line 342, in run
    raw = mm.generate(image=image, prompt_text=prompt_text, gen_kw=GEN_KW)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/manikm/Lecture 6/llava_code_to_compare_models.py", line 293, in generate
    output_ids = self.model.generate(**inputs, **gen_kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2673, in generate
    result = decoding_method(
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2866, in _sample
    outputs = self._prefill(input_ids, generation_config, model_kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3842, in _prefill
    return self(**model_inputs, return_dict=True)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/generic.py", line 757, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/models/llava_onevision/modeling_llava_onevision.py", line 813, in forward
    outputs = self.model(
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/generic.py", line 757, in wrapper
    output = func(self, *args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/models/llava_onevision/modeling_llava_onevision.py", line 576, in forward
    outputs = self.language_model(
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/generic.py", line 927, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 407, in forward
    position_embeddings = self.rotary_emb(hidden_states, position_ids)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/accelerate/hooks.py", line 175, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/modeling_rope_utils.py", line 173, in wrapper
    return rope_forward(self, x, position_ids, **kwargs)
  File "/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 107, in forward
    freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
