{
  "slide_id": "Slide40",
  "model": "llava-hf/llava-onevision-qwen2-7b-ov-hf",
  "prompt": "concepts",
  "raw_output": "user \nSystem:\nYou are an expert educator in medical imaging. From the following slide text,\nextract the key technical or scientific concepts that are essential for understanding the topic.\n\nUser:\nSLIDE_TEXT:\nNow let me introduce one of the most powerful tools in diagnostic performance evaluation: the receiver operating characteristic curve, or ROC curve.\n\nHere’s the key idea: sensitivity and specificity are not fixed properties of a test. They depend on the threshold we use to decide between “disease” and “no disease.”\n\nFor example, if I set the threshold very low, I’ll call almost everything abnormal. That means I’ll catch nearly every true case, so sensitivity will be very high. But I’ll also generate many false alarms, so specificity will drop.\nOn the other hand, if I set the threshold very high, I’ll call almost everything normal. That means I’ll have very few false alarms — so specificity will be excellent. But I’ll also miss many real cases, so sensitivity will be low.\n\nThe ROC curve captures this trade-off. On the x-axis, we plot 1 – specificity, which is the false positive rate. On the y-axis, we plot sensitivity, the true positive rate. By sweeping through all possible thresholds, we trace out the curve.\nThe ROC curve shows the overall performance of the test across all possible decision boundaries. And importantly, the area under the ROC curve, or AUC, provides a single number to summarize diagnostic accuracy. An AUC of 1.0 means perfect classification. An AUC of 0.5 — a diagonal line — means the test is no better than random guessing.\n\nSo the ROC curve is widely used in medical imaging research, because it provides a clear, quantitative way to compare diagnostic systems and observer performance.\n\nSTRICT INSTRUCTIONS:\n- Return pure JSON only. No prose, no markdown, no code fences.\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\n- Assign exactly one category from:\n  software | workflow | mathematics | signal_processing | frequency_domain |\n  physics | instrumentation | data_processing | reconstruction |\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\n- Category guidance:\n  * software → programming tools/environments (MATLAB, Octave, MathWorks)\n  * workflow → procedural/course steps (BUT exclude admin like office hours)\n  * mathematics / signal_processing / frequency_domain → formulas, transforms, filters, spectra\n  * physics → energy, radiation, waves, gradients, attenuation\n  * instrumentation → scanners, detectors, coils, transducers, gantry\n  * data_processing / reconstruction → corrections, backprojection, iterative, FBP, FFT usage\n  * quality_metric → SNR, resolution, artifacts, MTF, DQE\n  * communication → network or data transfer\n  * modality → CT, MRI, PET, SPECT, Ultrasound (US), Optical/Photoacoustic, etc.\n  * anatomy → biological structures (organs, tissues, bones, vessels) ONLY\n  * algorithm → analytical/iterative computational methods\n  * ai_ml → learning methods (deep learning, CNN, transformer, self-supervised)\n- Reject filler or administrative text (office hours, emails, rooms, homework logistics).\n- Output format:\n{\n  \"concepts\": [\n    {\"term\": \"<exact term from slide>\", \"category\": \"<category>\"}\n  ],\n  \"evidence\": [\"<short supporting phrase from SLIDE_TEXT>\"]\n}\nassistant\n```json\n{\n  \"concepts\": [\n    {\"term\": \"receiver operating characteristic curve\", \"category\": \"mathematics\"},\n    {\"term\": \"sensitivity\", \"category\": \"mathematics\"},\n    {\"term\": \"specificity\", \"category\": \"mathematics\"},\n    {\"term\": \"false positive rate\", \"category\": \"mathematics\"},\n    {\"term\": \"true positive rate\", \"category\": \"mathematics\"},\n    {\"term\": \"ROC curve\", \"category\": \"mathematics\"},\n    {\"term\": \"area under the ROC curve\", \"category\": \"mathematics\"},\n    {\"term\": \"AUC\", \"category\": \"mathematics\"},\n    {\"term\": \"diagnostic accuracy\", \"category\": \"quality_metric\"},\n    {\"term\": \"medical imaging research\", \"category\": \"modality\"}\n  ],\n  \"evidence\": [\"Now let me introduce one of the most powerful tools in diagnostic performance evaluation: the receiver operating characteristic curve, or ROC curve.\", \"Here’s the key idea: sensitivity and specificity are not fixed properties of a test. They depend on the threshold we use to decide between “disease” and “no disease.”\", \"For example, if I set the threshold very low, I’ll call almost",
  "parsed": {
    "term": "medical imaging research",
    "category": "modality"
  }
}