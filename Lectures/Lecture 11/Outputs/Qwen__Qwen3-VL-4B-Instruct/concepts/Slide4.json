{
  "slide_id": "Slide4",
  "model": "Qwen/Qwen3-VL-4B-Instruct",
  "prompt": "concepts",
  "timestamp_utc": "2025-11-09T03:00:31.725726+00:00",
  "text_length": 2705,
  "raw_output": "system\nYou are a helpful AI for medical imaging.\nuser\nSystem:\nYou are an expert educator in medical imaging. From the following slide text,\nextract the key technical or scientific concepts that are essential for understanding the topic.\n\nUser:\nSLIDE_TEXT:\nHere’s the outline for today’s lecture. We’ll approach image quality assessment from three perspectives: general measures, system-specific measures, and task-specific measures.\n\nFirst, we’ll talk about general measures. Imagine you have an image and you also know the ground truth — the ideal image you want to reconstruct. The goal is to measure how close your reconstructed image is to the ground truth. The simplest way is to calculate the difference between the two. In mathematics, we often describe this using the idea of a distance in a vector space. The most familiar example is the Euclidean distance, which leads directly to the mean squared error, or MSE.\n\nThere are other distances too. One example I’ll briefly mention is the Kullback–Leibler divergence, or KL distance. This is a bit trickier, so I won’t test you on it, but it’s good to be aware of. And then there is a very practical and powerful concept called structural similarity, or SSIM. This has become extremely influential — the original paper has been cited tens of thousands of times — because it captures how humans actually perceive similarity between images. We’ll look at why this idea is so effective.\n\nNext, we move to system-specific measures. Think of the imaging system as a kind of camera — it could be an X-ray detector, an ultrasound probe, or an MRI scanner. Every camera has its own specifications. Here we’ll talk about how noisy the images are, how well the system can distinguish a signal from background noise, and what kind of resolution it provides. Resolution itself has several dimensions: spatial resolution, contrast resolution, temporal resolution, and spectral resolution. We’ll also talk about artifacts — those misleading structures that appear in images even though they don’t exist in reality. Understanding noise, resolution, and artifacts is key to judging the performance of any imaging system.\n\nFinally, we’ll cover task-specific measures. This perspective is slightly different. Instead of asking “How good is my camera?”, we ask “How well does this imaging system perform a specific clinical task?” For example, can it reliably detect whether a bone is fractured? Can it identify a tumor in the lung? The most important thing in medicine is whether the imaging system helps doctors and patients make correct decisions. Even if a system isn’t perfect in a technical sense, if it consistently allows us to succeed in the clinical task, then it’s doing its job.\n\nSo these three aspects — general, system-specific, and task-specific — are connected, but they are not identical. Together they give us a complete picture of how to assess image quality. We’ll begin with the first: general measures.\n\nSTRICT INSTRUCTIONS:\n- Return pure JSON only. No prose, no markdown, no code fences.\n- Each concept must appear verbatim (case-insensitive) in SLIDE_TEXT.\n- Assign exactly one category from:\n  software | workflow | mathematics | signal_processing | frequency_domain |\n  physics | instrumentation | data_processing | reconstruction |\n  quality_metric | communication | modality | anatomy | algorithm | ai_ml\n- Reject filler or administrative text.\n- Output format:\n{\n  \"concepts\": [\n    {\"term\": \"<exact term from slide>\", \"category\": \"<category>\"}\n  ],\n  \"evidence\": [\"<short supporting phrase from SLIDE_TEXT>\"]\n}\n\nassistant\n{\n  \"concepts\": [\n    {\n      \"term\": \"General Measures\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"MSE\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"KL Distance\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"SSIM\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"System Specific\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"Noise\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"SNR & CNR\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"Resolution (Spatial, Contrast, Temporal, Spectral)\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"Artifacts\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"Task Specific\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"Sensitivity & Specificity\",\n      \"category\": \"quality_metric\"\n    },\n    {\n      \"term\": \"ROC & AUC\",\n      \"category",
  "parsed": {
    "term": "Sensitivity & Specificity",
    "category": "quality_metric"
  }
}