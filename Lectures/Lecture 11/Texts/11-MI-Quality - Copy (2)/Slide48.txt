Now, let’s step back and think about what diagnostic performance really means.

Not every doctor reads images with the same skill. Some physicians, with years of training and experience, can clearly separate diseased from non-diseased cases. For them, the two distributions hardly overlap, and their ROC curve bends sharply toward the upper-left corner — that’s excellent diagnostic power.

Others, perhaps junior residents still in training, may not yet recognize subtle features. Their separation is weaker, the overlap is greater, and the ROC curve lies closer to the diagonal. In the extreme case, if you cannot tell disease from normal at all, your decision is no better than flipping a coin — that’s the chance line.

So diagnostic performance is shaped by two things: the reader’s skill and the technology’s power. Better imaging systems reduce overlap, but equally important is the ability of the radiologist to interpret the image correctly.

That’s why, in practice, the same scan might lead to different conclusions depending on who reads it. A highly trained radiologist can extract subtle discriminating features that others may miss. This is exactly what the ROC curve captures — the combined effect of technology and human expertise.
