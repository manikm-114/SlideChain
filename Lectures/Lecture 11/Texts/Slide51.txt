Here’s another striking example, this time from a classic chest film study by Dr. E. James Potchen in 1999.
What you’re looking at are ROC curves comparing three groups: the top 20 radiologists, the bottom 20 radiologists, and a group of 71 radiology residents.

Notice the clear separation. The top 20 radiologists perform extremely well — their ROC curve stays high, close to the upper-left corner. That means they consistently detect abnormalities with very few false alarms.
In contrast, the bottom 20 radiologists struggle. Their ROC curve lies much closer to the diagonal, which means their decisions are only a little better than chance.
And then there are the residents. They fall somewhere in between — they’re still training, still developing the skills to interpret subtle features in chest films.

What this tells us is that diagnostic performance is not determined by the technology alone. The human factor — training, experience, and even natural ability — plays a huge role. The same X-ray image can be interpreted very differently depending on who is reading it.
This is why task-specific measures are so important. At the end of the day, what really matters is not just whether the imaging system produces a sharp picture, but whether that picture supports accurate clinical decisions.
