Now let’s look at this fascinating experiment. Here, subjects were shown two different types of images — human faces and buildings. The MRI scans you see here show how the brain reacts differently in each case. When a person looks at a face, certain brain regions light up — you can see those areas in red and orange. When the same person looks at a building, other regions become more active. This happens because the brain’s oxygen-rich blood flow changes depending on what you are thinking or perceiving.

When neurons in a region start firing, they consume more oxygen. The body responds by sending in oxygenated blood, which creates a stronger MRI signal in that area. This mechanism is called the BOLD effect, short for Blood Oxygen Level Dependent contrast. By analyzing these signal patterns statistically, we can tell what kind of object the person is viewing — for example, a face versus a house. This was one of the early experiments demonstrating how brain activity reflects thought and perception.

In more recent studies, researchers have gone even further. Using advanced image analysis and machine learning, they can now reconstruct, with rough resolution, what a person is actually seeing — essentially allowing us to peek into human perception. It’s an incredible step toward understanding how the brain encodes visual information. If you have time, I highly recommend watching a short video on this topic — it’s truly amazing to see how far this technology has come.
