nohup: ignoring input
/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:119: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✅ Device: cuda
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 11328.30it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.01it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.14it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
✅ Successfully loaded: llava-hf/llava-onevision-qwen2-7b-ov-hf

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=concepts on 49 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/49 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   2%|▏         | 1/49 [00:06<05:14,  6.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   4%|▍         | 2/49 [00:14<05:57,  7.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   6%|▌         | 3/49 [00:19<04:41,  6.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   8%|▊         | 4/49 [00:27<05:16,  7.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  10%|█         | 5/49 [00:35<05:17,  7.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  12%|█▏        | 6/49 [00:43<05:27,  7.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  14%|█▍        | 7/49 [00:52<05:30,  7.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  16%|█▋        | 8/49 [00:57<04:56,  7.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  18%|█▊        | 9/49 [01:05<04:58,  7.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  20%|██        | 10/49 [01:14<05:02,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  22%|██▏       | 11/49 [01:22<05:03,  7.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  24%|██▍       | 12/49 [01:31<05:00,  8.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  27%|██▋       | 13/49 [01:39<04:56,  8.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  29%|██▊       | 14/49 [01:48<04:50,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  31%|███       | 15/49 [01:56<04:43,  8.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  33%|███▎      | 16/49 [02:03<04:22,  7.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  35%|███▍      | 17/49 [02:09<03:49,  7.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  37%|███▋      | 18/49 [02:17<03:54,  7.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  39%|███▉      | 19/49 [02:24<03:38,  7.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  41%|████      | 20/49 [02:32<03:41,  7.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  43%|████▎     | 21/49 [02:41<03:40,  7.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  45%|████▍     | 22/49 [02:49<03:38,  8.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  47%|████▋     | 23/49 [02:57<03:29,  8.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  49%|████▉     | 24/49 [03:06<03:24,  8.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  51%|█████     | 25/49 [03:14<03:18,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  53%|█████▎    | 26/49 [03:23<03:11,  8.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  55%|█████▌    | 27/49 [03:31<03:04,  8.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  57%|█████▋    | 28/49 [03:39<02:56,  8.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  59%|█████▉    | 29/49 [03:46<02:38,  7.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  61%|██████    | 30/49 [03:55<02:33,  8.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  63%|██████▎   | 31/49 [04:03<02:27,  8.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  65%|██████▌   | 32/49 [04:11<02:17,  8.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  67%|██████▋   | 33/49 [04:19<02:11,  8.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  69%|██████▉   | 34/49 [04:28<02:04,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  71%|███████▏  | 35/49 [04:36<01:56,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  73%|███████▎  | 36/49 [04:45<01:48,  8.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  76%|███████▌  | 37/49 [04:53<01:40,  8.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  78%|███████▊  | 38/49 [05:02<01:32,  8.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  80%|███████▉  | 39/49 [05:07<01:16,  7.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  82%|████████▏ | 40/49 [05:16<01:10,  7.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  84%|████████▎ | 41/49 [05:24<01:03,  7.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  86%|████████▌ | 42/49 [05:30<00:51,  7.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  88%|████████▊ | 43/49 [05:38<00:46,  7.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  90%|████████▉ | 44/49 [05:47<00:39,  7.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  92%|█████████▏| 45/49 [05:55<00:32,  8.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  94%|█████████▍| 46/49 [06:04<00:24,  8.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  96%|█████████▌| 47/49 [06:11<00:15,  7.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  98%|█████████▊| 48/49 [06:17<00:07,  7.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 49/49 [06:24<00:00,  7.32s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 49/49 [06:24<00:00,  7.85s/it]
✅ Completed 48/49 slides

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=triples on 49 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   0%|          | 0/49 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   2%|▏         | 1/49 [00:03<02:57,  3.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   4%|▍         | 2/49 [00:07<02:46,  3.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   6%|▌         | 3/49 [00:10<02:49,  3.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   8%|▊         | 4/49 [00:17<03:38,  4.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  10%|█         | 5/49 [00:20<03:09,  4.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  12%|█▏        | 6/49 [00:24<02:49,  3.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  14%|█▍        | 7/49 [00:27<02:33,  3.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  16%|█▋        | 8/49 [00:31<02:39,  3.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  18%|█▊        | 9/49 [00:35<02:40,  4.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  20%|██        | 10/49 [00:39<02:29,  3.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  22%|██▏       | 11/49 [00:43<02:29,  3.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  24%|██▍       | 12/49 [00:47<02:24,  3.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  27%|██▋       | 13/49 [00:51<02:22,  3.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  29%|██▊       | 14/49 [00:55<02:16,  3.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  31%|███       | 15/49 [00:58<02:06,  3.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  33%|███▎      | 16/49 [01:02<02:07,  3.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  35%|███▍      | 17/49 [01:07<02:11,  4.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  37%|███▋      | 18/49 [01:11<02:06,  4.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  39%|███▉      | 19/49 [01:14<01:56,  3.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  41%|████      | 20/49 [01:20<02:03,  4.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  43%|████▎     | 21/49 [01:24<01:59,  4.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  45%|████▍     | 22/49 [01:28<01:52,  4.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  47%|████▋     | 23/49 [01:31<01:42,  3.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  49%|████▉     | 24/49 [01:35<01:35,  3.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  51%|█████     | 25/49 [01:38<01:30,  3.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  53%|█████▎    | 26/49 [01:42<01:26,  3.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  55%|█████▌    | 27/49 [01:46<01:24,  3.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  57%|█████▋    | 28/49 [01:50<01:22,  3.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  59%|█████▉    | 29/49 [01:54<01:18,  3.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  61%|██████    | 30/49 [01:59<01:18,  4.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  63%|██████▎   | 31/49 [02:03<01:12,  4.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  65%|██████▌   | 32/49 [02:07<01:09,  4.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  67%|██████▋   | 33/49 [02:10<01:01,  3.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  69%|██████▉   | 34/49 [02:15<01:03,  4.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  71%|███████▏  | 35/49 [02:18<00:54,  3.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  73%|███████▎  | 36/49 [02:23<00:54,  4.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  76%|███████▌  | 37/49 [02:28<00:53,  4.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  78%|███████▊  | 38/49 [02:32<00:45,  4.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  80%|███████▉  | 39/49 [02:35<00:40,  4.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  82%|████████▏ | 40/49 [02:39<00:35,  3.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  84%|████████▎ | 41/49 [02:43<00:30,  3.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  86%|████████▌ | 42/49 [02:47<00:27,  3.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  88%|████████▊ | 43/49 [02:55<00:31,  5.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  90%|████████▉ | 44/49 [02:59<00:24,  4.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  92%|█████████▏| 45/49 [03:03<00:17,  4.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  94%|█████████▍| 46/49 [03:08<00:13,  4.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  96%|█████████▌| 47/49 [03:12<00:08,  4.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  98%|█████████▊| 48/49 [03:15<00:04,  4.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 49/49 [03:18<00:00,  3.89s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 49/49 [03:18<00:00,  4.06s/it]
✅ Completed 48/49 slides
