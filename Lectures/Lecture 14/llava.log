nohup: ignoring input
/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:119: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✅ Device: cuda
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 8839.42it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.05it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.37it/s]
✅ Successfully loaded: llava-hf/llava-onevision-qwen2-7b-ov-hf

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=concepts on 60 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/60 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   2%|▏         | 1/60 [00:05<05:24,  5.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   3%|▎         | 2/60 [00:10<05:16,  5.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   5%|▌         | 3/60 [00:14<04:27,  4.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   7%|▋         | 4/60 [00:23<05:44,  6.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   8%|▊         | 5/60 [00:31<06:22,  6.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  10%|█         | 6/60 [00:39<06:42,  7.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  12%|█▏        | 7/60 [00:45<05:57,  6.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  13%|█▎        | 8/60 [00:53<06:18,  7.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  15%|█▌        | 9/60 [01:01<06:25,  7.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  17%|█▋        | 10/60 [01:07<05:50,  7.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  18%|█▊        | 11/60 [01:16<06:05,  7.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  20%|██        | 12/60 [01:20<05:19,  6.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  22%|██▏       | 13/60 [01:29<05:38,  7.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  23%|██▎       | 14/60 [01:37<05:48,  7.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  25%|██▌       | 15/60 [01:46<05:51,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  27%|██▋       | 16/60 [01:52<05:25,  7.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  28%|██▊       | 17/60 [01:59<05:12,  7.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  30%|███       | 18/60 [02:06<04:56,  7.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  32%|███▏      | 19/60 [02:12<04:42,  6.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  33%|███▎      | 20/60 [02:21<04:54,  7.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  35%|███▌      | 21/60 [02:26<04:20,  6.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  37%|███▋      | 22/60 [02:33<04:20,  6.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  38%|███▊      | 23/60 [02:41<04:31,  7.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  40%|████      | 24/60 [02:50<04:36,  7.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  42%|████▏     | 25/60 [02:58<04:36,  7.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  43%|████▎     | 26/60 [03:07<04:34,  8.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  45%|████▌     | 27/60 [03:15<04:29,  8.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  47%|████▋     | 28/60 [03:24<04:24,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  48%|████▊     | 29/60 [03:32<04:15,  8.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  50%|█████     | 30/60 [03:40<04:07,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  52%|█████▏    | 31/60 [03:46<03:41,  7.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  53%|█████▎    | 32/60 [03:55<03:40,  7.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  55%|█████▌    | 33/60 [04:03<03:37,  8.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  57%|█████▋    | 34/60 [04:12<03:32,  8.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  58%|█████▊    | 35/60 [04:20<03:26,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  60%|██████    | 36/60 [04:29<03:19,  8.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  62%|██████▏   | 37/60 [04:34<02:52,  7.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  63%|██████▎   | 38/60 [04:42<02:45,  7.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  65%|██████▌   | 39/60 [04:50<02:44,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  67%|██████▋   | 40/60 [04:59<02:40,  8.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  68%|██████▊   | 41/60 [05:07<02:32,  8.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  70%|███████   | 42/60 [05:15<02:26,  8.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  72%|███████▏  | 43/60 [05:24<02:20,  8.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  73%|███████▎  | 44/60 [05:32<02:13,  8.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  75%|███████▌  | 45/60 [05:41<02:05,  8.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  77%|███████▋  | 46/60 [05:49<01:57,  8.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  78%|███████▊  | 47/60 [05:58<01:49,  8.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  80%|████████  | 48/60 [06:06<01:41,  8.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  82%|████████▏ | 49/60 [06:15<01:33,  8.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  83%|████████▎ | 50/60 [06:19<01:12,  7.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  85%|████████▌ | 51/60 [06:27<01:08,  7.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  87%|████████▋ | 52/60 [06:31<00:51,  6.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  88%|████████▊ | 53/60 [06:37<00:43,  6.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  90%|█████████ | 54/60 [06:46<00:41,  6.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  92%|█████████▏| 55/60 [06:51<00:31,  6.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  93%|█████████▎| 56/60 [06:59<00:27,  6.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  95%|█████████▌| 57/60 [07:04<00:18,  6.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  97%|█████████▋| 58/60 [07:11<00:13,  6.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  98%|█████████▊| 59/60 [07:20<00:07,  7.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 60/60 [07:28<00:00,  7.56s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 60/60 [07:28<00:00,  7.48s/it]
✅ Completed 60/60 slides

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=triples on 60 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   0%|          | 0/60 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   2%|▏         | 1/60 [00:03<03:50,  3.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   3%|▎         | 2/60 [00:06<03:15,  3.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   5%|▌         | 3/60 [00:10<03:25,  3.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   7%|▋         | 4/60 [00:14<03:26,  3.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   8%|▊         | 5/60 [00:19<03:46,  4.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  10%|█         | 6/60 [00:23<03:34,  3.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  12%|█▏        | 7/60 [00:27<03:33,  4.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  13%|█▎        | 8/60 [00:35<04:42,  5.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  15%|█▌        | 9/60 [00:40<04:30,  5.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  17%|█▋        | 10/60 [00:45<04:22,  5.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  18%|█▊        | 11/60 [00:51<04:20,  5.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  20%|██        | 12/60 [00:56<04:11,  5.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  22%|██▏       | 13/60 [01:00<03:54,  5.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  23%|██▎       | 14/60 [01:04<03:32,  4.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  25%|██▌       | 15/60 [01:08<03:13,  4.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  27%|██▋       | 16/60 [01:12<03:14,  4.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  28%|██▊       | 17/60 [01:18<03:21,  4.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  30%|███       | 18/60 [01:21<03:04,  4.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  32%|███▏      | 19/60 [01:27<03:11,  4.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  33%|███▎      | 20/60 [01:31<02:58,  4.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  35%|███▌      | 21/60 [01:35<02:48,  4.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  37%|███▋      | 22/60 [01:39<02:45,  4.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  38%|███▊      | 23/60 [01:48<03:26,  5.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  40%|████      | 24/60 [01:51<02:56,  4.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  42%|████▏     | 25/60 [01:59<03:27,  5.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  43%|████▎     | 26/60 [02:08<03:47,  6.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  45%|████▌     | 27/60 [02:12<03:16,  5.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  47%|████▋     | 28/60 [02:15<02:45,  5.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  48%|████▊     | 29/60 [02:19<02:24,  4.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  50%|█████     | 30/60 [02:27<02:53,  5.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  52%|█████▏    | 31/60 [02:31<02:28,  5.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  53%|█████▎    | 32/60 [02:35<02:19,  4.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  55%|█████▌    | 33/60 [02:39<02:01,  4.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  57%|█████▋    | 34/60 [02:43<01:52,  4.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  58%|█████▊    | 35/60 [02:51<02:18,  5.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  60%|██████    | 36/60 [02:55<02:00,  5.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  62%|██████▏   | 37/60 [02:59<01:47,  4.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  63%|██████▎   | 38/60 [03:02<01:31,  4.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  65%|██████▌   | 39/60 [03:05<01:21,  3.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  67%|██████▋   | 40/60 [03:09<01:18,  3.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  68%|██████▊   | 41/60 [03:12<01:11,  3.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  70%|███████   | 42/60 [03:17<01:09,  3.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  72%|███████▏  | 43/60 [03:20<01:03,  3.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  73%|███████▎  | 44/60 [03:23<00:57,  3.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  75%|███████▌  | 45/60 [03:27<00:54,  3.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  77%|███████▋  | 46/60 [03:30<00:49,  3.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  78%|███████▊  | 47/60 [03:33<00:44,  3.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  80%|████████  | 48/60 [03:38<00:43,  3.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  82%|████████▏ | 49/60 [03:41<00:38,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  83%|████████▎ | 50/60 [03:44<00:35,  3.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  85%|████████▌ | 51/60 [03:48<00:30,  3.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  87%|████████▋ | 52/60 [03:51<00:27,  3.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  88%|████████▊ | 53/60 [03:54<00:24,  3.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  90%|█████████ | 54/60 [03:57<00:19,  3.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  92%|█████████▏| 55/60 [04:00<00:16,  3.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  93%|█████████▎| 56/60 [04:04<00:12,  3.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  95%|█████████▌| 57/60 [04:08<00:11,  3.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  97%|█████████▋| 58/60 [04:12<00:07,  3.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  98%|█████████▊| 59/60 [04:16<00:03,  3.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 60/60 [04:20<00:00,  3.93s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 60/60 [04:20<00:00,  4.35s/it]
✅ Completed 60/60 slides
