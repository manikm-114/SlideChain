nohup: ignoring input
/scratch/manikm/myenv/lib/python3.10/site-packages/transformers/utils/hub.py:119: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
✅ Device: cuda
Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 5363.56it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.05it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.15it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.20it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
✅ Successfully loaded: llava-hf/llava-onevision-qwen2-7b-ov-hf

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=concepts on 43 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   0%|          | 0/43 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   2%|▏         | 1/43 [00:09<06:33,  9.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   5%|▍         | 2/43 [00:17<05:59,  8.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   7%|▋         | 3/43 [00:26<05:45,  8.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:   9%|▉         | 4/43 [00:34<05:33,  8.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  12%|█▏        | 5/43 [00:43<05:23,  8.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  14%|█▍        | 6/43 [00:50<05:07,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  16%|█▋        | 7/43 [00:59<05:00,  8.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  19%|█▊        | 8/43 [01:07<04:53,  8.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  21%|██        | 9/43 [01:16<04:45,  8.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  23%|██▎       | 10/43 [01:24<04:37,  8.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  26%|██▌       | 11/43 [01:33<04:29,  8.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  28%|██▊       | 12/43 [01:41<04:21,  8.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  30%|███       | 13/43 [01:48<04:03,  8.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  33%|███▎      | 14/43 [01:57<03:58,  8.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  35%|███▍      | 15/43 [02:05<03:52,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  37%|███▋      | 16/43 [02:14<03:45,  8.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  40%|███▉      | 17/43 [02:22<03:38,  8.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  42%|████▏     | 18/43 [02:31<03:30,  8.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  44%|████▍     | 19/43 [02:39<03:22,  8.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  47%|████▋     | 20/43 [02:46<03:03,  7.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  49%|████▉     | 21/43 [02:55<02:58,  8.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  51%|█████     | 22/43 [03:03<02:52,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  53%|█████▎    | 23/43 [03:12<02:46,  8.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  56%|█████▌    | 24/43 [03:19<02:29,  7.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  58%|█████▊    | 25/43 [03:27<02:25,  8.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  60%|██████    | 26/43 [03:36<02:19,  8.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  63%|██████▎   | 27/43 [03:44<02:12,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  65%|██████▌   | 28/43 [03:53<02:05,  8.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  67%|██████▋   | 29/43 [04:01<01:57,  8.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  70%|██████▉   | 30/43 [04:10<01:49,  8.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  72%|███████▏  | 31/43 [04:17<01:37,  8.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  74%|███████▍  | 32/43 [04:23<01:23,  7.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  77%|███████▋  | 33/43 [04:31<01:15,  7.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  79%|███████▉  | 34/43 [04:39<01:10,  7.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  81%|████████▏ | 35/43 [04:45<00:56,  7.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  84%|████████▎ | 36/43 [04:51<00:47,  6.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  86%|████████▌ | 37/43 [04:59<00:43,  7.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  88%|████████▊ | 38/43 [05:06<00:36,  7.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  91%|█████████ | 39/43 [05:13<00:28,  7.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  93%|█████████▎| 40/43 [05:22<00:22,  7.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  95%|█████████▌| 41/43 [05:27<00:13,  6.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts:  98%|█████████▊| 42/43 [05:33<00:06,  6.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 43/43 [05:42<00:00,  7.21s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | concepts: 100%|██████████| 43/43 [05:42<00:00,  7.96s/it]
✅ Completed 43/43 slides

=== Running model=llava-hf/llava-onevision-qwen2-7b-ov-hf prompt=triples on 43 slides ===
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   0%|          | 0/43 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   2%|▏         | 1/43 [00:03<02:28,  3.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   5%|▍         | 2/43 [00:07<02:23,  3.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   7%|▋         | 3/43 [00:10<02:25,  3.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:   9%|▉         | 4/43 [00:14<02:26,  3.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  12%|█▏        | 5/43 [00:19<02:29,  3.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  14%|█▍        | 6/43 [00:23<02:28,  4.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  16%|█▋        | 7/43 [00:26<02:17,  3.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  19%|█▊        | 8/43 [00:30<02:12,  3.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  21%|██        | 9/43 [00:34<02:10,  3.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  23%|██▎       | 10/43 [00:38<02:06,  3.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  26%|██▌       | 11/43 [00:41<01:58,  3.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  28%|██▊       | 12/43 [00:44<01:48,  3.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  30%|███       | 13/43 [00:48<01:49,  3.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  33%|███▎      | 14/43 [00:52<01:47,  3.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  35%|███▍      | 15/43 [00:57<01:54,  4.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  37%|███▋      | 16/43 [01:00<01:44,  3.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  40%|███▉      | 17/43 [01:03<01:32,  3.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  42%|████▏     | 18/43 [01:07<01:32,  3.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  44%|████▍     | 19/43 [01:11<01:31,  3.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  47%|████▋     | 20/43 [01:15<01:31,  3.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  49%|████▉     | 21/43 [01:19<01:25,  3.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  51%|█████     | 22/43 [01:24<01:26,  4.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  53%|█████▎    | 23/43 [01:29<01:25,  4.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  56%|█████▌    | 24/43 [01:32<01:14,  3.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  58%|█████▊    | 25/43 [01:35<01:10,  3.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  60%|██████    | 26/43 [01:40<01:11,  4.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  63%|██████▎   | 27/43 [01:44<01:04,  4.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  65%|██████▌   | 28/43 [01:48<00:59,  3.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  67%|██████▋   | 29/43 [01:52<00:56,  4.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  70%|██████▉   | 30/43 [01:55<00:50,  3.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  72%|███████▏  | 31/43 [01:59<00:45,  3.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  74%|███████▍  | 32/43 [02:03<00:42,  3.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  77%|███████▋  | 33/43 [02:07<00:39,  3.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  79%|███████▉  | 34/43 [02:11<00:34,  3.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  81%|████████▏ | 35/43 [02:14<00:30,  3.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  84%|████████▎ | 36/43 [02:18<00:26,  3.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  86%|████████▌ | 37/43 [02:22<00:22,  3.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  88%|████████▊ | 38/43 [02:26<00:19,  3.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  91%|█████████ | 39/43 [02:29<00:14,  3.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  93%|█████████▎| 40/43 [02:33<00:11,  3.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  95%|█████████▌| 41/43 [02:37<00:07,  3.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples:  98%|█████████▊| 42/43 [02:41<00:03,  3.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.
llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 43/43 [02:45<00:00,  3.86s/it]llava-hf__llava-onevision-qwen2-7b-ov-hf | triples: 100%|██████████| 43/43 [02:45<00:00,  3.84s/it]
✅ Completed 43/43 slides
