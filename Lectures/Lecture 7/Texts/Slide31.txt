Now let’s dive into the process of sampling a signal — how we go from the continuous world to the digital one.

Look first at the top-left plot. That’s our original continuous signal, shown over a finite interval, from minus T over 2 to plus T over 2. Our goal is to digitize this — to convert it into a form that we can process on a computer.
And to do that, we take measurements at evenly spaced time intervals. This step is crucial, because without any prior knowledge about the signal, we don't know where we should sample more densely or more sparsely — so we just use uniform sampling.

We model this sampling process mathematically by multiplying the signal with a train of impulses — those red vertical lines spaced by delta t. This models a measurement being taken at regular intervals — just like a thermometer recording temperature every hour.

When we multiply the continuous function by this comb of impulses, we’re essentially pulling out values at those discrete points. The result is a sampled signal, where the values are available only at those locations. That’s what you see in the next plot below — the discrete signal.

Now shift your attention to the right-hand side — to the frequency domain.
The original continuous signal, when transformed using the Fourier transform, gives us a spectrum — and here it's shown to be concentrated between minus W and plus W. That’s the bandwidth of the signal — most of its energy lies within that frequency range.
And here’s something interesting: if a signal is limited in time — meaning it's non-zero only within a certain interval — then its Fourier transform will spread out infinitely. But if the time-domain signal is smooth, then the energy in its spectrum decays very fast. So in practice, we can often ignore the tiny tails and just focus on the dominant part within minus W to W.

Now, here comes the key insight.
When we sample the time-domain signal using a comb — a series of impulses spaced by delta t — then in the frequency domain, the Fourier transform becomes a convolution. That convolution replicates the original spectrum at regular intervals — and those intervals are one over delta t, which we denote as capital P.
So in the frequency domain, we now have multiple copies of the original spectrum, all spaced by P. These are sometimes called spectral replicas.

And here’s the big question: how small should delta t be? Or in other words — how dense should our sampling be — so that these spectral copies don’t overlap?
Because if they overlap, we get aliasing, and the original signal can’t be recovered. But if P — that is, one over delta t — is large enough, then these copies stay nicely separated, and we can isolate just one of them to recover the original signal perfectly.

So in short, if we sample densely enough, we don't lose any information. We can convert a continuous signal to a digital one and then reconstruct it — as if nothing was lost.
And that naturally brings us to the next topic — what is the minimum sampling rate we need to guarantee perfect recovery?
Let’s take a look.
